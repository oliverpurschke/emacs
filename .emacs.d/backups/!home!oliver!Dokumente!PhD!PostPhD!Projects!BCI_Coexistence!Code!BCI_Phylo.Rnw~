%% LyX 2.0.3 created this file.  For more info, see
http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage{mathpazo}
%\usepackage{lmodern}

\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\usepackage{url}
\usepackage[authoryear]{natbib}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% \VignetteIndexEntry{An Introduction to knitr}

\makeatother

\begin{document}

\title{Lab report: "Phylogenetic signal in species' co-occurrence"}

\author{Oliver Purschke}

\maketitle
The \textbf{knitr} package \citep{Bel10} is an alternative too to Sweave based on a different design with more features. This document is not the real vignette, but only serves as a placeholder to guide you to the real manuals of this package. You can find them in the package website: \url{http://yihui.name/knitr}%
\footnote{e.g. the main manual:
\url{https://github.com/downloads/yihui/knitr/knitr-manual.pdf}
and the graphics manual:
\url{https://github.com/downloads/yihui/knitr/knitr-graphics.pdf}}, and remember to read the help pages of functions in this package. Anyway, here is a code chunk that shows you can compile vignettes with \textbf{knitr} as well by using a proper \textsf{Makefile} (see \url{http://yihui.name/knitr/demo/vignette/}):

<<show-off>>=

# load packages
library(multitable)
library(knitr)
library(picante)
library(adephylo)
library(phylobase)
library(ade4)
library(phytools)
library(spacodiR)
library(gridExtra)
library(cooccur)
library(reshape)
library(bipartite)
library(rosalia)
library(mistnet)
library(cowplot)
library(ggplot2)
library(piecewiseSEM)
library(plyr)
library(dplyr)

# load "CTFSRPackage"
attach("CTFSRPackage/CTFSRPackage.rdata")
ls(2)
# set paths

path.code.generic <- "/home/oliver/Dokumente/PhD/Code/"
path.code <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Code/"
path.data <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/"
path.traits <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/"
path.species <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Species/"
path.phylo <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Phylo/"

path.results <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Results/"

# load additional functions
source(paste(path.code.generic, "OPfunc.R", sep = ""))
source(paste(path.code.generic,"RaoDeBelloJVS/Rao_JVS.R", sep = ""))
source(paste(path.code.generic, "spacodiutility.R", sep = ""))

# load entire data set

load(paste(path.data, "bci.data.Rdata", sep = ""))

## load BCI phylogeny
bci.tree <- read.tree(paste(path.phylo, "dated.tree.tre", sep = "")) 
bci.tree.OP <- read.tree(paste(path.phylo, "dated.tree.OP.tre", sep = ""))

# test correlations between distances:
pdf("CorTest.Niche.Fit.Diffs.pdf", width =12, height = 12)
CorTestPlot(bci.data$distvec.traits.phy.cooc[,c(53,3,5,7,9,11,13,17:20,27,28)])
dev.off()

pdf("CorTest.Niche.Fit.pdf", width = 15, height = 15)
CorTestPlot(bci.data$traits.pca[,c(1,2,4,6,8,10,12,16,18,26)])
dev.off()

## co-occurrence:
names(bci.data$grid.205)

cooccur.bci <- cooccur(mat=bci.data$grid.205[[14]],
			   type="site_spp",
			   thresh=T,
			   spp_names=TRUE)

pair.profile(cooccur.bci)

pdf("cooccur.bci.pdf", width=40, height = 30)
plot(cooccur.bci)
dev.off()

# 

# to do: 
# 1)  Check names in phylogeny (do they correspond to nate's and joe' new nomenclature?)
# 1.1) update names in BCI phylogeny according to new nomenclature (and at some stage also clean names using TNRS)

# 2) check names in Nadja's NEW trait data (do they correspond to the updated nomenclature?)
# 2.2) if needed, adapt to new nomenclature (see above)

# 3) add missing species (e.g. present in nadjas list but absent in the phylogeny) (?? ~ 15 species?)
# 3.1) !!! double-check whether missing species are not synomyms to species already present in the phylogeny
# two possibilities: i) either add to congeners (if there are many congeners add to most common ancestors if phylogeny if this genus of family is available) or ii) add to next family or order (less good option)


# what nadja already has done/checked already:

# 1) 14th may 2013:
# zwei Versionen demographischer traits, einmal ohne dass die Abundance in die Parameterschätzung einging (noabun) und einmal so, dass traits in Abhängigkeit der Abundance der Art geschätzt wurden (abun).

# missing_species_noabun (26 missing)
# missing_species_abun (24 missing)

# Die Artnamen habe ich der Phylogeny angepasst, so dass noch ca. 25 Arten fehlen und per Hand eingefügt werden müssten. (Nadja hat die Arten schon an die korrigierte nomenklaturlist von nate angepasst)


# 2) 
# 28th may 2013:
# zwei Listen von Arten, die in der Phylogeny fehlen: 
    # missing_species_abun_all.txt (33 species missing): alle Arten, für die mindestens ein demographic trait bekannt ist 
    # missing_species_abun_compl.txt (~ 12 species missing): alle
Arten, für die alle drei demografischen traits in beiden Intervallen
bekannt sind (da fällt die Artanzahl von ca. 300 auf ca. 200, keine
Ahnung, ob das Sinn hat 


# 1)  Check names in phylogeny (do they correspond to nate's and joe' new nomenclature?)

sort(bci.tree$tip.label)
# yes, correct appart from one species

bci.tree$tip.label[bci.tree$tip.label=="Appunia_seibertii"] <-
"Morinda_seibertii"

bci.data <- list()
bci.data$phyfull <- bci.tree

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))
load(paste(path.data, "bci.data.Rdata", sep = ""))

pdf("bci.tree.woGnetum.pdf", height = 25, width = 25)
plot(drop.tip(bci.tree, "Gnetum_leyboldii"), type = "f", cex = .6)
dev.off()

### modify Joe Wrights table with code names
# add new column with species in names in th e (!! do not change
codes)

spec.code <- read.csv(paste(path.species, "spec.code.csv", sep = ""),
sep = "\t")

# extra column for full species name
spec.code$spec <- paste(spec.code$GENUS., spec.code$SPECIES, sep =
"_")

# extra column for new/updated species name
spec.code$spec.new <- spec.code$spec

# rename species in joe's list according to new nomenclature,
according to list send by nate (?! and according nadja' old match?!)
# i) according to nate' list:
spec.code$spec.new[spec.code$spec.new=="Appunia_seibertii"] <-
"Morinda_seibertii" #!! to be changed in throughout Nadja's trait data
spec.code$spec.new[spec.code$spec.new=="Acacia_melanoceras"] <-
"Vachellia_melanoceras"
spec.code$spec.new[spec.code$spec.new=="Ardisia_fendleri"] <-
"Ardisia_standleyana"
spec.code$spec.new[spec.code$spec.new=="Attalea_butyracea"] <-
"Attalea_rostrata"
spec.code$spec.new[spec.code$spec.new=="Beilschmiedia_pendula"] <-
"Beilschmiedia_tovarensis"
spec.code$spec.new[spec.code$spec.new=="Miconia_corsiloba"] <-
"Miconia_dorsiloba"
spec.code$spec.new[spec.code$spec.new=="Nectandra_purpurea"] <-
"Nectandra_umbrosa"
spec.code$spec.new[spec.code$spec.new=="Piper_schiedeanum"] <-
"Piper_carrilloanum"
spec.code$spec.new[spec.code$spec.new=="Psychotria_pittieri"] <-
"Psychotria_cyanococca"
spec.code$spec.new[spec.code$spec.new=="Solanum_steyermarkii"] <-
"Solanum_lepidotum"
spec.code$spec.new[spec.code$spec.new=="Talisia_princeps"] <-
"Talisia_croatii"
spec.code$spec.new[spec.code$spec.new=="Virola_surinamensis"] <-
"Virola_nobilis"
spec.code$spec.new[spec.code$spec.new=="Zanthoxylum_acuminatum"] <-
"Zanthoxylum_juniperinum"

# ii) according to nadja's first match (non_matching_sp):
spec.code$spec.new[spec.code$spec.new=="Pterocarpus_officinalis"] <-
"Pterocarpus_belizensis"
spec.code$spec.new[spec.code$SP.=="SWARS1"] <-
"Swartzia_simplex_var_grandiflora"

# iii) rename (or add/ incl. shortnames) species in joe's list
according to nadja's new species (missing in the phylogeny)

"Alchornea_costaricensis"   # to correct
"Apeiba_hybrid"             # add "APEIHY"
"Bactris_coloradonis"       # add "BACTC2" (+ check in TNRS whether
synomyn to B. coloniata)
"Banara_guianensis"         # correct 
"Bertiera_guianensis"       # correct
"Cestrum_megalophyllum"       
"Cyathea_petiolata"           
"Colubrina_glandulosa"    
## ...
# species names in joes list appear to be truncated after 12 letters

### stop here:

# take species codes from Nadja's list instead


##############################################################################################
# add new species to the phylogeny (only take joe's list to get info
about family-affiliation)
##############################################################################################

"Alchornea_costaricensis"    # added 
"Apeiba_hybrid"              # added 
"Bactris_coloradonis"        # added, check whether it belongs to
b.col or b.bar
"Banara_guianensis"          # # added to genus Hasseltia
(Flacourtiace)

"Bertiera_guianensis"        # to be added to Rubiaceae (Borojoa,
Calycophyllu, Chimarrhis,Chomelia, Cosmibuena, Coussarea, Coutarea,
Elaeagia, Exostema, Faramea, Genipa (#), Guettarda (#), Hamelia,
Isertia, Macrocnemum, Morinda, Palicourea, Pentagonia, Pogonopus (#),
Posoqueria (#), Psychotria, Randia (##), Rosenbergiod (##), Rondeletia
(#), Rudgea, Tocoyena (##), Alibertia, Alseis, Amaioua, Pittoniotis,
Appunia)
# added

# find most closely related genus

"Cestrum_megalophyllum"      # family Solanaceae: Solanum (add to
Solanum), Cestrum (does Markea belong to Solanaceae, yes!)

"Cyathea_petiolata"          # Cyatheaceae family not represented (!!
tree fern, maybe skip?!)
# do include tree ferns

"Colubrina_glandulosa"       # to be added to "Rhamnaceae" (family not
represented)
# find most closely related family ()
# sister to clade that holds ficus and cecropia (N143)
# added

"Drypetes_standleyi" #(family Euphorbiacea: Hura, Hieronyma, Mabea,
Maprounea, Margaritaria, Pera, Sapium, Tetrorchidiu, Acalypha, Adelia,
Alchornea, Amanoa, Croton, Drypetes)
# added to Margaritina

# find most closely related genus

"Ficus_colubrinae"  # two groups within genus ficus add to one of them
# added
"Ficus_pertusa"  # two groups within genus ficus add to one of them #
added

"Geonoma_interrupta"  # family Aracaceae: Oenocarpus (##), Attalea (),
Socratea (), Synechanthus (), Astrocaryum (), Bactris (), Chamaedorea,
Elaeis
# find most closely related genus
# added to Oenocarpus (Arecoideae)
                   
"Inga_mucuna"   # added

"Koanophyllon_wetmorei" # family: Asteraceae (Verbesina, Vernonanthur)
# added to family: Asteraceae N326

"Lacmellea_panamensis"  # family Apocynaceae: Rauvolfia, Stemmadenia,
Tabernaemont, Thevetia, 
# Aspidosperma
# renamed to "Lacmellea_panamensis"

"Pavonia_dasypetala"   # search for family Malvacea (Hampea)
# added

"Lycianthes_maxonii" # family Solanaceae: Solanum (add to Solanum),
Cestrum (does Markea belong to Solanaceae)
# added

"Maclura_tinctoria"  # family Moraceae: Maquira (#), Trophis, Perebea
(#), Poulsenia (#), Pseudolmedia (#), Sorocea, Brosimum, Castilla (#),
Ficus, Trophis
# added

"Miconia_prasina"  
# added

"Ocotea_whitei" 
# added

"Piper_schiedeanum"    
# added 

"Pachira_sessilis" # added 

"Prioria_copaifera"  # family Fabaceae:cae : Schizolobium, Senna,
Tachigali, Brownea, Cassia, Copaifera (#), Dialium, Hymenaea (#)
# added             

"Psychotria_hoffmannseggiana" 
# see Sedio (2012) in JEcol for Psychotria phylogeny
# added to Psychotria_acuminata


"Quararibea_asterolepis"   # family Bombacaceae: add to N73 (holds
Ceiba and Pseudobombax)
# added   

"Schefflera_morototoni"   # added to Dendropanax

"Simarouba_amara"   # family Simaroubacea: Picramnia, Quassia (#)
(both distantly related in phylogeny)
# added to Quassia                     

"Talisia_nervosa" # added

"Tetragastris_panamensis"  # family Burseraceae: Trattinnicki,
Bursera, Protium
# added to Protium

"Trichospermum_galeottii" # add to Apeiba
# added 

"Vismia_macrophylla" # added

"Xylopia_macrantha"  # family Annonaceae: Anaxagorea, Annona (#),
Desmopsis, Guatteria, Mosannona, Oxandra, Rollinia (#), Unonopsis
# find most closely related genus

"Xylosma_chlorantha" # added

#####

# make example how to add secies
bci.tree.nodes <- makeNodeLabel(drop.tip(bci.tree,
"Gnetum_leyboldii"), prefix = "N")

write.tree(bci.tree.nodes, file = "bci.tree.node.tre")

pdf("bci.tree.nodes.pdf", height = 25, width = 25)
plot(bci.tree.nodes, type = "f", cex = .6, show.node.label = TRUE)
dev.off()

###

bci.tree.node.OP <- read.tree("bci.tree.node.OP.tre")
pdf("bci.tree.node.OP.pdf", height = 25, width = 25)
plot(bci.tree.node.OP, type = "f", cex = .6, show.node.label = TRUE)
dev.off()


bci.data$bci.tree.node.OP <- bci.tree.node.OP

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))
load(paste(path.data, "bci.data.Rdata", sep = ""))

### load trait data

traits.abund <- read.table(paste(path.traits,
"Nadja_Traits/abun/demographic_traits_abun.txt", sep = ""), sep =
"\t")

rownames(traits.abund)[rownames(traits.abund)=="Appunia_seibertii"] <-
"Morinda_seibertii"

rownames(traits.abund)[which(rownames(traits.abund) %in%
bci.data$bci.tree.node.OP$tip.label == FALSE)]

# delete "Cyathea_petiolata"

traits.abund.wo.Cyathea <-
traits.abund[rownames(traits.abund)!="Cyathea_petiolata", ]
rownames(traits.abund.wo.Cyathea)[which(rownames(traits.abund.wo.Cyathea)
%in% bci.data$bci.tree.node.OP$tip.label == FALSE)]

bci.data$traits.abund.all <- traits.abund.wo.Cyathea

# match phylogeny to trait data:

mat <- match.phylo.comm(phy=bci.tree.node.OP, comm=t(bci.data$traits.abund.all))
mat$phy$edge.length <- mat$phy$edge.length+.1

bci.data$phy.308 <- mat$phy
bci.data$traits.abu.308 <- t(mat$comm)

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

## plot added species with different tip.color

names(bci.tree.node.OP)
ss <- bci.tree.node.OP$tip.label[c(1,3,5,7)]

ss <- c("Alchornea_costaricensis", "Apeiba_hybrid" ,
"Bactris_coloradonis", "Banara_guianensis", "Bertiera_guianensis",
"Cestrum_megalophyllum", "Colubrina_glandulosa",
"Colubrina_glandulosa", "Drypetes_standleyi","Ficus_colubrinae",
"Ficus_pertusa",
"Geonoma_interrupta","Inga_mucuna","Koanophyllon_wetmorei",
"Lacmellea_panamensis", "Pavonia_dasypetala", "Lycianthes_maxonii",
"Maclura_tinctoria", "Miconia_prasina" ,"Ocotea_whitei", 
"Piper_schiedeanum" ,"Pachira_sessilis", "Prioria_copaifera",
"Psychotria_hoffmannseggiana", "Quararibea_asterolepis",
"Schefflera_morototoni", "Simarouba_amara", "Talisia_nervosa",
"Tetragastris_panamensis", "Trichospermum_galeottii",
"Vismia_macrophylla", "Xylopia_macrantha", "Xylosma_chlorantha")

pdf("bci.tree.308.pdf", height = 25, width = 25)
plot(mat$phy, type = "f", cex = .9, show.node.label = TRUE,
tip.color=ifelse(mat$phy$tip.label %in% ss, "red","black"))
dev.off()


################################################
##### test for phylogenetic signal in traits ###
################################################

# decisions to be made:

# 1) which time intervall (90s, the later the better)

# 2) which species:
# (i) all which have values for a particular trait)
# (ii) those that for which all traits are available
# (iii) those species for which both, the niche and fitness trait are
available (maybe best compromise)

# 3) with and without measurement error: diff(c(2.3, 2.7))

# !!! 4) which traits to take? 

###############################

# variable names in trait data set:

###############
# recruitment #
###############

# abun.rec2 – Abundance in 1990

# rec.nr.mean2 – Measure of the number of recruits in the census
interval (1990-1995), posterior mean of constant a in log(number of
predicted recruits) = a + b * (log(light)-log(0.02)	
# rec.nr.cilow2 – lower limit of 95% credible interval of a
# rec.nr.ciup2 – upper limit of 95% credible interval of a

# rec.light.mean2 - Measure of the light dependence of recruitment in
the first census interval (1990-1995), posterior mean of slope b in
log(number of predicted recruits) = a + b * (log(light)+3.969)	
# rec.light.cilow2– lower limit of 95% credible interval of b 
# rec.light.ciup2 – upper limit of 95% credible interval of b 

#############
### growth ##
#############

# abun.growth2 – Abundance in 1990 (should be the same as for
recruitment)	

# growth.mean2 - Measure of growth at standardized conditions (5 cm
dbh and 5% light) in the census interval (1990-1995), posterior mean
of constant a in log(predicted_growth) = a + b *
(log(light)-log(0.05)) + c * (log(dbh)-log(50))
# growth.cilow2 – lower limit of 95% credible interval of a	
# growth.ciup2 – upper limit of 95% credible interval of a

# growth.light.mean2 - Measure of the light dependence of growth in
the census interval (1990-1995), posterior mean of slope b in
log(predicted_growth) = a + b * (log(light)-log(0.05)) + c *
(log(dbh)-log(50))	
# growth.light.cilow2 - lower limit of 95% credible interval of b	
# growth.light.ciup2 - upper limit of 95% credible interval of b

################
### mortality ##
################

# abun.mort2 – Abundance in 1990 (includes also trees that have died
during the interval, but only >20 away from edges, that doesn’t
matter)	

# intercept
# mort.mean2 - Measure of mortality at standardized conditions (5 cm
dbh and 5% light) in the census interval (1990-1995), posterior mean
of constant a in logistic regression m = 1/1+exp(-x);  x = a + b *
(log(light)-log(0.05)) + c * (log(dbh)-log(50)) + d * (dbh-50)
# mort.cilow2 – lower limit of 95% credible interval of a	
# mort.ciup2 – upper limit of 95% credible interval of a	

# slope
# mort.light.mean2 - Measure of the light dependence of mortality in
the first census interval (1990-1995), posterior mean of slope b in
above equation
# mort.light.cilow2 - lower limit of 95% credible interval of b	
# mort.light.ciup2 - upper limit of 95% credible interval of b

################
################


# i) for 1990-95 census (2nd period)
# a) test for signal in traits (mean demographic rate, with and
without measurement error) for all species

# rec90: "abun.rec2" ,"rec.nr.mean2", "rec.nr.cilow2", "rec.nr.ciup2"
,"rec.light.mean2", "rec.light.cilow2" "rec.light.ciup2"

colnames(t(mat$comm))

traits.abu.308 <- as.data.frame(t(mat$comm))

#  transform into numeric
traits.abu.308[,3:44] <- apply(traits.abu.308[,3:44], 2, as.numeric)

bci.data$traits.abu.308 <- traits.abu.308

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

mat <- matrix(nrow = 3, ncol = 2, c(1,1,NA, NA,1,1 ))
sum(mat, na.rm=T)

sum(mat)

##################################################
# data prep. for signal test in rec. (gro, mor) ##
##################################################

# colnames(bci.data$traits.abu.308)
 # [1] "sp"                  "species"             "abun.rec1"          
 # [4] "rec.nr.mean1"        "rec.nr.cilow1"       "rec.nr.ciup1"       
 # [7] "rec.light.mean1"     "rec.light.cilow1"    "rec.light.ciup1"    
# [10] "abun.rec2"           "rec.nr.mean2"        "rec.nr.cilow2"      
# [13] "rec.nr.ciup2"        "rec.light.mean2"     "rec.light.cilow2"   
# [16] "rec.light.ciup2"     "abun.growth1"        "growth.mean1"       
# [19] "growth.cilow1"       "growth.ciup1"       
"growth.light.mean1" 
# [22] "growth.light.cilow1" "growth.light.ciup1"  "abun.growth2"       
# [25] "growth.mean2"        "growth.cilow2"       "growth.ciup2"       
# [28] "growth.light.mean2"  "growth.light.cilow2"
"growth.light.ciup2" 
# [31] "abun.mort1"          "mort.mean1"          "mort.cilow1"        
# [34] "mort.ciup1"          "mort.light.mean1"    "mort.light.cilow1"  
# [37] "mort.light.ciup1"    "abun.mort2"          "mort.mean2"         
# [40] "mort.cilow2"         "mort.ciup2"          "mort.light.mean2"   
# [43] "mort.light.cilow2"   "mort.light.ciup2"   

###### growth
# b
###
rec90abu <- bci.data$traits.abu.308[,c(24,28:30)]
colnames(rec90abu)
rec90abu2 <- rec90abu[which(!is.na(rec90abu[,1])), ]
dim(rec90abu2)[1]
err.rec90 <- abs(apply(rec90abu2[,3:4], 1, diff))
rec90abu <- cbind(rec90abu2[,c(1,2)], err.rec90)
colnames(rec90abu)
mat2 <- match.phylo.comm(phy=mat$phy, comm=t(rec90abu))
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=t(mat2$comm)[,3], start=NULL, control=list())
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=t(mat2$comm)[,3], start=NULL, control=list())

###### mortality
# a
###
rec90abu <- bci.data$traits.abu.308[,c(38,39:41)]
colnames(rec90abu)
rec90abu2 <- rec90abu[which(!is.na(rec90abu[,1])), ]
dim(rec90abu2)[1]
err.rec90 <- abs(apply(rec90abu2[,3:4], 1, diff))
rec90abu <- cbind(rec90abu2[,c(1,2)], err.rec90)
colnames(rec90abu)
mat2 <- match.phylo.comm(phy=mat$phy, comm=t(rec90abu))
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=t(mat2$comm)[,3], start=NULL, control=list())
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=t(mat2$comm)[,3], start=NULL, control=list())

# b
###
rec90abu <- bci.data$traits.abu.308[,c(38,42:44)]
colnames(rec90abu)
rec90abu2 <- rec90abu[which(!is.na(rec90abu[,1])), ]
dim(rec90abu2)[1]
err.rec90 <- abs(apply(rec90abu2[,3:4], 1, diff))
rec90abu <- cbind(rec90abu2[,c(1,2)], err.rec90)
colnames(rec90abu)
mat2 <- match.phylo.comm(phy=mat$phy, comm=t(rec90abu))
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="K", test=TRUE, nsim=1000,
se=t(mat2$comm)[,3], start=NULL, control=list())
# sig. in abundance
phylosig(mat2$phy, t(mat2$comm)[,1], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w/0 error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=NULL, start=NULL, control=list())
# w error
phylosig(mat2$phy, t(mat2$comm)[,2], method="lambda", test=TRUE,
nsim=1000, se=t(mat2$comm)[,3], start=NULL, control=list())

#############################################
# b) test species for which we have all the traits, with and without
measurement error

rec90abu2 <- bci.data$traits.abu.308[which(!is.na(rec90abu[,1])), ]

traits.abu.all <-
bci.data$traits.abu.308[which(!is.na(rowSums(bci.data$traits.abu.308[,3:44]))),]

bci.data$traits.abu.all <- traits.abu.all
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

res <- NA 
for (i in c(11,14,25,28,39,42)){
    rec90abu <- bci.data$traits.abu.all[,c(i:c(i+2))]
    colnames(rec90abu)
    error<- abs(apply(rec90abu[,2:3], 1, diff))
    rec90abu2 <- cbind(rec90abu[,1], error)
    colnames(rec90abu2) <- c(colnames(rec90abu)[1], paste("err",
colnames(rec90abu)[1], sep = "."))
    res <- cbind(res, rec90abu2)
    res
}

# add abundance column
res[,1] <- bci.data$traits.abu.all[,10]
colnames(res)[1] <- colnames(bci.data$traits.abu.all)[10]

bci.data$traits.abu.all.err <- res


MultiK<- function(tre, traits){
require(phytools)
mat <- matrix(NA, ncol = 2, nrow = dim(traits)[2])
colnames(mat) <- c("K","P")
rownames(mat) <- colnames(traits)
for (i in 1:dim(traits)[2]){
    x <- phylosig(tre, traits[tre$tip.label,i], method="K", test=TRUE,
nsim=1000)
    mat[i,] <- round(as.numeric(x), 3)
  }
    mat
}

mat2 <- match.phylo.comm(phy=mat$phy, comm=t(res))

multk <- MultiK(bci.data$phy206, bci.data$traits.pca[,c(16,18)])
multk

write.csv(multk, file = "multk.csv")


MultiLambda <- function(tre, traits){
require(phytools)
mat <- matrix(NA, ncol = 4, nrow = dim(traits)[2])
colnames(mat) <- c("lambda","logL","logL0","P")
rownames(mat) <- colnames(traits)
for (i in 1:dim(traits)[2]){
    x <- phylosig(tre, traits[tre$tip.label,i], method="lambda",
test=TRUE)
    mat[i,] <- round(as.numeric(x), 3)
  }
    mat
}

multlam <- MultiLambda(mat2$phy,
t(mat2$comm)[,c(1,2,4,6,8,10,12,14:19)])
multlam
write.csv(multlam, file = "multlam.csv")

## re-run taking measurement error into account
#    rewrite function to include measurement error

## !!! runs for 1h for 7 traits <- run over lunch
MultiKerror<- function(tre, traits, error){
require(phytools)
mat <- matrix(NA, ncol = 4, nrow = dim(traits)[2])
colnames(mat) <- c("K","P","sig2","logL")
rownames(mat) <- colnames(traits)
for (i in 1:dim(traits)[2]){
    x <- phylosig(tre, traits[tre$tip.label,i], method="K",
se=error[tre$tip.label,i], test=TRUE, nsim=1000)
    mat[i,] <- round(as.numeric(x), 3)
  }
    mat
}

# !! run over lunch  
multkerr <- MultiKerror(bci.data$phy206,
bci.data$traits.pca[,c(2,4,6,8,10,12)],
error=bci.data$traits.pca[,c(3,5,7,9,11,13)])

multkerr
write.csv(multkerr, file = "multkerr.csv")

## run for PCs including error based on PCAs on the errors
multkerr <- MultiKerror(bci.data$phy206,
bci.data$traits.pca[,c(14:19)], error=bci.data$traits.pca[,c(20:25)])
multkerr

### run lambda for common trait set (206 species)

#colnames(t(mat2$comm))
# [1] "abun.rec2"              "rec.nr.mean2"          
"err.rec.nr.mean2"      
# [4] "rec.light.mean2"        "err.rec.light.mean2"    "growth.mean2"          
# [7] "err.growth.mean2"       "growth.light.mean2"    
"err.growth.light.mean2"
#[10] "mort.mean2"             "err.mort.mean2"        
"mort.light.mean2"      
#[13] "err.mort.light.mean2" 

phylosig(mat2$phy, t(mat2$comm)[,12], method="lambda", test=TRUE,
nsim=1000, se=t(mat2$comm)[,13], start=NULL, control=list())

#############################################################################
## plot abundance + 6 traits + 6 measurement error (n=13) on the
phylogeny ##
#############################################################################

comm2 <- t(mat2$comm)
comm2[,1] <- comm2[,1]^.25
    
herb <- phylo4d(mat2$phy, comm2)

pdf("BCI.traits.phylo.pdf", width = 12, height = 20)
# postscript(file = "BCI.traits.phylo.eps",width = 12, height = 20,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
phytab <- table.phylo4d(herb, treetype="phylogram", show.node.label=F,
box=F, ratio.tree=1/3, font=3, cex.label=.5, cex.symbol=1.2,
cex.legend = .8)
dev.off()

########################
# test correlations between variables:
traits.err <- t(mat2$comm)
colnames(traits.err) <-
c("abun","rec.a","err.rec.a","rec.b","err.rec.b","gro.a","err.gro.a","gro.b","err.gro.b","mor.a","err.mor.a","mor.b","err.mor.b")

# [1] "abun.rec2"              "rec.nr.mean2"          
"err.rec.nr.mean2"      
# [4] "rec.light.mean2"        "err.rec.light.mean2"    "growth.mean2"          
# [7] "err.growth.mean2"       "growth.light.mean2"    
"err.growth.light.mean2"
#[10] "mort.mean2"             "err.mort.mean2"        
"mort.light.mean2"      
#[13] "err.mort.light.mean2" 

pdf("Cor.traits.pdf", width = 15, height = 15)
CorTestPlot(traits.err)
dev.off()

#########################################################################
# run PCA on all traits to see trait correlations and amount of
variation explained
#########################################################################

########### all variables

pca.traits.all <- rda(traits.err[,c(2,4,6,8,10,12)], scale = T)
summary(pca.traits.all)

#Importance of components:
#                        PC1    PC2    PC3     PC4     PC5     PC6
#Eigenvalue            3.330 0.9728 0.7580 0.41529 0.27530 0.24864
#Proportion Explained  0.555 0.1621 0.1263 0.06921 0.04588 0.04144
#Cumulative Proportion 0.555 0.7171 0.8435 0.91268 0.95856 1.00000

pdf("pca.traits.all.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.all, type = "none", xlim = c(-2.5,2.5),
ylim=c(-1.5,1))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.all)
identify(fig, "sit")

pdf("pca.traits.all.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.all, bstick = TRUE, "lines")
dev.off()

############## for intercepts (a) -- fitness

pca.traits.a <- rda(traits.err[,c(2,6,10)], scale = T)
summary(pca.traits.a)

#Importance of components:
#                         PC1    PC2    PC3
#Eigenvalue            1.5533 0.7999 0.6468
#Proportion Explained  0.5178 0.2666 0.2156
#Cumulative Proportion 0.5178 0.7844 1.0000

pdf("pca.traits.a.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.a, type = "none", xlim = c(-2.5,2),
ylim=c(-1,2.3))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.a)
identify(fig, "sit")

pdf("pca.traits.a.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.a, bstick = TRUE, "lines")
dev.off()

################ for slopes (b) -- niche

pca.traits.b <- rda(traits.err[,c(4,8,12)], scale = T)
summary(pca.traits.b)

#Importance of components:
#                        PC1    PC2    PC3
#Eigenvalue            2.166 0.4510 0.3830
#Proportion Explained  0.722 0.1503 0.1277
#Cumulative Proportion 0.722 0.8723 1.0000

pdf("pca.traits.b.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.b, type = "none", xlim = c(-2.5,2.5),
ylim=c(-1.8,1))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.b)
identify(fig, "sit")

pdf("pca.traits.b.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.b, bstick = TRUE, "lines")
dev.off()

############################################
### PCA based on errors
############################################

pca.traits.all.err <- rda(bci.data$traits.pca[,c(3,5,7,9,11,13)],
scale = T)
summary(pca.traits.all.err)

##Importance of components:
#                         PC1     PC2     PC3     PC4     PC5     PC6
#Eigenvalue            5.1011 0.40994 0.22849 0.18748 0.04349 0.02946
#Proportion Explained  0.8502 0.06832 0.03808 0.03125 0.00725 0.00491
#Cumulative Proportion 0.8502 0.91851 0.95660 0.98784 0.99509 1.00000

pdf("pca.traits.all.err.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.all.err, type = "none", xlim = c(-2.5,2.5),
ylim=c(-1.5,1))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.all.err)
identify(fig, "sit")

pdf("pca.traits.all.err.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.all.err, bstick = TRUE, "lines")
dev.off()


############## for intercepts (a) -- fitness

pca.traits.a.err <- rda(bci.data$traits.pca[,c(3,7,11)], scale = T)
summary(pca.traits.a.err)

#Importance of components:
#                         PC1     PC2     PC3
#Eigenvalue            2.6125 0.23869 0.14886
#Proportion Explained  0.8708 0.07956 0.04962
#Cumulative Proportion 0.8708 0.95038 1.00000

pdf("pca.traits.a.err.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.a.err, type = "none", xlim = c(-2.5,2),
ylim=c(-1,2.3))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.a.err)
identify(fig, "sit")

pdf("pca.traits.a.err.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.a.err, bstick = TRUE, "lines")
dev.off()

################ for slopes (b) -- niche

pca.traits.b.err <- rda(bci.data$traits.pca[,c(5,9,13)], scale = T)
summary(pca.traits.b.err)

#                        PC1     PC2     PC3
#Eigenvalue            2.691 0.17571 0.13324
#Proportion Explained  0.897 0.05857 0.04441
#Cumulative Proportion 0.897 0.95559 1.00000

pdf("pca.traits.b.err.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.b.err, type = "none", xlim = c(-2.5,2.5),
ylim=c(-1.8,1))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()
  
fig <- ordiplot(pca.traits.b.err)
identify(fig, "sit")

pdf("pca.traits.b.err.scree.pdf", width = 5, height = 5)
screeplot(pca.traits.b.err, bstick = TRUE, "lines")
dev.off()

###################################

# cbind PCs based on errors
bci.data$traits.pca <- cbind(bci.data$traits.pca,
pca.traits.all.err$CA$u[,1:2], pca.traits.a.err$CA$u[,1:2],
pca.traits.b.err$CA$u[,1:2])
colnames(bci.data$traits.pca)[20:25] <-
c("PC1.All.err","PC2.All.err","PC1.Fit.err","PC2.Fit.err","PC1.Nich.err","PC2.Nich.err")

######################################################################

###################################
# phylogentic signal of all traits (n=6), PCs for all, niche and
fitness traits 

traits.pca <- cbind(traits.err,pca.traits.all$CA$u[,1:2],
pca.traits.a$CA$u[,1:2], pca.traits.b$CA$u[,1:2])

colnames(traits.pca)[14:19] <-
c("PC1.All","PC2.All","PC1.Fit","PC2.Fit","PC1.Nich","PC2.Nich")

bci.data$traits.pca <- traits.pca
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

multkpca <- MultiK(mat2$phy,
bci.data$traits.pca[,c(2,4,6,8,10,12,14:19)])
multkpca
write.csv(multkpca, file = "multkpca.csv")


multlampca <- MultiLambda(mat2$phy,
bci.data$traits.pca[,c(2,4,6,8,10,12,14:19)])
multlampca
write.csv(multlampca, file = "multlampca.csv")


######################################################################
# plot traits + PCs on phylogeny
######################################################################

herb <- phylo4d(mat2$phy,
bci.data$traits.pca[,c(2,4,6,8,10,12,14:19)])

pdf("BCI.traits.pca.phylo.pdf", width = 12, height = 20)
# postscript(file = "BCI.traits.phylo.eps",width = 12, height = 20,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
phytab <- table.phylo4d(herb, treetype="phylogram", show.node.label=F,
box=F, ratio.tree=1/3, font=3, cex.label=.5, cex.symbol=1.2,
cex.legend = .8)
dev.off()

######################################################################
# correlations between traits + PCs
######################################################################

pdf("Cor.traits.pca.pdf", width = 15, height = 15)
CorTestPlot(bci.data$traits.pca[,c(2,4,6,8,10,12,14:19)])
dev.off()

####################################
# prepare for nodewise signal test #
####################################

par(mfrow=c(4,3))
for (i in c(2,4,6,8,10,12,14:19)){
hist(bci.data$traits.pca[,i], main = colnames(bci.data$traits.pca)[i])
}

# all trait are nicely normaly distributed

# scale trait data 
traits.pca.scale <- scale(traits.pca)

writetraits(traits.pca.scale[,c(1,2,4,6,8,10,12,14,16,18)], file =
"traits", bin = NULL, sigd = 3)
write.tree(mat2$phy, file = "phylo")

divergence.bci <- read.csv("divergence.bci.csv", dec = ",", sep =
"\t")

##
###########
# Divergence size (Tsd)
###########

div <- xyplot(Tsd.rankLow ~ age, groups=trait.name, data =
divergence.bci, type = "smooth", xlim = c(0, 135), ylim = c(-25,
1050), lty = c(1,2,3,4,5,1,2,3,4,5), par.settings = list(axis.line =
list(col = 0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right
axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Observed divergence size (Rank)",
key=list(space="inside",  between = 1, padding.text = 2, just = c(.7,
.5), columns = 2, lines = list(lty = c(1,2,3,4,5,1,2,3,4,5), lwd =
1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci$trait.name))))
plot(div)

pdf(file = "BCI.DivergenceSize.pdf",width = 6, height = 6.5,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

##
###########
# Divergence deviation (Nsd)
###########

div <- xyplot(Nsd.rankLow ~ age, groups=trait.name, data =
divergence.bci, type = "smooth", xlim = c(0, 135), ylim = c(-25,
1050), lty = c(1,2,3,4,5,1,2,3,4,5), par.settings = list(axis.line =
list(col = 0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right
axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Observed divergence deviation (Nsd,
Rank)", key=list(space="inside",  between = 1, padding.text = 2, just
= c(.7, .5), columns = 2, lines = list(lty = c(1,2,3,4,5,1,2,3,4,5),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci$trait.name))))
plot(div)

pdf(file = "BCI.DivergenceDev.pdf",width = 6, height = 6.5,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()
######################################################################

###########
# Tip.mn
###########

div <- xyplot(Tip.mn ~ age, groups=trait.name, data = divergence.bci,
type = "smooth", xlim = c(0, 135), ylim = c(-.5, .5), lty =
c(1,2,3,4,5,1,2,3,4,5), par.settings = list(axis.line = list(col =
0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Trait mean value",
key=list(space="inside",  between = 1, padding.text = 2, just = c(.7,
.5), columns = 2, lines = list(lty = c(1,2,3,4,5,1,2,3,4,5), lwd =
1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci$trait.name))))
plot(div)

pdf(file = "BCI.Tip.mn.pdf",width = 6, height = 6.5, pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()


######################################################################

###########
# ContributionIndex 
###########

div <- xyplot(ContributionIndex ~ age, groups=trait.name, data =
divergence.bci, type = "smooth", xlim = c(0, 135), ylim = c(0, .03),
lty = c(1,2,3,4,5,1,2,3,4,5), par.settings = list(axis.line = list(col
= 0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Contribution of divergence to overall
trait variation", key=list(space="inside",  between = 1, padding.text
= 2, just = c(.7, .5), columns = 2, lines = list(lty =
c(1,2,3,4,5,1,2,3,4,5), lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci$trait.name))))
plot(div)

pdf(file = "BCI.ContributionIndex.pdf",width = 6, height = 6.5,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()


###########
# percVarAtNode
###########

div <- xyplot(percVarAtNode ~ age, groups=trait.name, data =
divergence.bci, type = "smooth", xlim = c(0, 135), ylim = c(-.02, .4),
lty = c(1,2,3,4,5,1,2,3,4,5), par.settings = list(axis.line = list(col
= 0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Total trait variance at node (%)",
key=list(space="inside",  between = 1, padding.text = 2, just = c(.7,
.5), columns = 2, lines = list(lty = c(1,2,3,4,5,1,2,3,4,5), lwd =
1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci$trait.name))))
plot(div)

pdf(file = "Tot.trait.var.node.pdf",width = 6, height = 6.5,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

divergence.bci$percVarAtNode[]

######################################################################
###########
# percVarAmongNodes
###########

# substitute NA values
divergence.bci2 <- divergence.bci
divergence.bci2$percVarAmongNodes[which(is.na(divergence.bci$percVarAmongNodes))]
<- mean(divergence.bci$percVarAmongNodes, na.rm=T)

div <- xyplot(percVarAmongNodes ~ age, groups=trait.name, data =
divergence.bci2, type = "smooth", xlim = c(-10, 135), ylim =
c(-.2,1.5), lty = c(1,2,3,4,5,1,2,3,4,5), par.settings =
list(axis.line = list(col = 0)),scales=list(col=1,tck=c(-1,0)),  #
remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 2.5)
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey"),
xlab = "Time (Myr)", ylab = "Total trait variance within clade (%)",
key=list(space="inside",  between = 1, padding.text = 2, just = c(.7,
.5), columns = 2, lines = list(lty = c(1,2,3,4,5,1,2,3,4,5), lwd =
1.5, col =
c("black","black","black","black","black","darkgrey","darkgrey","darkgrey","darkgrey","darkgrey")),text
= list(levels(divergence.bci2$trait.name))))
plot(div)

pdf(file = "Tot.clade.level.trait.var.node.pdf",width = 6, height =
6.5, pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

######################################################################
## plot niche differences vs. fitness differences
######################################################################
# ? how can we plot niche vs.fitness differences
# ? do we have to scale data and if yes, at which stage?

plot(scale(dist(bci.data$traits.pca[,16])),scale(dist(bci.data$traits.pca[,18])))
plot(dist(bci.data$traits.pca[,16]),dist(bci.data$traits.pca[,18]))
plot(dist(scale(bci.data$traits.pca[,16])),dist(scale(bci.data$traits.pca[,18])))

# create matrix that contains distance vectors:

vec2dist2vec <- function(x){
    res <- NA
    for (i in 1:dim(x)[2]){
        distvec <- dist(x[,i])
            res <- cbind(res, distvec)
    }
    res <- res[,-1]
    colnames(res) <- colnames(x)
    res
}

distvec.traits <- vec2dist2vec(bci.data$traits.pca)

distvec.traits.phy <- cbind(distvec.traits,
as.dist(cophenetic(mat2$phy)))
colnames(distvec.traits.phy)[20] <- "phy.dist"

bci.data$distvec.traits.phy <- distvec.traits.phy
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))


###############################################################

# contour plot
require(stats)
attach(as.data.frame(distvec.traits.phy.scaled))

phylodistance <- loess(phy.dist ~ PC1.Nich*PC1.Fit, span = 1, degree =
2) # try additive effect

n.marginal <- seq(min(PC1.Nich), max(PC1.Nich), length.out = 50)
f.marginal <- seq(min(PC1.Fit), max(PC1.Fit), length.out = 50)

nf.marginal <- list(PC1.Nich = n.marginal, PC1.Fit = f.marginal)

grid <- expand.grid(nf.marginal)

grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "PhyloPC1nichePC1fitness.dots.pdf",width = 6, height = 5.5,
pointsize=12)

contourplot(fit ~ PC1.Nich * PC1.Fit, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phylogenetic distance ~ PC1.Nich*PC1.Fit",
            panel=function(...){
            panel.contourplot(...)
            grid.points(PC1.Nich, PC1.Fit, pch=1, size=unit(.2,
"char"))
          })

dev.off()


################# try whith single traits
# later: try with scaled data

colnames(distvec.traits.phy)

distvec.traits.phy.scaled <- scale(distvec.traits.phy)
attach(as.data.frame(distvec.traits.phy.scaled))

phylodistance <- loess(phy.dist ~ rec.b * gro.a, span = 1, degree = 2)

n.marginal <- seq(min(rec.b), max(rec.b), length.out = 50)
f.marginal <- seq(min(gro.a), max(gro.a), length.out = 50)

nf.marginal <- list(rec.b = n.marginal, gro.a = f.marginal)

grid <- expand.grid(nf.marginal)

grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "PhyloRec.b.Gro.a.fitness.pdf",width = 6, height = 5.5,
pointsize=12)
contourplot(fit ~ rec.b * gro.a, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phylogenetic distance ~ rec.b*gro.a")
dev.off()

detach()

## next steps:

# only predict z-values within the occupied parameter space (see
harrell)
# plot pure z-variable (phylodist) against niche and fitness
differences instead of predicting z-surface
# test for phylogenetic signal in niche and fitness differences
(mantel test)
# test for phylogenetic depth of signal in niche vs. fitness
differences


## mantel test
lmp(phy.dist ~ rec.b, data = as.data.frame(distvec.traits.phy))

betadist <- vec2dist(distvec.traits.phy, mat2$comm)

vec2dist <- function(betavec, com){
  mat <- matrix(NA, nrow = dim(com)[1], ncol = dim(com)[1])
  rownames(mat) <- rownames(com) 
  colnames(mat) <- rownames(com) 
  d <- as.dist(mat)
  for (i in 1:length(betavec)){
      d[i] <- betavec[i]
    }
  d
}


######################################################################

# analysis of species co-occurrence

grid20.90 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells20_1990.txt", sep
= ""), sep = "\t")
dim(grid20.90)
# 1250 grid cells and 305 species

# match grid data to trait data
colnames(grid20.90)[which(colnames(grid20.90) %in%
bci.data$traits.abu.all$sp == FALSE)]

as.character(bci.data$traits.abu.all$sp)[which(as.character(bci.data$traits.abu.all$sp)
%in% colnames(grid20.90) == FALSE)]

bci.data$traits.abu.all$sp <- as.character(bci.data$traits.abu.all$sp)

grid20.90.206 <- grid20.90[, which(colnames(grid20.90) %in%
bci.data$traits.abu.all$sp)]

# assign full species names to grid-data
# reorder short names according to trait data
grid20.90.206.new <- grid20.90.206[, bci.data$traits.abu.all$sp]
# give full names to gridded data
colnames(grid20.90.206.new) <- rownames(bci.data$traits.abu.all)

mat <- match.phylo.comm(phy = bci.data$phy.308, comm =
grid20.90.206.new)

bci.data$phy206 <- mat$phy
bci.data$grid20.90.206 <- mat$comm
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

# test for correlation between species co-occurrence and phylogenetic
distance

species.dist(bci.data$grid20.90.206[,1:10], metric = "cij")

coocc.phylo <- comm.phylo.cor(bci.data$grid20.90.206, bci.data$phy206,
metric="check",null.model="sample.taxa.labels")
str(coocc.phylo)

# never significant, slightly significant for doij
pdf("test")
coocc.phylo.qr <- comm.phylo.qr(bci.data$grid20.90.206,
bci.data$phy206, metric="check",null.model="sample.taxa.labels",
show.plot = TRUE)
dev.off()
str(coocc.phylo.qr)

abline(coocc.phylo.qr$results$obs.qr.intercept, results$obs.qr.slope)
legend("topleft", paste("q", as.character(quant), sep = ""))

#$obs.qr.intercept
#[1] 1.250155
#
#$obs.qr.slope
#[1] 0.001246724
#
#$obs.qr.slope.p
#[1] 0.715
#
#$obs.rank
#[1] 715
#
#$runs
#[1] 999
# never significant

# check wether randomization test from "coocc.phylo" gives results
identical to those obtained from a mantel-test
mantel(coocc.check, as.dist(cophenetic(bci.data$phy206)))
# gives similar results
plot(coocc.check, as.dist(cophenetic(bci.data$phy206)))


# create species co-occurrence vector

coocc.cij <- species.dist(bci.data$grid20.90.206, metric = "cij")
coocc.cij.pa <- species.dist(decostand(bci.data$grid20.90.206, "pa"),
metric = "cij")
coocc.check <- species.dist(bci.data$grid20.90.206, metric =
"checkerboard")
coocc.doij <- species.dist(bci.data$grid20.90.206, metric = "doij")

distvec.traits.phy.coocc <- cbind(bci.data$distvec.traits.phy,
coocc.cij, coocc.check, coocc.doij)

bci.data$distvec.traits.phy.cooc <-
cbind(bci.data$distvec.traits.phy.cooc, coocc.cij.pa)

bci.data$distvec.traits.phy.coocc <- distvec.traits.phy.coocc
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

########################
# another test for co-occurrence: species regressions (Helmus, 2007)

spec.reg.abu <- sppregs(bci.data$grid20.90.206, env=NULL,
tree=bci.data$phy206, fam="gaussian")
    

coocc.cscore.norm <- as.vector(C.score(bci.data$grid20.90.206,
normalise=T, FUN=print))
coocc.cscore <- as.vector(C.score(bci.data$grid20.90.206, normalise=F,
FUN=print))

bci.data$distvec.traits.phy.cooc <-
cbind(bci.data$distvec.traits.phy.cooc, coocc.cscore,
coocc.cscore.norm)

bci.data$distvec.traits.phy.cooc <- bci.data$distvec.traits.phy.cooc[,
-c(33:34)]

#########################################################################################
### calculated species niche and fitness differences but based on all
six traits, and all three niche traits and fitness traits,
respectively 
# a) based on distances from the standardized trait data
# b) based on distances from a pca on the standardized trait data

colnames(bci.data$traits.pca)

# a) based on distances from the standardized trait data

# all
trait.all.stand <- scale(bci.data$traits.pca[,c(2,4,6,8,10,12)])
colnames(trait.all.stand)
trait.all.stand.distvec <- as.vector(dist(trait.all.stand))

# niche
trait.nich.stand <- scale(bci.data$traits.pca[,c(4,8,12)])
colnames(trait.nich.stand)
trait.nich.stand.distvec <- as.vector(dist(trait.nich.stand))

# fitness
trait.fit.stand <- scale(bci.data$traits.pca[,c(2,6,10)])
colnames(trait.fit.stand)
trait.fit.stand.distvec <- as.vector(dist(trait.fit.stand))


# b) based on distances from a pca on the standardized trait data

pc.all.stand.distvec <- as.vector(pca.traits.all.euclid)
pc.nich.stand.distvec <- as.vector(pca.traits.b.euclid)
pc.fit.stand.distvec <- as.vector(pca.traits.a.euclid)


# cbind with bci.data:

distvec.traits.phy.coocc <- cbind(bci.data$distvec.traits.phy.coocc,
trait.all.stand.distvec, trait.nich.stand.distvec,
trait.fit.stand.distvec, pc.all.stand.distvec, pc.nich.stand.distvec,
pc.fit.stand.distvec)

bci.data$distvec.traits.phy.coocc <- distvec.traits.phy.coocc
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

#########################################################################################

# contour plot

distvec.traits.phy.scaled <- scale(bci.data$distvec.traits.phy.coocc)

detach(as.data.frame(distvec.traits.phy.scaled))

phylodistance <- loess(coocc.check ~ rec.b * gro.a, span = 1, degree =
2)

n.marginal <- seq(min(rec.b), max(rec.b), length.out = 50)
f.marginal <- seq(min(gro.a), max(gro.a), length.out = 50)
nf.marginal <- list(rec.b = n.marginal, gro.a = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "Coocc.check.Rec.b.Gro.a.fitness.pdf",width = 6, height =
5.5, pointsize=12)
contourplot(fit ~ rec.b * gro.a, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Co-occurrence_Check ~ rec.b*gro.a")
dev.off()

detach()

######################

detach(as.data.frame(bci.data$distvec.traits.phy.coocc))

# use standard settings: span = .66, degree = 1 (check literature why
this is good)

phylodistance <- loess(coocc.cij ~ pc.nich.stand.distvec *
pc.fit.stand.distvec, span = 1, degree = 1)

n.marginal <- seq(min(pc.nich.stand.distvec),
max(pc.nich.stand.distvec), length.out = 50)
f.marginal <- seq(min(pc.fit.stand.distvec),
max(pc.fit.stand.distvec), length.out = 50)
nf.marginal <- list(pc.nich.stand.distvec = n.marginal,
pc.fit.stand.distvec = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
#pdf(file = "phy.dist.pc.nich.fit.pdf",width = 6, height = 5.5,
pointsize=12)

pdf(file =
"phy.dist.pc.nich.stand.distvec.pc.fit.stand.distvec.pdf",width = 6,
height = 5.5, pointsize=12)

contourplot(fit ~ pc.nich.stand.distvec * pc.fit.stand.distvec, data =
grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "phy.dist ~ pc.nich.stand.distvec *
pc.fit.stand.distvec"
            #,          panel=function(...){
            #panel.contourplot(...)
            #grid.points(rec.b, gro.a, pch=1, size=unit(.2, "char"))
          #}
            )

dev.off()

detach()

# result: it seems that fitness differences seem to be more important
for co-existence (at least for Schoener's cij)
                                        # also, abundance based cij
gives similar results as
presence-absence-based cij
## # for "check", both fitness and niche appear to be important BUT
test
whether niche differences really are as important as fitness
differences; as we might make an argument that in our system niche
differences are less important for co-occurrence than fitness
# differences




##################################################################################
## test for correlation between co-occurrence and niche and fitness
differences ##
##################################################################################

# first run cortest plot for all pairwise measures:
#
pdf(file = "CorTestPlotPairwise.pdf",width = 15, height = 15,
pointsize=12)
CorTestPlot(bci.data$distvec.traits.phy.coocc[,c(2,4,6,8,10,12,14,16,18,20:23)])
dev.off()

##################################################################################
                                    
# use lmp to test (randomization-based) interactions                                        
path.data <-
"/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/"
load(paste(path.data, "bci.data.Rdata", sep = ""))

library(lmPerm)

####################################
# for phylogenetic distance
####################################

# based on randomizations, but only possible for a subset of data

# try testing on 17500 random points:
randvec <- sample(c(1:21115), 17500)

mod <- lmp(phy.dist ~ PC1.Fit * PC1.Nich, data =
as.data.frame(scale(bci.data$distvec.traits.phy.coocc[randvec,])))                   
summary(mod) 
gc()

#                                             Estimate Iter Pr(Prob)    
#pc.fit.stand.distvec                        0.0355886 5000   <2e-16
***
#pc.nich.stand.distvec                       0.0009085   51        1    
#pc.fit.stand.distvec:pc.nich.stand.distvec -0.0128176 5000   <2e-16
***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 0.9994 on 17496 degrees of freedom
#Multiple R-Squared: 0.00134,	Adjusted R-squared: 0.001168 
#F-statistic: 7.823 on 3 and 17496 DF,  p-value: 3.246e-05 


###

# try different co-occurrence indices:

doij <- species.dist(phylocom$sample, "doij")
cij <- species.dist(phylocom$sample, "cij")
check <- species.dist(phylocom$sample, "check")
cor.test(1-doij, check)

###########################
# based on parametric testing, but for the full dataset


randvec <- sample(c(1:21115), 17500)

mod <- lm(phy.dist ~ PC1.Fit * PC1.Nich, data =
as.data.frame(scale(bci.data$distvec.traits.phy.coocc[randvec,])))                                   
summary(mod) 

## using interaction as response

#mod <- lm(PC1.Fit * PC1.Nich ~ phy.dist, data =
as.data.frame(scale(bci.data$distvec.traits.phy#.coocc[randvec,])))                                   
#summary(mod) 

# yes, phy.dist significantly explained the interaction between niche
and fitness differences


#                                            Estimate Std. Error t
value
#(Intercept)                                 0.003392   0.007153  
0.474
#pc.fit.stand.distvec                        0.031734   0.007227  
4.391
#pc.nich.stand.distvec                       0.005891   0.007180  
0.820
#pc.fit.stand.distvec:pc.nich.stand.distvec -0.011842   0.006854 
-1.728
#                                           Pr(>|t|)    
#(Intercept)                                   0.635    
#pc.fit.stand.distvec                       1.13e-05 ***
#pc.nich.stand.distvec                         0.412    
#pc.fit.stand.distvec:pc.nich.stand.distvec    0.084 .  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 0.9995 on 21111 degrees of freedom
#Multiple R-squared:  0.00119,	Adjusted R-squared:  0.001048 
#F-statistic: 8.385 on 3 and 21111 DF,  p-value: 1.442e-05


##########################################################
## general result: phylogenetic relatedness appears to be determined
by fitness, but not niche, differences, with phylogenetic distance
increasing with increasing fitness differences.
# phylogenetic differ
# do to: randomization test on the full data set (so far only tested
with parametric testing on the full data set.)
###########################################################


####################################
#### for co-occurrence
####################################

# based on randomizations, but only possible for a subset of data

# try testing on 17500 random points:
randvec <- sample(c(1:21115), 17500)

mod <- lmp(coocc.check ~ PC1.Fit * PC1.Nich, data =
as.data.frame(scale(bci.data$distvec.traits.phy.coocc[,])))                                   
summary(mod) 
gc()

# 

#                 Estimate Iter Pr(Prob)    
#PC1.Fit          -0.19024 5000   <2e-16 ***
#PC1.Nich          0.04694 5000   <2e-16 ***
#PC1.Fit:PC1.Nich -0.03243 5000   <2e-16 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 0.9826 on 17496 degrees of freedom
#Multiple R-Squared: 0.03475,	Adjusted R-squared: 0.03458 
#F-statistic:   210 on 3 and 17496 DF,  p-value: < 2.2e-16 


###
# based on parametric testing, but for the full dataset

mod <- lm(coocc.check ~ pc.fit.stand.distvec * pc.nich.stand.distvec,
data = as.data.frame(scale(bci.data$distvec.traits.phy.coocc[,])))                                   
summary(mod)  

#                                            Estimate Std. Error t
value
#(Intercept)                                 0.005999   0.007093  
0.846
#pc.fit.stand.distvec                       -0.128056   0.007167
-17.869
#pc.nich.stand.distvec                       0.079269   0.007120 
11.133
#pc.fit.stand.distvec:pc.nich.stand.distvec -0.020942   0.006796 
-3.081
#                                           Pr(>|t|)    
#(Intercept)                                 0.39768    
#pc.fit.stand.distvec                        < 2e-16 ***
#pc.nich.stand.distvec                       < 2e-16 ***
#pc.fit.stand.distvec:pc.nich.stand.distvec  0.00206 ** 
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#
#Residual standard error: 0.9911 on 21111 degrees of freedom
#Multiple R-squared:  0.01782,	Adjusted R-squared:  0.01768 
#F-statistic: 127.6 on 3 and 21111 DF,  p-value: < 2.2e-16


# general result: 
# all three parameters are significant, irrespective of whether niche
and fitness differences are based on PC1 or all three PCs

############################################
# try regression on distance matrices 
############################################

library(ecodist)

data(graze)
LOAR10.mrm <- MRM(dist(LOAR10) ~ dist(sitelocation) + dist(forestpct)
+ I(dist(sitelocation)*dist(forestpct)), data=graze, nperm=100)
(LOAR10.mrm)

####################################
# calculate community phylogenetic and functional structure
####################################

library(spacodiR)

# value: 3 - Bst, 4 - PIst


com = t(bci.data$grid20.90.206)
phy=bci.data$phy206
value=3
nullmod="taxaShuffle"
runs=3


spa.PD.step5 <- function(com, phy, value, nullmod, runs){
results <- matrix(NA, nrow = 1, ncol = 8)
pairwise <- list("Pairwise") # list because it should hold objects of
varying length
names(pairwise) <- c("Pairwise")
PI.shuff <- function(com, runs){
  Res = NA
  for (r in 1:runs) {      
    Res <- c(Res, spacodi.calc(sp.plot = com, phy =
eval(parse(text=nullmod))(cophenetic(phy)), prune = FALSE, pairwise =
TRUE)[[value]]) 
  }
  return(Res)
}
  obs <- spacodi.calc(sp.plot = com, phy = cophenetic(phy), prune =
FALSE, pairwise = TRUE) # single obsversed PIst value  
  obs.val <- obs[[value]]

   resamp <- PI.shuff(com = com, runs = runs) 
  resamp[1] <- obs.val
  obs.rank <- rank(resamp)[1]
results[1,1] <- obs.val
results[1,2] <- mean(resamp[2:(runs+1)], na.rm = TRUE)
results[1,3] <- sd(resamp[2:(runs+1)], na.rm = TRUE)
results[1,4] <- quantile(resamp[2:(runs+1)], na.rm = TRUE,  probs =
c(2.5, 97.5)/100)[1]
results[1,5] <- quantile(resamp[2:(runs+1)], na.rm = TRUE,  probs =
c(2.5, 97.5)/100)[2]
results[1,6] <- obs.rank/(runs+1) ## P(1-sided test, H1: obs<exp)
results[1,7] <- 1-(obs.rank/(runs+1)) ## P(1-sided test, H1: obs>exp)
results[1,8] <- (1-(obs.rank/(runs+1)))*2 ## P(2-sided test, H1:
obs<>exp)
dimnames(results) <- list(c("stats"),
c(names(obs)[value],"rand.mean","rand.sd","2.5%","97.5%","P.obs<exp","P.obs>exp","P.obs<>exp"))
#pairwise[[]] <- as.dist(obs[[value]])
return(list(Results = results, Pairwise = pairwise))
}

# 50 runs take ~ 0.5h (until 12.00)
spacoBCI <- spa.PD.step5(com=t(bci.data$grid20.90.206),
phy=bci.data$phy206, value=3, nullmod="taxaShuffle", runs=49)
spacoBCI
# this shows clustering for the 

##

#######################
## SES.MPD (based on mean values) ################
#######################

MPD.ses.mean <- function(com, dis, nullmod, runs){  
  results <- matrix(NA, nrow = 1, ncol = 8)  
  alpha <- list("stats") # list because it should hold objects of
varying length
  names(alpha) <- c("stats")  
  alpha.shuff <- function(com, runs){
  Res = NA
  for (r in 1:runs) {      
    Res <- c(Res, mean(mpd(samp = t(eval(parse(text=paste("resamp.",
nullmod, sep = "")))(com)), dis = dis, abundance.weighted = TRUE)))  
  }
  return(Res)
}  
  
  obs <- mpd(samp = t(com), dis = dis, abundance.weighted = TRUE) #
single obsversed MPD value   
  obs.val <- mean(obs) 
  resamp <- (alpha.shuff(com = com, runs = runs))
  resamp[1] <- obs.val
  obs.rank <- rank(resamp)[1]
  results[1,1] <- obs.val
  results[1,2] <- mean(resamp[2:(runs+1)], na.rm = TRUE)
  results[1,3] <- sd(resamp[2:(runs+1)], na.rm = TRUE)
  results[1,4] <- quantile(resamp[2:(runs+1)],  probs = c(2.5,
97.5)/100)[1]
  results[1,5] <- quantile(resamp[2:(runs+1)],  probs = c(2.5,
97.5)/100)[2]
  results[1,6] <- obs.rank/(runs+1) ## P(1-sided test, H1: obs<exp)
  results[1,7] <- 1-(obs.rank/(runs+1)) ## P(1-sided test, H1:
obs>exp)
  results[1,8] <- (1-(obs.rank/(runs+1)))*2 ## P(2-sided test, H1:
obs<>exp)
dimnames(results) <- list(c("stats"),
c("mpd.obs","rand.mean","rand.sd","2.5%","97.5%","P.obs<exp","P.obs>exp","P.obs<>exp"))
  alpha[[1]] <- obs
  
  return(list(Results = results, Alpha = alpha))
}

########################

MNTD.ses.mean <- function(com, dis, nullmod, runs){  
  results <- matrix(NA, nrow = 1, ncol = 8)  
  alpha <- list("stats") # list because it should hold objects of
varying length
  names(alpha) <- c("stats")  
  alpha.shuff <- function(com, runs){
  Res = NA
  for (r in 1:runs) {      
    Res <- c(Res, mean(mntd(samp = t(eval(parse(text=paste("resamp.",
nullmod, sep = "")))(com)), dis = dis, abundance.weighted = TRUE)))  
  }
  return(Res)
}  
  
  obs <- mntd(samp = t(com), dis = dis, abundance.weighted = TRUE) #
single obsversed MNTD value   
  obs.val <- mean(obs) 
  resamp <- (alpha.shuff(com = com, runs = runs))
  resamp[1] <- obs.val
  obs.rank <- rank(resamp)[1]
  results[1,1] <- obs.val
  results[1,2] <- mean(resamp[2:(runs+1)], na.rm = TRUE)
  results[1,3] <- sd(resamp[2:(runs+1)], na.rm = TRUE)
  results[1,4] <- quantile(resamp[2:(runs+1)],  probs = c(2.5,
97.5)/100)[1]
  results[1,5] <- quantile(resamp[2:(runs+1)],  probs = c(2.5,
97.5)/100)[2]
  results[1,6] <- obs.rank/(runs+1) ## P(1-sided test, H1: obs<exp)
  results[1,7] <- 1-(obs.rank/(runs+1)) ## P(1-sided test, H1:
obs>exp)
  results[1,8] <- (1-(obs.rank/(runs+1)))*2 ## P(2-sided test, H1:
obs<>exp)
dimnames(results) <- list(c("stats"),
c("mntd.obs","rand.mean","rand.sd","2.5%","97.5%","P.obs<exp","P.obs>exp","P.obs<>exp"))
  alpha[[1]] <- obs
  
  return(list(Results = results, Alpha = alpha))
}

#############################
# Phylogenetic diversity
BCI.mpd.mean <- MPD.ses.mean(com = t(bci.data$grid20.90.206), dis =
cophenetic(bci.data$phy206), nullmod = "1s", runs = 999)
BCI.mpd.mean$Results

BCI.mntd.mean <- MNTD.ses.mean(com = t(bci.data$grid20.90.206), dis =
cophenetic(bci.data$phy206), nullmod = "1s", runs = 999)
BCI.mntd.mean$Results

bci.data$BCI.mpd.mean.phy <- BCI.mpd.mean
bci.data$BCI.mntd.mean.phy <- BCI.mntd.mean

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

################################
# Functional diversity
# traits = as.matrix(phycom09$pca11.euclid.all)

# !!!!!!!!!!!!!!!!!!!!!!!!!!!!
# run everything on scaled trait distances (without prior PCA)
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!

# just based on the first axis from the PCA:

# all traits
pca.traits.all <- rda(bci.data$traits.pca[,c(2,4,6,8,10,12)], scale =
T)
summary(pca.traits.all)
pca.traits.all.euclid <- dist(pca.traits.all$CA$u[,1])

# intercepts (a) -- fitness
pca.traits.a <- rda(bci.data$traits.pca[,c(2,6,10)], scale = T)
summary(pca.traits.a)
pca.traits.a.euclid <- dist(pca.traits.a$CA$u[,1])

# slopes (b) -- niche
pca.traits.b <- rda(bci.data$traits.pca[,c(4,8,12)], scale = T)
summary(pca.traits.b)
pca.traits.b.euclid <- dist(pca.traits.b$CA$u[,1])

#######################
# scaled trait distances (without prior PCA)
trait.all.stand.dist <-
dist(scale(bci.data$traits.pca[,c(2,4,6,8,10,12)]))
    
trait.nich.stand.dist <- dist(scale(bci.data$traits.pca[,c(4,8,12)]))
    
trait.fit.stand.dist <- dist(scale(bci.data$traits.pca[,c(2,6,10)]))

## write csv-tables of community structure results:
names(bci.data)

res <- NA
for (i in c(20,21,17,18,13:16)){
 res <- rbind(res, bci.data[[i]]$Results)
}

ComStructResults <- res[-1,]
rownames(ComStructResults) <- names(bci.data)[c(20,21,17,18,13:16)]
ComStructResults <- ComStructResults[,-8]
colnames(ComStructResults)[1] <- "obs"

write.csv(ComStructResults, file = "ComStructResults.csv")

#########################################
# based on the first PC-axis (PC1) only #
#########################################

## all traits
BCI.mpd.mean.all <- MPD.ses.mean(com = t(bci.data$grid20.90.206), dis
= as.matrix(pca.traits.all.euclid), nullmod = "1s", runs = 999)
BCI.mpd.mean.all$Results
#bci.data$BCI.mpd.mean.all <- BCI.mpd.mean.all

BCI.mntd.mean.all <- MNTD.ses.mean(com = t(bci.data$grid20.90.206),
dis = as.matrix(pca.traits.all.euclid), nullmod = "1s", runs = 999)
BCI.mntd.mean.all$Results
#bci.data$BCI.mntd.mean.all <- BCI.mntd.mean.all


## fitness
BCI.mpd.mean.fit <- MPD.ses.mean(com = t(bci.data$grid20.90.206), dis
= as.matrix(pca.traits.a.euclid), nullmod = "1s", runs = 999)
BCI.mpd.mean.fit$Results
#bci.data$BCI.mpd.mean.fit <- BCI.mpd.mean.fit

BCI.mntd.mean.fit <- MNTD.ses.mean(com = t(bci.data$grid20.90.206),
dis = as.matrix(pca.traits.a.euclid), nullmod = "1s", runs = 999)
BCI.mntd.mean.fit$Results
#bci.data$BCI.mntd.mean.fit <- BCI.mntd.mean.fit

# findings:
# MNTD based on fitness traits is (marginally) higher than expected by
change (overdispersion) (not significant when based on MPD) -> species
within communities are more dissimilar with respect to their fitness
traits (competitive ability)


## nich
BCI.mpd.mean.nich <- MPD.ses.mean(com = t(bci.data$grid20.90.206), dis
= as.matrix(pca.traits.b.euclid), nullmod = "1s", runs = 999)
BCI.mpd.mean.nich$Results
#bci.data$BCI.mpd.mean.nich <- BCI.mpd.mean.nich

BCI.mntd.mean.nich <-MNTD.ses.mean(com = t(bci.data$grid20.90.206),
dis = as.matrix(pca.traits.b.euclid), nullmod = "1s", runs = 999)
BCI.mntd.mean.nich$Results
#bci.data$BCI.mntd.mean.nich <- BCI.mntd.mean.nich

# findings:
# MPD based on niche traits is lower than expected (clustering) (when
based on MPD, less significant when based MNTD) -> species within
communities are more similar with respect to their niche differences
than expected by chance

## generally, only if all traits are included, either from PCA or
"raw" trait distance we find random structure when all traits are
included (all), clustering for niche traits, and overdispersion in
fitness traits.


res <- rbind(BCI.mpd.mean.all$Results, BCI.mntd.mean.all$Results,
BCI.mpd.mean.nich$Results, BCI.mntd.mean.nich$Results,
BCI.mpd.mean.fit$Results, BCI.mntd.mean.fit$Results)

ComStructResults.PC.1 <- res
rownames(ComStructResults.PC.1) <- c("mpd.all.PC.1",
"mntd.all.PC.1","mpd.nich.PC.1", "mntd.nich.PC.1","mpd.fit.PC.1",
"mntd.fit.PC.1")
ComStructResults.PC.1 <- ComStructResults.PC.1[,-8]
colnames(ComStructResults.PC.1)[1] <- "obs"

write.csv(ComStructResults.PC.1, file = "ComStructResults.PC.1.csv")


save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))


##################################################################
##################### Sensitivity analysis #######################
##################################################################

# 1) based on abundance data 
# 1.1) without rec.a (abu.206)

# just to check, reproduce results from my previous figs.

attach(as.data.frame(bci.data$distvec.traits.phy))

phylodistance <- loess(phy.dist ~ PC1.Nich*PC1.Fit, span = 1, degree =
2) # try additive effect
n.marginal <- seq(min(PC1.Nich), max(PC1.Nich), length.out = 50)
f.marginal <- seq(min(PC1.Fit), max(PC1.Fit), length.out = 50)
nf.marginal <- list(PC1.Nich = n.marginal, PC1.Fit = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "PhyloPC1nichePC1fitness.dots.pdf",width = 10, height = 9,
pointsize=12)
contourplot(fit ~ PC1.Nich * PC1.Fit, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phylogenetic distance ~ PC1.Nich*PC1.Fit",
            panel=function(...){
            panel.contourplot(...)
            grid.points(PC1.Nich, PC1.Fit, pch=1, size=unit(.2,
"char"))
          })
dev.off()

detach(as.data.frame(bci.data$distvec.traits.phy))

##### yes, works

# PCA on the two fitness traits:
colnames(bci.data$traits.pca)

pca.traits.a.wo.rec.a <- rda(bci.data$traits.pca[,c(6,10)], scale = T)
summary(pca.traits.a.wo.rec.a)

fig <- ordiplot(pca.traits.a.wo.rec.a, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)

screeplot(pca.traits.a.wo.rec.a, bstick = TRUE, "lines")

bci.data$traits.pca <- cbind(bci.data$traits.pca,
pca.traits.a.wo.rec.a$CA$u[,1:2])
colnames(bci.data$traits.pca)[c(26,27)] <-
c("PC1.Fit.wo.rec.a","PC2.Fit.wo.rec.a")


# PCA on the errors of the two fitness traits
pca.traits.err.a.wo.rec.a <- rda(bci.data$traits.pca[,c(7,11)], scale
= T)
summary(pca.traits.err.a.wo.rec.a)

fig <- ordiplot(pca.traits.err.a.wo.rec.a, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)

screeplot(pca.traits.err.a.wo.rec.a, bstick = TRUE, "lines")

bci.data$traits.pca <- cbind(bci.data$traits.pca,
pca.traits.err.a.wo.rec.a$CA$u[,1:2])

colnames(bci.data$traits.pca)[c(28,29)] <-
c("PC1.Fit.err.wo.rec.a","PC2.Fit.err.wo.rec.a")

# function to create a distance vector for each 
vec2dist2vec <- function(x){
    res <- NA
    for (i in 1:dim(x)[2]){
        distvec <- dist(x[,i])
        res <- cbind(res, distvec)
    }
    res <- res[,-1]
    colnames(res) <- colnames(x)
    res <- as.data.frame(res)
    nam <- NA
    dis <- dist(x[,1])
    for (i in 1:(attr(dis, "Size")-1)){
        for (j in (i+1):attr(dis, "Size")){
            nam <- c(nam, paste(attr(dis, "Labels")[i], attr(dis,
"Labels")[j], sep = " vs "))
        }
    }
    nam <- nam[-1]   
    res <- cbind(nam, res)
    rownames(res) <- nam
    res
}


distvec.traits.2 <- vec2dist2vec(bci.data$traits.pca)
tail(distvec.traits.2)

# !! check manually 2 or 3 distances for some traits # yes, correct

# combine new distance with existing distance vector

# save new distance vector and new trait-axes in bci.data

bci.data$distvec.traits.phy.cooc <- cbind(distvec.traits.2,
bci.data$distvec.traits.phy.cooc[,20:32])

# recalculate niche-PCAs and save all three PCA axes

colnames(bci.data$traits.pca)

pca.traits.b <- rda(bci.data$traits.pca[,c(4,8,12)], scale = T)
summary(pca.traits.b)

fig <- ordiplot(pca.traits.b, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
screeplot(pca.traits.b, bstick = TRUE, "lines")
bci.data$traits.pca <- cbind(bci.data$traits.pca,
pca.traits.b$CA$u[,1:3])
colnames(bci.data$traits.pca)[c(30:32)] <-
c("PC1.Nich","PC2.Nich","PC3.Nich")

# check whether first two niche PCs correspond to the old ones # yes,
is okay
niche1 <- pca.traits.b$CA$u[,1]
plot(bci.data$traits.pca[,18], niche1)
plot(bci.data$traits.pca[,18], bci.data$traits.pca[,30])

# run PCA on the niche errors
colnames(bci.data$traits.pca)

pca.traits.b.err <- rda(bci.data$traits.pca[,c(5,9,13)], scale = T)
summary(pca.traits.b.err)

fig <- ordiplot(pca.traits.b.err, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
screeplot(pca.traits.b.err, bstick = TRUE, "lines")
bci.data$traits.pca <- cbind(bci.data$traits.pca,
pca.traits.b.err$CA$u[,1:3])

colnames(bci.data$traits.pca)[c(33:35)] <-
c("PC1.Nich.err","PC2.Nich.err","PC3.Nich.err")

# create distance vectors:
distvec.traits.3 <- vec2dist2vec(bci.data$traits.pca[,c(30:35)])
tail(distvec.traits.3)

bci.data$distvec.traits.phy.cooc <-
cbind(bci.data$distvec.traits.phy.cooc, distvec.traits.3)

colnames(bci.data$distvec.traits.phy.cooc)

# !!!!!! continue here
# recalculate means and standard deviation for each species on each
PCA axis (according to the advice of Tim Paine):

# 1) Run PCA on all niche (and fitness) trait values, thereby treating
higher and lower CI values, respectively as individual trait values
# 2) calculate the mean and standard deviation for each species

# try two different ways: (i) taking only the higher and lower
confidence intervals and (ii) taking the higher and lower confidence
intervals as well as the mean

# for the two fitness traits (mean and lower and higher CI, and mean)
fit <- rbind(as.matrix(bci.data$traits.abu.all[,c(25,39)]),
as.matrix(bci.data$traits.abu.all[,c(26,40)]),
as.matrix(bci.data$traits.abu.all[,c(27,41)]))
fit

cor.test(fit[,1],fit[,2])

pca.traits.a.ind<- rda(fit, scale = T)
summary(pca.traits.a.ind)

fig <- ordiplot(pca.traits.a.ind, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
screeplot(pca.traits.a.ind, bstick = TRUE, "lines")

x <- pca.traits.a.ind$CA$u

agg.mean.sd <- function(x){
    res <- NA
    for (i in 1:dim(x)[2]){
        m <- aggregate(x[,i], by = list(row.names(x)), FUN = mean)
        s <- aggregate(x[,i], by = list(row.names(x)), FUN = sd)
        ms <- cbind(m[,c(2)],s[,2])
        res <- cbind(res, ms)
        rownames(res) <- s[,1]
    }
    res    
}

PCA.mean.sd <- agg.mean.sd(pca.traits.a.ind$CA$u)[,-1]

colnames(PCA.mean.sd) <-
c("PC1.Fit.mean","PC1.Fit.sd","PC2.Fit.mean","PC2.Fit.sd")

# !! continue here:

# for the two fitness traits (lower and higher CI without mean)



# calculate overall fitness and niche differences based on (i) all two
fitness and (ii) all three niche PCA axes

fit <- rbind(as.matrix(bci.data$traits.abu.all[,c(26,40)]),
as.matrix(bci.data$traits.abu.all[,c(27,41)]))
fit

cor.test(fit[,1],fit[,2])

pca.traits.a.ind<- rda(fit, scale = T)
summary(pca.traits.a.ind)

fig <- ordiplot(pca.traits.a.ind, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)

screeplot(pca.traits.a.ind, bstick = TRUE, "lines")

x <- pca.traits.a.ind$CA$u

agg.mean.sd <- function(x){
    res <- NA
    for (i in 1:dim(x)[2]){
        m <- aggregate(x[,i], by = list(row.names(x)), FUN = mean)
        s <- aggregate(x[,i], by = list(row.names(x)), FUN = sd)
        ms <- cbind(m[,c(2)],s[,2])
        res <- cbind(res, ms)
        rownames(res) <- s[,1]
    }
    res    
}

PCA.wo.mean.sd <- agg.mean.sd(pca.traits.a.ind$CA$u)[,-1]

colnames(PCA.wo.mean.sd) <-
c("PC1.Fit.wo.mean","PC1.Fit.wo.sd","PC2.Fit.wo.mean","PC2.Fit.wo.sd")

# are the PC-scores that include the mean correlated to the ones
without means (only ased on CI.low and CI.upp)?

plot(PCA.wo.mean.sd[,1], PCA.mean.sd[,1]) # yes, they are highly
correlated

cor.test(PCA.wo.mean.sd[,4], PCA.mean.sd[,4]) # yes, they are highly
correlated

# are the means and sd calculated with this method (in Baraloto et
2012 J.Ecol.) correlated with the means and stand.errors i used
before?
plot(PCA.wo.mean.sd[rownames(bci.data$traits.pca),1],
bci.data$traits.pca[,26]) # strongly correlated
plot(PCA.wo.mean.sd[rownames(bci.data$traits.pca),2],
bci.data$traits.pca[,28]) # strongly correlated

PCA.wo.mean.sd[rownames(bci.data$traits.pca), 1:2]

# do means and sd have similar co-variances using the two approaches
plot(bci.data$traits.pca[,28], bci.data$traits.pca[,26]) # low
co-variance
cor.test(bci.data$traits.pca[,28], bci.data$traits.pca[,26]) # low
co-variance

plot(PCA.wo.mean.sd[,1], PCA.wo.mean.sd[,2])
cor.test(PCA.wo.mean.sd[,2], PCA.wo.mean.sd[,1])

# do the same for the three niche traits

niche <- rbind(as.matrix(bci.data$traits.abu.all[,c(14,28,42)]),
as.matrix(bci.data$traits.abu.all[,c(15,29,43)]),
as.matrix(bci.data$traits.abu.all[,c(16,30,44)]))
niche

cor.test(niche[,1],niche[,2])

pca.traits.b.ind<- rda(niche, scale = T)
summary(pca.traits.b.ind)

fig <- ordiplot(pca.traits.b.ind, type = "none")
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)

screeplot(pca.traits.b.ind, bstick = TRUE, "lines")

x <- pca.traits.b.ind$CA$u

agg.mean.sd <- function(x){
    res <- NA
    for (i in 1:dim(x)[2]){
        m <- aggregate(x[,i], by = list(row.names(x)), FUN = mean)
        s <- aggregate(x[,i], by = list(row.names(x)), FUN = sd)
        ms <- cbind(m[,c(2)],s[,2])
        res <- cbind(res, ms)
        rownames(res) <- s[,1]
    }
    res    
}

PCA.mean.sd.niche <- agg.mean.sd(pca.traits.b.ind$CA$u)[,-1]



colnames(PCA.mean.sd.niche) <-
c("PC1.Niche.mean","PC1.Niche.sd","PC2.Niche.mean","PC2.Niche.sd","PC3.Niche.mean","PC3.Niche.sd")

# ! be careful: rownames from data from PCA (e.g. PCA.mean.sd.niche)
are in different order than rownames from bci.data$traits.abu.all
# only problem, if output from the aggregation function (that orders
species names) is used

# ! cbind with existing data 
bci.data$traits.pca <- cbind(bci.data$traits.pca,
PCA.wo.mean.sd[rownames(bci.data$traits.pca), ],
PCA.mean.sd.niche[rownames(bci.data$traits.pca), ])
bci.data$traits.pca <- cbind(bci.data$traits.pca,
PCA.mean.sd[rownames(bci.data$traits.pca), ])

plot(bci.data$traits.pca[,46], bci.data$traits.pca[,26])

# ! save the data
save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

# 

# !!!!!! continue here

# (7.00- 7.30)
# calculate phylogenetic signal for:
# i) the new first two fitness PCs (that exclude the rec.a)
# ! when calculating phylogenetic signal that includes measurement
error, take both the memeans and the sd from the ordination based on
the "individual" measurements (CI.low, CI.upp, mean)
# ! check whether the "real" measured trait means give similar
absolute signal values then the means from the PCA.

# [40] "PC1.Niche.mean"       "PC1.Niche.sd"
# [46] "PC1.Fit.mean"         "PC1.Fit.sd"

colnames(bci.data$traits.pca)

mat2 <- match.phylo.comm(phy=mat$phy, comm=t(res))

multk <- MultiK(bci.data$phy206, bci.data$traits.pca[,c(40,46)])
multkerr

multkerr <- MultiKerror(bci.data$phy206,
bci.data$traits.pca[,c(40,46)], error=bci.data$traits.pca[,c(41,47)])
multkerr

multkerr.2 <- MultiKerror(bci.data$phy206,
bci.data$traits.pca[,c(26,30)], error=bci.data$traits.pca[,c(28,33)])
multkerr.2

write.csv(multkerr, file = "multkerr.csv")


# 7.30-8.00:
# calculate overall fitness and niche differences based on (i) all two
fitness and (ii) all three niche PCA axes


distvec.traits.niche.fit.comb <-
cbind(dist(bci.data$traits.pca[,c(30:32)]),
dist(bci.data$traits.pca[,c(26,27)])) 

colnames(bci.data$distvec.traits.phy.cooc)
colnames(distvec.traits.niche.fit.comb) <- c("PC.niche.comb",
"PC.fit.comb")

bci.data$distvec.traits.phy.cooc <-
cbind(bci.data$distvec.traits.phy.cooc, distvec.traits.niche.fit.comb)
    
# create distance vectors based on differences in relative abundances
abund.rel <-
bci.data$traits.abu.all[,c(10)]/sum(bci.data$traits.abu.all[,c(10)])

CorTestPlot(cbind(bci.data$traits.abu.all[,c(10,24,38)], abund.rel))

abund.rel.dist <- dist(abund.rel)

bci.data$distvec.traits.phy.cooc <-
cbind(bci.data$distvec.traits.phy.cooc, as.vector(abund.rel.dist))

colnames(bci.data$distvec.traits.phy.cooc)[53] <- "abund.rel"

plot(bci.data$distvec.traits.phy.cooc[,2],
bci.data$distvec.traits.phy.cooc[,53])





######
colnames(bci.data$traits.abu.all)
colnames(bci.data$traits.pca)
colnames(as.data.frame(bci.data$distvec.traits.phy.cooc))

# try trait distances without prior PCA
niche.dist <- dist(scale(bci.data$traits.pca[ ,c(5,9,13)]))
fit.dist <- dist(scale(bci.data$traits.pca[ ,c(3,7,11)]))

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.pca[ ,c(5,9,13)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.pca[ ,c(3,7,11)], scale =
T)$CA$u[,1:3])

# based on rare on rare or abundant species
niche.dist <- dist(rda(traits.abu.all.5000[ ,c(14,28,42)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(traits.abu.all.5000[ ,c(25,39)], scale =
T)$CA$u[,1:2])

resp <- as.vector(phy.dist.5000)
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "Phy.dist.PCnich.PCfit.(spa1dec1).5000.wo.rec.a.pdf",width
= 10, height = 9, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phy.dist.5000.wo.rec.a ~ niche*fitness",
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
dev.off()

detach(as.data.frame(bci.data$distvec.traits.phy))

# !!! continue here: 
# read in new rec.a parameter (re-name )

# match the 

rec.a.new<- read.table(paste(path.traits,
"Nadja_Traits/abun/rec_a_new.txt", sep = ""), sep = "\t")

traits.abu.308.2 <- merge(bci.data$traits.abu.308, rec.a.new, by.x =
"sp", by.y = "sp", all = T)

bci.data$traits.abu.308 <- traits.abu.308.2

# combine with the 206 species data:

traits.pca.2 <- merge(bci.data$traits.abu.all, rec.a.new, by.x = "sp",
by.y = "sp", all = F, sort = F)

rownames(bci.data$traits.pca) <- bci.data$traits.pca$species


# reorder the data:


traits.pca.4 <- bci.data$traits.pca[rownames(bci.data$traits.abu.all),
]
bci.data$traits.pca <- traits.pca.4

# 1.4) create data sets for i) >=20 ind. (gro) and >= 50 (mor)
colnames(bci.data$traits.abu.all)

CorTestPlot(bci.data$traits.abu.all[,c(10,24,38)])

bci.data$traits.abu.all[,]

traits.abu.all.20 <-
bci.data$traits.abu.all[which(bci.data$traits.abu.all[,24]>20),]
dim(traits.abu.all.20) # 187  44

traits.abu.all.50 <-
bci.data$traits.abu.all[which(bci.data$traits.abu.all[,38]>50),]
dim(traits.abu.all.50) # 170  44

# 1.5) test <5000 mort.

traits.abu.all.5000 <-
bci.data$traits.abu.all[which(bci.data$traits.abu.all[,38]<5000),]
dim(traits.abu.all.5000) # 199  44
                                       
# 1.6) create phylodist (20,50,5000) (16.15-16.30)
mat.20.trait <- match.phylo.data(phy=bci.data$phy206,
data=traits.abu.all.20[,c(3:44)])
mat.50.trait <- match.phylo.data(phy=bci.data$phy206,
data=traits.abu.all.50[,c(3:44)])
mat.5000.trait <- match.phylo.data(phy=bci.data$phy206,
data=traits.abu.all.5000[,c(3:44)])

# calculate phylogenetic distances
phy.dist.20 <- as.dist(cophenetic(mat.20.trait$phy))
phy.dist.50 <- as.dist(cophenetic(mat.50.trait$phy))
phy.dist.5000 <- as.dist(cophenetic(mat.5000.trait$phy))

# 1.7) create coocc.scores (20,50,5000) (16.30-17.00)
mat.20.com <- match.phylo.comm(phy = mat.20.trait$phy, comm =
bci.data$grid20.90.206)
mat.50.com <- match.phylo.comm(phy = mat.50.trait$phy, comm =
bci.data$grid20.90.206)
mat.5000.com <- match.phylo.comm(phy = mat.5000.trait$phy, comm =
bci.data$grid20.90.206)

# calculate co-occurrence scores
coocc.check.20 <- species.dist(mat.20.com$comm, metric =
"checkerboard")
coocc.check.50 <- species.dist(mat.50.com$comm, metric =
"checkerboard")
coocc.check.5000 <- species.dist(mat.5000.com$comm, metric =
"checkerboard")

# make sure phylo-distances are in the same order as co-occurrences
scores
match(attr(coocc.check.20, "Labels"), attr(phy.dist.20, "Labels"))
match(attr(coocc.check.50, "Labels"), attr(phy.dist.50, "Labels"))
match(attr(coocc.check.5000, "Labels"), attr(phy.dist.5000, "Labels"))

# ... run analyses (17.00-17.15):

# patterns are robust, irrespective whether rare or dominant species
are excluded
# pattern (slightly) change when rec.a is excluded
# rec.a.corrected (according to nadja )

# ! save the data

bci.data$gro.20_90.95$traits.abu.all.20 <- traits.abu.all.20
bci.data$gro.20_90.95$phy.dist.20 <- phy.dist.20
bci.data$gro.20_90.95$coocc.check.20 <- coocc.check.20

bci.data$mor.50_90.95$traits.abu.all.50 <- traits.abu.all.50
bci.data$mor.50_90.95$phy.dist.50 <- phy.dist.50
bci.data$mor.50_90.95$coocc.check.50 <- coocc.check.50

bci.data$mor.5000_90.95$traits.abu.all.5000 <- traits.abu.all.5000
bci.data$mor.5000_90.95$phy.dist.5000 <- phy.dist.5000
bci.data$mor.5000_90.95$coocc.check.5000 <- coocc.check.5000

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

# 2) run on no.abund (14.45-15.15)

traits.noabund <- read.table(paste(path.traits,
"Nadja_Traits/noabun/demographic_traits_noabun_complete.txt", sep =
""), sep = "\t")

dim(traits.noabund)

rownames(traits.noabund)[rownames(traits.noabund)=="Appunia_seibertii"]
<- "Morinda_seibertii"

rownames(traits.noabund)[which(rownames(traits.noabund) %in%
bci.data$bci.tree.node.OP$tip.label == FALSE)]

# delete "Cyathea_petiolata"

traits.noabund.wo.Cyathea <-
traits.noabund[rownames(traits.noabund)!="Cyathea_petiolata", ]
rownames(traits.noabund.wo.Cyathea)[which(rownames(traits.noabund.wo.Cyathea)
%in% bci.data$bci.tree.node.OP$tip.label == FALSE)]

bci.data$traits.noabund.all <- traits.noabund.wo.Cyathea

# match phylogeny to trait data:

mat <- match.phylo.comm(phy=bci.data$bci.tree.node.OP,
comm=t(bci.data$traits.noabund.all))
mat$phy$edge.length <- mat$phy$edge.length+.1

bci.data$traits.noabu.308 <- t(mat$comm)

colnames(t(mat$comm))

traits.noabu.308 <- as.data.frame(t(mat$comm))

#  transform into numeric
traits.noabu.308[,3:43] <- apply(traits.noabu.308[,3:43], 2,
as.numeric)

bci.data$traits.noabu.308 <- traits.noabu.308

save(bci.data, file = paste(path.data, "bci.data.Rdata", sep = ""))

###### analyses of noabund
names(bci.data)
colnames(bci.data$traits.noabu.308)

rownames(bci.data$traits.noabu.308) <- bci.data$traits.noabu.308[,2]

mat.traits.noabu <- match.phylo.data(phy=bci.data$phy206,
data=bci.data$traits.noabu.308[,c(3:43)])

bci.data$traits.noabu.206 <- mat.traits.noabu$data

####################################
colnames(bci.data$traits.noabu.206)
plot(bci.data$traits.noabu.206[,c(25,36)])
CorTestPlot(bci.data$traits.noabu.206[,c(25,36)])

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.noabu.206[ ,c(10,22,39)], scale
= T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.noabu.206[ ,c(19,25)], scale =
T)$CA$u[,1:2]) # or 36 instead 25
# ! just for fun: try 85-90 census (but for now take coocc-scores from
the 90-95 census)

#resp <- as.vector(phy.dist.5000)
resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file =
"Coocc.check.PCnich.PCfit.(spa1dec1).noabund.wo.rec.a.pdf",width = 10,
height = 9, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Coocc.check.noabund.wo.rec.a ~ niche*fitness",
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
dev.off()

######
# abund and noabund give roughly similar results (at least with
respect to co-occurrence)
# similar as in the abund-analysis, also in the noabund-analyses it
has the biggest influence wether or not rec.a is includes in the
analyses: if rec.a is considered, it will produce the chesson 1:1,
while exluding rec.a yields in chesson at small to intermediate niche
differences, while in cases where species have very large niche
differences, species will co-exist irrespective oftheir fitness
(competitive ability differences)
# note, in the noabund analysis, the relationships with phylogenetic
distance look like an inverted chesson
######

# 1.2) run on the full data (308) using PCoA (18.45-19.15)
names(bci.data)
colnames(bci.data$traits.abu.308)

# no possible using PCoA
# use MICE instead
# do default multiple imputation on a numeric matrix
 
imp <-
mice(bci.data$traits.abu.308[,c(3,4,7,11,14,18,21,25,28,32,35,39,42)])
traits.abu.308.full <- complete(imp)
 
rownames(traits.abu.308.full) <-  bci.data$traits.abu.308[,2]
bci.data$traits.abu.308.full <- traits.abu.308.full

match(rownames(traits.abu.308.full), bci.data$phy.308$tip.label)

rownames(bci.data$traits.abu.308.full)[rownames(bci.data$traits.abu.308.full)=="Appunia_seibertii"]
<- "Morinda_seibertii"

mat.trait.308 <- match.phylo.data(bci.data$phy.308,
data=bci.data$traits.abu.308.full)

# calculate phylogenetic distances
phy.dist.308 <- as.dist(cophenetic(mat.trait.308$phy))

# calculate co-occurrence scores
grid20.90 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells20_1990.txt", sep
= ""), sep = "\t")
dim(grid20.90)

# match grid data to trait data
colnames(grid20.90)[which(colnames(grid20.90) %in%
bci.data$traits.abu.308$sp == FALSE)]
# [1] "ANNOHA" "CNEMPE" "PIPEIM" "PSYCB1" "SOLAAR" "TERNTE" "TREMIN"

as.character(bci.data$traits.abu.308$sp)[which(as.character(bci.data$traits.abu.308$sp)
%in% colnames(grid20.90) == FALSE)]
# [1] "APEIHY" "CECRLO" "CLIDSE" "LOPIDA" "LYCIMA" "RAUVLI" "SCH2MO"
"STEMGR"
# [9] "VISMMA" "XYL2CH"

bci.data$traits.abu.308$sp <- as.character(bci.data$traits.abu.308$sp)

grid20.90 <- grid20.90[, which(colnames(grid20.90) %in%
bci.data$traits.abu.308$sp)]

nam <- as.data.frame(colnames(grid20.90))
colnames(nam)[1] <- "sp"

traits.abu.298 <- merge(bci.data$traits.abu.308, nam, by = "sp")

match(colnames(grid20.90), traits.abu.298$sp)

bci.data$grid20.90.298 <- grid20.90
# give full names to gridded data
colnames(bci.data$grid20.90.298) <- bci.data$traits.abu.298[,2]
bci.data$traits.abu.298 <- traits.abu.298

colnames(bci.data$grid20.90.298)[colnames(bci.data$grid20.90.298)=="Appunia_seibertii"]
<- "Morinda_seibertii"

# phylogenetic distances
mat.com <- match.phylo.comm(bci.data$phy.308,
comm=bci.data$grid20.90.298)
phy.dist.298 <- as.dist(cophenetic(mat.com$phy))
bci.data$phy.298 <- mat.com$phy
bci.data$grid20.90.298 <-  mat.com$comm

rownames(bci.data$traits.abu.298) <- bci.data$traits.abu.298[,2]
rownames(bci.data$traits.abu.298)[rownames(bci.data$traits.abu.298)=="Appunia_seibertii"]
<- "Morinda_seibertii"

mat.traits <- match.phylo.data(bci.data$phy.298,
data=bci.data$traits.abu.308.full)
dim(mat.traits$data)
bci.data$traits.abu.298 <- mat.traits$data

match(rownames(bci.data$traits.abu.298),
colnames(bci.data$grid20.90.298))

# phylogenetic distances
phy.dist.298 <- as.dist(cophenetic(bci.data$phy.298))

# co-occurrence scores
coocc.check.298 <- species.dist(bci.data$grid20.90.298, metric =
"checkerboard")

match(attr(coocc.check, "Labels"), attr(phy.dist.298, "Labels"))


colnames(bci.data$traits.abu.298)

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.abu.298[ ,c(5,9,13)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.298[ ,c(8,12)], scale =
T)$CA$u[,1:2]) # or 36 instead 25
# ! just for fun: try 85-90 census (but for now take coocc-scores from
the 90-95 census)

resp <- as.vector(coocc.check.298)
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file =
"Coocc.check.PCnich.PCfit.(spa1dec1).298.wo.rec.a.pdf",width = 10,
height = 9, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Coocc.check.298.wo.rec.a ~ niche*fitness",
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
dev.off()

# similar pattern to 206 when rec.a is included
# when rec.a is included, co-occurrence increases with both niche and
fitness differences, irrespective of whether the two forces differ
from each other


# 1.3) test for trait correlations between 1st and 2nd census
(19.15-19.45)
# 1.3.1) try with first census (1985-90) (11.00-11.30)
# 1.3.1.1) with the same 206 species
# (patterns look completely different)
grid20.85 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells20_1985.txt", sep
= ""), sep = "\t")

colnames(grid20.85)[which(colnames(grid20.85) %in%
bci.data$traits.abu.all$sp == FALSE)]

as.character(bci.data$traits.abu.all$sp)[which(as.character(bci.data$traits.abu.all$sp)
%in% colnames(grid20.85) == FALSE)]

bci.data$traits.abu.all$sp <- as.character(bci.data$traits.abu.all$sp)

grid20.85.206 <- grid20.85[, which(colnames(grid20.85) %in%
bci.data$traits.abu.all$sp)]

# reorder short names according to trait data
grid20.85.206.new <- grid20.85.206[, bci.data$traits.abu.all$sp]
# give full names to gridded data
colnames(grid20.85.206.new) <- rownames(bci.data$traits.abu.all)
bci.data$grid20.85.206 <- grid20.85.206.new


# phylogenetic distances
phy.dist.206 <- as.dist(cophenetic(bci.data$phy206))

# co-occurrence scores
coocc.check.206.1985 <- species.dist(bci.data$grid20.85.206, metric =
"checkerboard")
coocc.check.206.1990 <- species.dist(bci.data$grid20.85.206, metric =
"checkerboard")

match(attr(coocc.check.206.1985, "Labels"), attr(phy.dist.206,
"Labels"))

match(rownames(bci.data$traits.abu.all), attr(coocc.check.206.1985,
"Labels"))

####

colnames(bci.data$traits.abu.all)

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.abu.all[ ,c(14,28,42)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all[ ,c(25,39)], scale =
T)$CA$u[,1:2]) 

#resp <- as.vector(coocc.check.206.1990)
resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
#pdf(file = "Phy.dist.PCnich.PCfit.(spa1dec1).1985.pdf",width = 10,
height = 9, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phy.dist.1985.pdf ~ niche*fitness",
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
#dev.off()

## span = .66, degree = 1 looks perfect (like in narwani, incl. all
three fitness axes (with rec.a)) # without rec.a, span = 1, degree =
1, looks best

# !!! continue here:
# re-try with 2nd census; do we get the same results as in the first
analysis with the 2nd census
# yes, we get the same thing

# 1.3.1.2) with the set of species for which all 6 trait in the first
census are available
colnames(bci.data$traits.abu.308)[c(4,7,18,21,32,35)]

trait.abu.85 <- bci.data$traits.abu.308[,c(1,2,4,7,18,21,32,35)]

!is.na(rowSums(trait.abu.85[,c(3:8)]))
trait.abu.85.sel <-
trait.abu.85[!is.na(rowSums(trait.abu.85[,c(3:8)])), ]

bci.data$trait.abu.85.228 <- trait.abu.85.sel

# match with phylogeny:
rownames(bci.data$trait.abu.85.228) <-
bci.data$trait.abu.85.228$species
mat.traits <- match.phylo.data(bci.data$phy.308,
data=bci.data$trait.abu.85.228)

# match with grid-data

colnames(grid20.85)[which(colnames(grid20.85) %in%
bci.data$traits.abu.all$sp == FALSE)]

as.character(bci.data$traits.abu.all$sp)[which(as.character(bci.data$traits.abu.all$sp)
%in% colnames(grid20.85) == FALSE)]

bci.data$traits.abu.all$sp <- as.character(bci.data$traits.abu.all$sp)

grid20.85.sel <- grid20.85[, which(colnames(grid20.85) %in%
bci.data$trait.abu.85.228$sp)]

# reorder short names according to trait data
grid20.85.228 <- grid20.85.sel[, bci.data$trait.abu.85.228$sp]

# give full names to gridded data
colnames(grid20.85.228) <- rownames(bci.data$trait.abu.85.228)

bci.data$grid20.85.228 <- grid20.85.228


mat.com <- match.phylo.comm(bci.data$phy.308,
comm=bci.data$grid20.85.228)

bci.data$grid20.85.228 <- mat.com$comm
bci.data$trait.abu.85.228 <- mat.traits$data

match(rownames(bci.data$trait.abu.85.228),
colnames(bci.data$grid20.85.228))

trait.abu.85.228 <- 
  trait.abu.85.228.num <- apply(bci.data$trait.abu.85.228[,3:8], 2,
as.numeric)

bci.data$trait.abu.85.228 <- trait.abu.85.228.num

# phylogenetic distances
phy.dist.228 <- as.dist(cophenetic(mat.com$phy))
# co-occurrence scores
coocc.check.228.1985 <- species.dist(bci.data$grid20.85.228, metric =
"checkerboard")


## run the analysis:
colnames(bci.data$trait.abu.85.228)

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$trait.abu.85.228[ ,c(2,4,6)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$trait.abu.85.228[ ,c(3,5)], scale =
T)$CA$u[,1:2]) # or 36 instead 25
# ! just for fun: try 85-90 census (but for now take coocc-scores from
the 90-95 census)

resp <- as.vector(phy.dist.228)
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file =
"Phy.dist.PCnich.PCfit.(spa1dec1).228.1985.wo.rec.a.pdf",width = 10,
height = 9, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phy.dist.228.1985.wo.rec.a ~ niche*fitness",
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
dev.off()

# for the first census, we get the same results irrespective of
whether we use 

# 1.3.2) try with combined census (1985-90 + 1990-95) (20.15-20.45)
# !!! do this later, and for now continue with the scaling analysis


# 4) cross scale analysis
# start with 206 species (1990-95), wo.rec.a

# read all files:

path <-
"/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/5m_Steps/"
temp <- list.files(path, pattern="*.txt")

for(file in temp)
{
perpos <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, perpos-1)), 
read.table(paste(path,file,sep="")))
}

grid5.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells5_1982.txt", sep
= ""), sep = "\t")
grid10.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells10_1982.txt", sep
= ""), sep = "\t")
grid20.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells20_1982.txt", sep
= ""), sep = "\t")
grid33.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells33_1982.txt", sep
= ""), sep = "\t")
grid50.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells50_1982.txt", sep
= ""), sep = "\t")
grid100.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells100_1982.txt",
sep = ""), sep = "\t")
grid250.1982 <- read.table(paste(path.traits,
"Nadja_Traits/abundance_gridcells/Abundance_gridcells250_1982.txt",
sep = ""), sep = "\t")

##

# create "bci.data$traits.abu.all.205" data set  KOANWE- 
Koanophyllon_wetmorei 

traits.abu.all.205 <-
bci.data$traits.abu.all[rownames(bci.data$traits.abu.all)!="Koanophyllon_wetmorei",]

bci.data$traits.abu.all.205 <- traits.abu.all.205

i <- 5
j <- 2010

vec <- as.vector(get(paste(paste("Abundance_gridcells", i, sep = ""),
j, sep = "_")))

########################################
#  run the following to match and order the abundance grids to the
trait-data
########################################

# read all files:
path <-
"/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/5m_Steps/"
temp <- list.files(path, pattern="*.txt")
for(file in temp)
{
    perpos <- which(strsplit(file, "")[[1]]==".")
    assign(
        gsub(" ","",substr(file, 1, perpos-1)), 
        read.table(paste(path,file,sep="")))
}

# match the grids
gridlist <- list()
for (i in seq(5,100, 5)){
    for (j in c(1990)){ # just if there are several years
        colnames(get(paste(paste("Abundance_gridcells", i, sep = ""),
j, sep = "_")))[which(colnames(get(paste(paste("Abundance_gridcells",
i, sep = ""), j, sep = "_"))) %in% bci.data$traits.abu.all.205$sp ==
FALSE)]
        as.character(bci.data$traits.abu.all.205$sp)[which(as.character(bci.data$traits.abu.all.205$sp)
%in% colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j,
sep = "_"))) == FALSE)]
        bci.data$traits.abu.all.205$sp <-
as.character(bci.data$traits.abu.all.205$sp)
        new.205 <- get(paste(paste("Abundance_gridcells", i, sep =
""), j, sep = "_"))[,
which(colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j,
sep = "_"))) %in% bci.data$traits.abu.all.205$sp)]
                                        # reorder short names
according to trait data
        new.205 <- get(paste(paste("Abundance_gridcells", i, sep =
""), j, sep = "_"))[, bci.data$traits.abu.all.205$sp]
                                        # give full names to gridded
data
colnames(new.205) <- rownames(bci.data$traits.abu.all.205)
        gridlist <- c(gridlist, list(new.205))
    }
}

# name the grid list
gridlistnames <- NA
for (i in seq(5,100, 5)){    
    for (j in c(1990)){
        gridlistnames <- c(gridlistnames, paste(i,j, sep = "."))
    }    
}
gridlistnames <- gridlistnames[-1]
# create comma-separated name vector
cat(paste(shQuote(gridlistnames, type="cmd"), collapse=", "))

names(gridlist) <- c("5.1990", "10.1990", "15.1990", "20.1990",
"25.1990", "30.1990", "35.1990", "40.1990", "45.1990", "50.1990",
"55.1990", "60.1990", "65.1990", "70.1990", "75.1990", "80.1990",
"85.1990", "90.1990", "95.1990", "100.1990")

################
### end ###
################

# create co-occurrence distance-matrics
coocc.list <- list()
for (i in 1:length(gridlist)){
coocc.list <- c(coocc.list, list(species.dist(gridlist[[i]], metric =
"check")))
}

names(coocc.list) <- c("5.1990", "10.1990", "15.1990", "20.1990",
"25.1990", "30.1990", "35.1990", "40.1990", "45.1990", "50.1990",
"55.1990", "60.1990", "65.1990", "70.1990", "75.1990", "80.1990",
"85.1990", "90.1990", "95.1990", "100.1990")

bci.data$grid.205 <- gridlist

bci.data$coocc.check.205 <- coocc.list




# phylogenetic distances
phy.dist.206 <- as.dist(cophenetic(bci.data$phy206))

# co-occurrence scores
coocc.check.206.100.1990 <- species.dist(bci.data$grid100.90.206,
metric = "checkerboard")

coocc.cij.206.250.1990 <- species.dist(bci.data$grid250.90.206, metric
= "cij")
coocc.cij.206.100.1990 <- species.dist(bci.data$grid100.90.206, metric
= "cij")
coocc.cij.206.50.1990 <- species.dist(bci.data$grid50.90.206, metric =
"cij")
coocc.cij.206.20.1990 <- species.dist(bci.data$grid20.90.206, metric =
"cij")
coocc.cij.206.10.1990 <- species.dist(bci.data$grid10.90.206, metric =
"cij")
coocc.cij.206.5.1990 <- species.dist(bci.data$grid5.90.206, metric =
"cij")

coocc.check.206.250.1990 <- species.dist(bci.data$grid250.90.206,
metric = "checkerboard")
coocc.check.206.100.1990 <- species.dist(bci.data$grid100.90.206,
metric = "checkerboard")
coocc.check.206.50.1990 <- species.dist(bci.data$grid50.90.206, metric
= "checkerboard")
coocc.check.206.20.1990 <- species.dist(bci.data$grid20.90.206, metric
= "checkerboard")
coocc.check.206.10.1990 <- species.dist(bci.data$grid10.90.206, metric
= "checkerboard")
coocc.check.206.5.1990 <- species.dist(bci.data$grid5.90.206, metric =
"checkerboard")

coocc.doij.206.250.1990 <- species.dist(bci.data$grid250.90.206,
metric = "doij")
coocc.doij.206.100.1990 <- species.dist(bci.data$grid100.90.206,
metric = "doij")
coocc.doij.206.50.1990 <- species.dist(bci.data$grid50.90.206, metric
= "doij")
coocc.doij.206.20.1990 <- species.dist(bci.data$grid20.90.206, metric
= "doij")
coocc.doij.206.10.1990 <- species.dist(bci.data$grid10.90.206, metric
= "doij")
coocc.doij.206.5.1990 <- species.dist(bci.data$grid5.90.206, metric =
"doij")


plot(coocc.check.206.5.1990,coocc.check.206.100.1990)


####################################

colnames(bci.data$traits.abu.all)
match(rownames(bci.data$traits.abu.all), attr(phy.dist.206, "Labels"))

match(rownames(bci.data$traits.abu.all.205),
attr(bci.data$coocc.check.205[[10]], "Labels"))


# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(11,25,39)], scale
= T)$CA$u[,1:3]) # or 36 instead 25
# ! just for fun: try 85-90 census (but for now take coocc-scores from
the 90-95 census)
# make animation 

names(bci.data$coocc.check.205)

figlist <- list()
for (i in c(1:49)){ 
    # continue here
resp <- as.vector(bci.data$coocc.check.205[[i]])
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = names(bci.data$coocc.check.205)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )
figlist <- c(figlist, list(fig))  
} 

pdf(file = "Coocc.check.all.pdf", width = 35, height = 31,
pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],
    figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],
   figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],figlist[[19]],figlist[[20]],figlist[[21]],
   figlist[[22]],figlist[[23]],figlist[[24]],figlist[[25]],figlist[[26]],figlist[[27]],figlist[[28]], 
   figlist[[29]],figlist[[30]],figlist[[31]],figlist[[32]],figlist[[33]],figlist[[34]],figlist[[35]],
   figlist[[36]],figlist[[37]],figlist[[38]],figlist[[39]],figlist[[40]],figlist[[41]],figlist[[42]], 
    figlist[[43]],figlist[[44]],figlist[[45]],figlist[[46]],figlist[[47]],figlist[[48]],figlist[[49]],            
    ncol=7, nrow=7)
dev.off()


#####################
### calculate wo.rec.a (traits.1990)
#####################

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2]) 

figlist <- list()
for (i in c(1:49)){ 
    # continue here
resp <- as.vector(bci.data$coocc.check.205[[i]])
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = names(bci.data$coocc.check.205)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )
figlist <- c(figlist, list(fig))  
} 

pdf(file = "Coocc.check.all.wo.rec.a.pdf", width = 35, height = 31,
pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],
    figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],
   figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],figlist[[19]],figlist[[20]],figlist[[21]],
   figlist[[22]],figlist[[23]],figlist[[24]],figlist[[25]],figlist[[26]],figlist[[27]],figlist[[28]], 
   figlist[[29]],figlist[[30]],figlist[[31]],figlist[[32]],figlist[[33]],figlist[[34]],figlist[[35]],
   figlist[[36]],figlist[[37]],figlist[[38]],figlist[[39]],figlist[[40]],figlist[[41]],figlist[[42]], 
    figlist[[43]],figlist[[44]],figlist[[45]],figlist[[46]],figlist[[47]],figlist[[48]],figlist[[49]],            
    ncol=7, nrow=7)
dev.off()


#####################
### calculate (traits.1985)
#####################
colnames(bci.data$traits.abu.all.205)

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(7,21,35)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(4,18,32)], scale
= T)$CA$u[,1:3])

figlist <- list()
for (i in c(1:49)){ 
    # continue here
resp <- as.vector(bci.data$coocc.check.205[[i]])
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = names(bci.data$coocc.check.205)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )
figlist <- c(figlist, list(fig))  
} 

pdf(file = "Coocc.check.all.traits85.pdf", width = 35, height = 31,
pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],
    figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],
   figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],figlist[[19]],figlist[[20]],figlist[[21]],
   figlist[[22]],figlist[[23]],figlist[[24]],figlist[[25]],figlist[[26]],figlist[[27]],figlist[[28]], 
   figlist[[29]],figlist[[30]],figlist[[31]],figlist[[32]],figlist[[33]],figlist[[34]],figlist[[35]],
   figlist[[36]],figlist[[37]],figlist[[38]],figlist[[39]],figlist[[40]],figlist[[41]],figlist[[42]], 
    figlist[[43]],figlist[[44]],figlist[[45]],figlist[[46]],figlist[[47]],figlist[[48]],figlist[[49]],            
    ncol=7, nrow=7)
dev.off()


#####################
### calculate wo.rec.a (traits.1985)
#####################

# trait distances with prior PCA
niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(7,21,35)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(18,32)], scale =
T)$CA$u[,1:2])

figlist <- list()
for (i in c(1:49)){
    # continue here
resp <- as.vector(bci.data$coocc.check.205[[i]])
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = names(bci.data$coocc.check.205)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )
figlist <- c(figlist, list(fig))  
} 

pdf(file = "Coocc.check.all.traits85.wo.rec.a.pdf", width = 35, height
= 31, pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],
    figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],
   figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],figlist[[19]],figlist[[20]],figlist[[21]],
   figlist[[22]],figlist[[23]],figlist[[24]],figlist[[25]],figlist[[26]],figlist[[27]],figlist[[28]], 
   figlist[[29]],figlist[[30]],figlist[[31]],figlist[[32]],figlist[[33]],figlist[[34]],figlist[[35]],
   figlist[[36]],figlist[[37]],figlist[[38]],figlist[[39]],figlist[[40]],figlist[[41]],figlist[[42]], 
    figlist[[43]],figlist[[44]],figlist[[45]],figlist[[46]],figlist[[47]],figlist[[48]],figlist[[49]],            
    ncol=7, nrow=7)
dev.off()


#####################

figlist <- NA
for (i in 43:49){
figlist <- c(figlist, paste(paste("figlist[[", i, sep = ""), "]]", sep
= ""))
}

get(paste(paste("figlist[[", i, sep = ""), "]]", sep = ""))

###
gridlistnames <- NA
for (i in c(5,10,20,33,50,100,250)){    
    for (j in c(1982,1985,1990,1995,2000,2005,2010)){
        gridlistnames <- c(gridlistnames, paste(i,j, sep = "."))
    }    
}
gridlistnames <- gridlistnames[-1]
# create comma-separated name vector
cat(paste(shQuote(gridlistnames, type="cmd"), collapse=", "))
####

## search for particular functions using the "sos"-package
library(sos)

z <- findFn("phylo heatmap")
z

findFn(string = "phylo heatmap")

##########################################
## co-occurrence probability analysis according to Veech (2013) GEB:
##########################################
# run through the functions using the example data

library(cooccur)

data(finches)
cooccur.finches <- cooccur(mat=finches,
                                type="spp_site",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                           eff_matrix=F)

summary(cooccur.finches)
plot(cooccur.finches)

# converts occurrence probabilities into number into numbers according
to their significance:
# negative: -1
# random: 0
# positive: 1

ptab <- cooccur.finches$results
ptab$signs <- ifelse(ptab$p_gt >= 0.05, 0, 1) + ifelse(ptab$p_lt >=
0.05, 0, -1)

## run for BCI (20, 1990)
names(bci.data$grid.205)

## try for BCI (20, 2010)
# if changing years doesnt help also try:
# exclude rec.a
# use just the first PC axes
# changing scale (10m, 2010)

## changing years didnt help: after 20, try 10 m and after that try 33
m

# 1st try: 10m, 2010 (after that try 33m, 2010)

# ! save the entire output object

veech.20.1990 <- cooccur(mat=bci.data$grid.205[[17]],
                                type="site_spp",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                         eff_matrix=F)

summary(veech.20.1990)

plot(veech.20.1990)

bci.data$veech.cooccur <- list()

bci.data$veech.cooccur$veech.20.1990

# continue here
# 1) convert cooccurrence probs.
ptab <- veech.20.1990$results
ptab$signs <- ifelse(ptab$p_gt >= 0.05, 0, 1) + ifelse(ptab$p_lt >=
0.05, 0, -1)
names(ptab)

# 2) calculate SES
SES.20.1990 <- effect.sizes(veech.20.1990, standardized = T, matrix =
F)
names(SES.20.1990)

cbind(as.character(ptab$sp1_name), as.character(SES.20.1990$sp1))
cbind(ptab$sp1_name, SES.20.1990$sp1)

# 3) combine the two data sets:
cbind(ptab$sp1_name, SES.20.1990$sp1)
SES.ptab.20.1990 <- cbind(ptab, SES.20.1990[,3])

# 4) check whether order of species pairs matches to order of species
pairs from "species dist" (checkerboard)
coocc.check.205.20.1990 <- species.dist(bci.data$grid.205[[17]],
metric = "checkerboard")

###
> coocc.check.205.20.1990
                                 Terminalia_amazonia
Terminalia_oblonga
Terminalia_oblonga                       0.147393592                   
Mouriri_myrtilloides                     0.165853659       
0.162840746
Conostegia_cinnamomea                    0.308464849       
0.418938307
Miconia_nervosa                          0.279674797       
0.589574366

####
> as.vector(coocc.check.205.20.1990)
    [1] 0.147393592 0.165853659 0.308464849 0.279674797

###
> SES.ptab.20.1990[,10:13]
                              sp1_name                        
sp2_name signs
1                  Terminalia_amazonia              
Terminalia_oblonga     0
2                  Terminalia_amazonia            
Mouriri_myrtilloides     0
3                  Terminalia_amazonia           
Conostegia_cinnamomea     0
4                  Terminalia_amazonia                 
Miconia_nervosa     1

#####
# yes, the way in which distances are transformed into vectors (and
vice versa) are consistent!
########

# 5) analyse occurrence probs and effect sizes in relation to niche
and fitness diffs.
# trait distances with prior PCA
colnames(SES.ptab.100.1990)

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])
resp <- SES.ptab.100.1990[,13]
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "SES.100.1990.wo.rec.a"
            ,
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
fig

####

pdf("Veech.SES.100.1990.wo.rec.a.pdf", width=10, height = 10)
plot(fig)
dev.off()

###### run Hardy null models on checkerboard index

check <- species.dist(phylocom$sample, "check")
schoener <- species.dist(phylocom$sample, "cij")

plot(check,schoener)

library(spacodiR)

names(bci.data$grid.213)

com <- phylocom$sample
nullmod <- "1s"
metric <- "checkerboard"
runs <- 9

Coocc.Null <- function(com, nullmod, metric, runs){
    Coocc.shuff <- function(com, runs){
        Res = list()
        for (r in 1:runs) {
            Res <- c(Res, list(species.dist(x =
t(eval(parse(text=paste("resamp.", nullmod, sep = "")))(t(com))),
metric = metric)))
        }
        return(Res)
    }
    obs <- species.dist(x = com, metric = metric)
    obs <- as.vector(obs)
    resamp <- Coocc.shuff(com = com, runs = runs)
    resamp.vec <- as.data.frame(lapply(resamp, as.vector))
    rand.mean <- apply(resamp.vec, MARGIN = 1, FUN = mean, na.rm =
TRUE)
    rand.sd <- apply(resamp.vec, MARGIN = 1, FUN = sd, na.rm = TRUE)
    ses <- (obs - rand.mean)/rand.sd
    data.frame(obs, ses)
}

Coocc.2x.10.1990.check <- Coocc.Null(com = bci.data$grid.205[[10]],
nullmod = "1s", metric = "check", runs = 3)
    
Coocc.2x.20.1990.check
summary(Coocc.Null.20.1990.check)

plot(density(Coocc.1a.20.1990.check[,2], na.rm=T))

### run loop for null models on cooccurrence scores (and extract ses)
res <- NA
for (i in 2:20){
    res <- cbind(res, Coocc.Null(com = bci.data$grid.205[[i]], nullmod
= "1s", metric = "check", runs = 499)[,2])
    res
}
check.205.ses.1s <- res[,-1]

colnames(check.205.ses.1s) <- names(bci.data$grid.205)[2:20]
bci.data$check.205.ses.1s <- check.205.ses.1s

save(bci.data, file = "bci.data.Rdata")


names(bci.data$grid.205)[c(3,10,17,24,31,38,45)]

# test whether cij and doij are differnt for presence-absence or
abundance data:
data(phylocom)
cij.abu <- species.dist(phylocom$sample, metric = c("cij"))
cij.pa <- species.dist(decostand(phylocom$sample, "pa"), metric =
c("cij"))
cor(cij.abu, cij.pa)
plot(cij.abu, cij.pa)
# yes, is different for abundance data

doij.abu <- species.dist(phylocom$sample, metric = c("doij"))
doij.pa <- species.dist(decostand(phylocom$sample, "pa"), metric =
c("doij"))
cor(doij.abu, doij.pa)
plot(doij.abu, doij.pa)

# no, is not different from abundance data

# how about veech
veech.50.1990.abu <- cooccur(mat=bci.data$grid.205[[31]],
                                type="site_spp",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                         eff_matrix=F)

veech.50.1990.pa <- cooccur(mat=decostand(bci.data$grid.205[[31]],
"pa"),
                                type="site_spp",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                         eff_matrix=F)

SES.veech.50.1990.abu <- effect.sizes(veech.50.1990.abu, standardized
= T, matrix = F)
SES.veech.50.1990.pa <- effect.sizes(veech.50.1990.pa, standardized =
T, matrix = F)

cor(SES.veech.50.1990.abu[,3], SES.veech.50.1990.pa[,3])
plot(SES.veech.50.1990.abu[,3], SES.veech.50.1990.pa[,3])

# yes, veech is highly correlated irrespective whether abundance or
presence-absence data is used

###############
# 1) re-run cij ~ niche * fitness analyis for presence absence data
(across spatial scales but just for the 1990 census)

# create co-occurrence distance-matrics
coocc.list <- list()
for (i in 1:length(bci.data$grid.205)){
coocc.list <- c(coocc.list,
list(species.dist(decostand(bci.data$grid.205[[i]],"pa"), metric =
"cij")))
}

names(coocc.list) <- c("5.1982", "5.1985", "5.1990", "5.1995",
"5.2000", "5.2005", "5.2010", "10.1982", "10.1985", "10.1990",
"10.1995", "10.2000", "10.2005", "10.2010", "20.1982", "20.1985",
"20.1990", "20.1995", "20.2000", "20.2005", "20.2010", "33.1982",
"33.1985", "33.1990", "33.1995", "33.2000", "33.2005", "33.2010",
"50.1982", "50.1985", "50.1990", "50.1995", "50.2000", "50.2005",
"50.2010", "100.1982", "100.1985", "100.1990", "100.1995", "100.2000",
"100.2005", "100.2010", "250.1982", "250.1985", "250.1990",
"250.1995", "250.2000", "250.2005", "250.2010")

bci.data$coocc.cij.205.pa <- coocc.list

# do lattice plot:

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2]) 

figlist <- list()
for (i in c(3,10,17,24,31,38,45)){ 
    # continue here
resp <- as.vector(bci.data$coocc.cij.205.pa[[i]])
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = names(bci.data$coocc.cij.205.pa)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )
figlist <- c(figlist, list(fig))  
} 

pdf(file = "Coocc.cij.all.wo.rec.a.pa.pdf", width = 35, height = 4.5,
pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],ncol=7,
nrow=1)
dev.off()
######


# 2) do FINAL lattice plot for "check.1990.wo.rec.a" just for 1990 and
the 7 spatial scales

# 2.1) do with RDA

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])

# 2.2) without RDA + without scaling

niche.dist <- dist((bci.data$traits.abu.all.205[ ,c(14,28,42)]))
fit.dist <- dist((bci.data$traits.abu.all.205[ ,c(25,39)]))

# 2.3) new fitness measure (growth.mean/mort.mean)
niche <- (rda(bci.data$traits.abu.all.205[ ,c(14,28,42)], scale =
F)$CA$u[,1:3])

summary((prcomp(bci.data$traits.abu.all.205[ ,c(14,28,42)]))$x)

niche.dist <- dist(niche)
fit <- ((bci.data$traits.abu.all.205[ ,c(25)]) /
(bci.data$traits.abu.all.205[ ,c(39)]))
fit.dist <- dist(fit)

niche.fit.dist <- list("niche.dist"=niche.dist, "fit.dist" = fit.dist)
save(niche.fit.dist, file = "niche.fit.dist.Rdata")

niche.fit <- (cbind(niche, fit))
niche.fit.scale <- scale(cbind(niche, fit))
niche.dist <- dist(niche.fit.scale[,1:3])
fit.dist <- dist(niche.fit.scale[,4])

# plot(fit.dist, fit.dist.new)


colnames(bci.data$check.205.ses.1s) <- paste(seq(10,100,5), " m", sep
= "")

figlist <- list()
for (i in 1:19){ 
    # continue here    
        resp <- bci.data$check.205.ses.1s[,i]
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- (as.vector(niche.dist))
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- (as.vector(fit.dist))
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50) # !! needs
to be corrected to max(niche) and min(niche)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50) #
change back to fitness
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))   
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
                   labels = F,
                 contour = F,
            xlab = "Light response differences",
            ylab = "Demographic differences",
            main = colnames(bci.data$check.205.ses.1s)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
           ,
                   panel = function(x,y,z,...){
              panel.contourplot(x,y,z,...)
              panel.abline(0,1,lwd=1,col="blue")
                   }
            )   
    fig
    
pdf(file = paste(paste("Coocc.check.wo.rec.a.fit_new.scale_no.woPCA.",
i, sep=""), "pdf", sep="."), width = 5, height = 4.6, pointsize=12)
#jpeg(filename = paste(paste("Coocc.check.wo.rec.a.spat.", i, sep=""),
"jpeg", sep="."), width = 240, height = 226, quality = 100)
plot(fig)
dev.off()
figlist <- c(figlist, list(fig))  
}


pdf(file = "Coocc.check.wo.rec.a.fit_new.15.100.scale_no.woPCA.pdf",
width = 41, height = 8, pointsize=12)
grid.arrange(
    figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],figlist[[19]],ncol=9,
nrow=2)
dev.off()

# save as .eps:
#postscript(file = "Coocc.check.wo.rec.a.spat.5-100.eps", width = 15,
height = 9, horizontal = FALSE, onefile = T, pointsize=12)
pdf(file = "Coocc.check.wo.rec.a.spat.5-100.SES.pdf", width = 15,
height = 9, pointsize=12)
grid.arrange(
    figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],ncol=9,
nrow=2)
dev.off()

summary(bci.data$check.205.ses.1a)

### plot density of SES-values
plot(density(bci.data$check.205.ses.1s[,10]))

# Tuesday, continue here!!
# next steps: 
# 1) scaling of standardized regression coefficients
# 2) identify species pairs (3-4 pairs each) with a) maximally high,
b) maximally low niche differences, c) ... high fitness diffs., d)
...low fitness diffs., e) high niche but low fit. diffs., f) low niche
but high fit. diffs. (use histograms based on distance matrices to
determine large and small differences, also use order distance
matrices aka Legendre-book)
# -> do species with high or low difference have high or low
cooccurrence frequencies at a particular scale?
# 3) vice versa to 2): identify, at each spatial scale, species pairs
with very high and very low checkerboard scores -> do those pairs
correspond to high/low niche diffs. and high/low fitness differences

pca.traits.b <- rda(bci.data$traits.abu.all.205[ ,c(14,28,42)], scale
= F)

#Importance of components:
#                         PC1     PC2     PC3
#Eigenvalue            0.3783 0.03385 0.01420
#Proportion Explained  0.8873 0.07939 0.03331
#Cumulative Proportion 0.8873 0.96669 1.00000

pdf("pca.traits.b.no_scale.pdf", width = 8, height = 6)
fig <- ordiplot(pca.traits.b, type = "none", xlim = c(-1.5,3),
ylim=c(-1,1))
points(fig, "sites", pch=19, col="red")
text(fig, "species", col="blue", cex=0.9)
dev.off()

#  scaling of model coefficients

niche.fit.scaled <- as.data.frame((cbind(niche, fitness)))

modelcoef <- NA

for (i in 1:19){
resp.vec <- bci.data$check.205.ses.1s[,i]
mod <- lm(resp.vec ~ niche*fitness, data = niche.fit.scaled)                   
modelcoef <- rbind(modelcoef, melt(summary(mod)$coefficients))
}
modelcoef <- modelcoef[-1,]
modelcoef$scale <- rep(seq(10,100,5), each=16)
colnames(modelcoef)[c(1:2)] <- c("variable", "coefficient")
str(modelcoef)

modelcoef$variable <- as.character(modelcoef$variable)
modelcoef$coefficient <- as.character(modelcoef$coefficient)

 ##

modelcoef.estim <- modelcoef[modelcoef$coefficient=="t value",]
modelcoef.estim.2 <-
modelcoef.estim[modelcoef.estim$variable!="(Intercept)",]
modelcoef.estim.2 <-
modelcoef.estim.2[modelcoef.estim.2$variable!="niche.vec:fit.vec",]

modelcoef.estim.3 <- modelcoef.estim.2[,-2]
# scale >15
modelcoef.estim.4 <- modelcoef.estim.3[modelcoef.estim.3$scale > 15, ]
modelcoef.estim.4$variable <- as.factor(modelcoef.estim.4$variable)
modelcoef.estim.4$value <- -(modelcoef.estim.4$value)
modelcoef.estim.5 <- modelcoef.estim.4

# rerun for t-value

# do the lattice plot
# include interaction
div <- xyplot(value ~ scale, groups=variable, data =
modelcoef.estim.4, type = "l", lty = c(1), par.settings =
list(axis.line = list(col = 0)),scales=list(col=1,tck=c(-1,0)),  #
remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 4.5)
                panel.abline(h=0,lwd=1, lty=2, col="black")
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 2.5, col = c("red","green","black"), xlab = "Scale (m)", ylab =
"Correlation", key=list(space="inside",  between = 1, padding.text =
2, just = c(.6, .5), columns = 1, lines = list(lty = c(1), lwd = 2.5,
col = c("red","green","black")),text = list(c("Fitness diff.",
"Niche.diff", "Niche x Fitness"))))
plot(div)

pdf(file = "Scales.t_value.inter.PCA1-3.coef.scale.pdf",width = 4.2,
height = 4, pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

####
# without interaction
div <- xyplot(value ~ scale, groups=variable, data =
subset(modelcoef.estim.4, variable != "niche:fitness"), type = "l",
lty = c(1), par.settings = list(axis.line = list(col =
0)),scales=list(col=1,tck=c(-1,0)),  # remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 4.5)
                panel.abline(h=0,lwd=1, lty=2, col="black")
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 2.5, col = c("red","green","black"), xlab = "Scale (m)", ylab =
"Correlation", key=list(space="inside",  between = 1, padding.text =
2, just = c(.6, .5), columns = 1, lines = list(lty = c(1), lwd = 2.5,
col = c("red","green")),text = list(c("Fitness diff.",
"Niche.diff"))))
plot(div)

pdf(file = "Scales.t_value.nointer.PCA1-3.coef.nonscale.pdf",width =
4.2, height = 4, pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

#################
######## repeat analysis for the 213 species for which complete trait
data from the 2nd census is available
# also try analysis with 308 (partly imputed) species:
# bci.data$traits.abu.308.full
# 1) prune species for which all traits are available:
"rec.light.mean2"    "growth.light.mean2" "mort.light.mean2"

colnames(bci.data$traits.abund.all[,c(1,14,28,42,25,39)])

traits.abu.308.niche.fit.2 <- bci.data$traits.abund.all[,c(1,14,28,42,25,39)]
index <- (is.na(rowMeans(traits.abu.308.niche.fit.2[,c(2:6)]))==F)

traits.abu.213 <- traits.abu.308.niche.fit.2[index,]
str(traits.abu.213)

# match to the species in the abundance grid
# read all files:
path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/5m_Steps/"
temp <- list.files(path, pattern="*.txt")
for(file in temp)
{
    perpos <- which(strsplit(file, "")[[1]]==".")
    assign(
        gsub(" ","",substr(file, 1, perpos-1)), 
        read.table(paste(path,file,sep="")))
}

# rename colnames of the 5-m grid to upper case letter
colnames(Abundance_gridcells5_1990) <- toupper(colnames(Abundance_gridcells5_1990))

# match the grids

i <- 20
j <- 1990

gridlist <- list()
for (i in seq(5,100, 5)){
    for (j in c(1990)){ 
                                        # just if there are several years        
        # i <-20
        colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_")))[which(colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"))) %in% traits.abu.213$sp == FALSE)]
        as.character(traits.abu.213$sp)[which(as.character(traits.abu.213$sp) %in% colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"))) == FALSE)]
        
        traits.abu.213$sp <- as.character(traits.abu.213$sp)
        new.205 <- get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"))[, which(colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"))) %in% traits.abu.213$sp)]
                                        # reorder short names according to trait data
        new.205 <- get(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"))[, traits.abu.213$sp]
                                        # give full names to gridded data
colnames(new.205) <- rownames(traits.abu.213)
        gridlist <- c(gridlist, list(new.205))    
    }
}

# name the grid list
gridlistnames <- NA
for (i in seq(5,100, 5)){    
    for (j in c(1990)){
        gridlistnames <- c(gridlistnames, paste(i,j, sep = "."))
    }    
}
gridlistnames <- gridlistnames[-1]
# create comma-separated name vector
cat(paste(shQuote(gridlistnames, type="cmd"), collapse=", "))

names(gridlist) <- c("5.1990", "10.1990", "15.1990", "20.1990",
"25.1990", "30.1990", "35.1990", "40.1990", "45.1990", "50.1990",
"55.1990", "60.1990", "65.1990", "70.1990", "75.1990", "80.1990",
"85.1990", "90.1990", "95.1990", "100.1990")

# create co-occurrence distance-matrics
coocc.list <- list()
for (i in 1:length(gridlist)){
coocc.list <- c(coocc.list, list(C.score(gridlist[[i]], normalise =
TRUE, FUN=print)))
}

bci.data$grid.213 <- gridlist

bci.data$coocc.check.213 <- coocc.list
save(bci.data, file = "bci.data.Rdata")



################################
# check whether trait and grid data match:
# species names:
match(colnames(gridlist[[1]]), rownames(traits.abu.213))
# yes, they match

# do the trait.values in traits.abu.213 match to
traits.abu.308.niche.fit.2:
head(traits.abu.308.niche.fit.2)
head(traits.abu.308.niche.fit.2)
match(rownames(traits.abu.308.niche.fit.2), rownames(traits.abu.213))
# yes, they match up

# do the abundance values in i.e.gridlist[[3]] match to
Abundance_gridcells15_1990:
# yes, they match


##############
# to do #
##############
# 1) data checking: i) traits data in the right order?, 

# ii) calculate new niche and fitness distances:
# to do thursday morning

# 2) remove clutter from null 3t

obj=t(bci.data$grid.213[[20]][1:5,1:5])

resamp.3t <- function (obj, dmat = NULL) 
{
    if (is.null(dmat)) 
        flag = TRUE
    else flag = FALSE
    names.orig = names(obj) # plot names
    names(obj) = seq(1:ncol(obj))
    if (is.null(dmat)) {
        dmat = as.data.frame(matrix(0, ncol(obj), ncol(obj)))
        names(dmat) = names.orig
        row.names(dmat) = names.orig
    }
    dmat = as.data.frame(as.matrix(dmat))
    if (!all(names(dmat) %in% names.orig) || ncol(obj) != ncol(dmat)
|| 
        ncol(dmat) != nrow(dmat)) 
        stop("Names in distance matrix do not correspond to plot
names")
    row.names(dmat) = names(obj)
    names(dmat) = names(obj)
    torus = rep(1:ncol(obj), 2)
    plus.array = array(dim = c(1, ncol(obj)))
    torus.array = array(dim = c(ncol(obj), ncol(obj)))
    for (plus in 1:ncol(obj)) {
        for (tt in 1:ncol(torus.array)) {
            from = tt
            to = torus[tt + plus]
            d.tt = dmat[from, to]
            torus.array[tt, plus] = d.tt
        }
        plus.array[1, plus] = mean(torus.array[, plus], na.rm = TRUE)
    }
    plus.array = as.data.frame(plus.array)
    names(plus.array) = names(obj)
    plus.array = plus.array[, order(plus.array)]
    for (ss in 1:nrow(obj)) {
        if (!flag) {
            shifter =
as.numeric(names(plus.array))[min(which(plus.array >= 
                runif(1, min = min(plus.array), max =
max(plus.array))))]
        }
        else {
            shifter = sample(as.numeric(names(plus.array)), 1)
        }
        t.array = array(dim = c(ncol(obj), 2))
        t.array[, 1] = 1:ncol(obj)
        for (o in 1:ncol(obj)) {
            tt = torus[shifter + (o - 1)]
            t.array[tt, 2] = obj[ss, o]
        }
        obj[ss, ] = t.array[, 2]
    }
    if (flag) 
        message("Plots were assumed to be equidistant from one
another.")
    res = obj
    names(res) = names.orig
    return(res)
}

# 3) run 3t (and 3x for comparison)

# 3x: (try for 3 interations first)

library(doParallel)
# Find out how many cores are available (if you don't already know)
detectCores()
# Create cluster with desired number of cores
cl <- makeCluster(3)

# Register cluster
registerDoParallel(cl)

# Find out how many cores are being used
getDoParWorkers()

data(phylocom)
# com <- phylocom$sample
com <-  bci.data$grid.213[[19]]
nullmod <- "3x"
metric <- "checkerboard"
runs <- 9

Coocc.Null <- function(com, nullmod, metric, runs){
    Coocc.shuff <- function(com, runs){
        # Res = list() # delete
        x <- foreach(r = 1:runs, .combine = cbind) %dopar% {
            # as.vector(picante::species.dist(x = t(spacodiR::resamp.3x(t(com), level = 0.6)), metric = "checkerboard"))
# adapt concentenate function in foreach
            as.vector(bipartite::C.score(t(spacodiR::resamp.3x(t(com), level = 0.6)), normalise = TRUE, FUN = print)) # adapt concentenate function in foreach
  
        }
    }
    # obs <- species.dist(x = com, metric = metric)
    obs <- C.score(com, normalise = TRUE, FUN = print)
    obs <- as.vector(obs)
    resamp <- Coocc.shuff(com = com, runs = runs)
    #resamp.vec <- as.data.frame(lapply(resamp, as.vector)) # adapt
    rand.mean <- apply(resamp, MARGIN = 1, FUN = mean, na.rm = TRUE)
    rand.sd <- apply(resamp, MARGIN = 1, FUN = sd, na.rm = TRUE)
    ses <- (obs - rand.mean)/rand.sd
    data.frame(obs, ses)
}

system.time(
Coocc.3x.10.1990.check <- Coocc.Null(com = bci.data$grid.213[[19]],
nullmod = "3x", metric = "check", runs = 9)
)

# 19.363 sec. on one core
    
summary(Coocc.3x.10.1990.check)

plot(density(bci.data$check.213.ses.3t[,3], na.rm=T))
hist(bci.data$check.213.ses.3t[,2], na.rm=T)

### run loop for null models on cooccurrence scores (and extract ses)
res <- NA
system.time(
for (i in 18:20){
    res <- cbind(res, Coocc.Null(com = bci.data$grid.213[[i]], nullmod = "3x", metric = "check", runs = 99)[,2])
    res
}
)
check.213.ses.3x <- res[,-1]

colnames(check.213.ses.3x) <- names(bci.data$grid.213)[15:20]
bci.data$check.213.ses.3x <- check.213.ses.3x

save(bci.data, file = "bci.data.Rdata")


# 4) use 3i as random observed community
# done on Rstudio server

# 4.1) substitute NA values with 0
check.213.ses.3i.no.na <- bci.data$check.213.ses.3i
check.213.ses.3i.no.na[is.na(bci.data$check.213.ses.3i)] <- 0
head(check.213.ses.3i.no.na)
summary(check.213.ses.3i.no.na)


# data <- check.213.ses.3i.no.na # for substituted data
data <- bci.data$check.213.ses.3t
pdf("SES.check.3t.w.na.pdf", width = 12, height = 7)
par(mfrow=c(3,6))
for (i in 1:dim(data)[2]){
    hist(data[,i], xlim=c(-6,6), main = colnames(data)[i],
xlab="SES.check.3t.w.na")
    abline(v=c(-2,2), col= "red", lty=2)
}
dev.off()


# 5) calculate cooccurrence according to Veech 2013 (observed and
standardized effect sizes)
# run in foreach loop on cluster

x <- foreach(i = 18:20, .combine = c) %dopar% {
    list(cooccur::cooccur(mat=bci.data$grid.213[[i]],
                                type="site_spp",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                         eff_matrix=F)$results)
}

str(x)
length(x)

summary(x[[8]])


SES.100.1990 <- effect.sizes(veech.100.1990, standardized = T, matrix = F)

summary(veech.20.1990)

## check order of veech matrix
library(bipartite)

m <- matrix(c(1,0,0, 1,1,0, 1,1,0, 0,1,1, 0,0,1), 5,3,TRUE)
test1 <- C.score(m, normalise=FALSE, FUN=print)
as.vector(test1)

test2 <- cooccur(mat=as.data.frame(m),type="site_spp",
                                thresh=F,
                                spp_names=TRUE,
                           only_effects=F,
                           eff_standard=T,
                         eff_matrix=F)
test2$results
effect.sizes(test2, matrix = T)
# yes, right order

# get bci.data with veech-cooccur output from R-server

load(paste(path.data, "bci.data.Rdata", sep = ""))
names(bci.data)

# calculate effect sizes
ses <- foreach(i = 1:18, .combine = cbind) %dopar% {
  cooccur::effect.sizes(bci.data$veech213.15.100[[i]], standardized =
T, matrix = F)$effect
}

ses <- as.data.frame(ses)
colnames(ses) <- names(bci.data$veech213.15.100)
  
summary(ses)

bci.data$veech213.15.100.ses <- ses

# $ obs_cooccur
obs <- foreach(i = 1:18, .combine = cbind) %dopar% {
  bci.data$veech213.15.100[[i]]$results$obs_cooccur
}

obs <- as.data.frame(obs)
colnames(obs) <- names(bci.data$veech213.15.100)
  
summary(obs)

bci.data$veech213.15.100.obs <- obs


# $ prob_cooccur
prob <- foreach(i = 1:18, .combine = cbind) %dopar% {
  bci.data$veech213.15.100[[i]]$results$prob_cooccur
}

prob <- as.data.frame(prob)
colnames(prob) <- names(bci.data$veech213.15.100)
  
summary(prob)

bci.data$veech213.15.100.prob <- prob

names(bci.data)
save(bci.data, file = "bci.data.Rdata")
# !!! this Rdata-file is much smaller after saving the Veech stuff
str(bci.data$veech213.15.100)

################################
# calculate niche differences ##
################################

####################
# a) raw distances: 
####################
# i) rec, gro, mor
colnames(traits.abu.213[, c(2,3,4)])
niche.diff.raw3 <- as.vector(dist(traits.abu.213[, c(2,3,4)]))

# ii)  rec, gro
colnames(traits.abu.213[, c(2,3)])
niche.diff.raw2 <- as.vector(dist(traits.abu.213[, c(2,3)]))

# iii: rec
colnames(traits.abu.213[, c(2)])
niche.diff.raw1 <- as.vector(dist(traits.abu.213[, c(2)]))

################
# b) using PCA (on all 3 traits):
################ 
# i) pca1-3
PCA <- prcomp(traits.abu.213[ ,c(2,3,4)])
niche.diff.pca3 <- as.vector(dist(scores(PCA, choices=c(1,2,3))))

# ii) pca1-2
niche.diff.pca2 <- as.vector(dist(scores(PCA, choices=c(1,2))))

# iii) pca1
niche.diff.pca1 <- as.vector(dist(scores(PCA, choices=c(1))))

# check of species names on these distance matrices, do they
(as.matrix) match with the names on the grid.213

[43] "Phylo.Check.spat.10.100"  "grid.213"                
[45] "coocc.check.213"          "check.213.ses.3x"        
[47] "check.213.ses.3i"         "check.213.ses.3t"        
[49] "veech213.15.100"          "veech213.15.100.ses"     
[51] "veech213.15.100.obs"      "veech213.15.100.prob"  

str(bci.data$grid.213[[3]])
colnames(bci.data$grid.213[[3]])[1:10]

str(dist(prcomp(traits.abu.213[ ,c(2,3)])$x))

match(colnames(bci.data$grid.213[[3]]),
labels(dist(prcomp(bci.data$traits.abu.213[ ,c(2,3)])$x)))
# yes, the names on the niche-distance matrix matches with the names
on the abundance grids which were used for the calculation of the
cooccurence scores

# check structure of the cooccurence data sets, and put them (where
required) in a matrix form:
str(bci.data$coocc.check.213) # list of 20 lists needs to be reshaped
into data.frame (only take 18 largest scales)
coocc.vec <- as.data.frame(lapply(bci.data$coocc.check.213,
as.vector))
str(coocc.vec)
check.213.df <- coocc.vec[,3:20]
colnames(check.213.df) <- colnames(bci.data$veech213.15.100.ses)
### 1. -> check.213.df

str(bci.data$check.213.ses.3x) # matrix with 18 columns
check.213.ses.3x.df <- as.data.frame(bci.data$check.213.ses.3x)
check.213.ses.3x.df[is.na(bci.data$check.213.ses.3x)] <- 0
# replace NA
str(check.213.ses.3x.df)
### 2. -> check.213.ses.3x.df

str(bci.data$check.213.ses.3i) # dito
check.213.ses.3i.df <- as.data.frame(bci.data$check.213.ses.3i)
check.213.ses.3i.df[is.na(bci.data$check.213.ses.3i)] <- 0
# replace NA
str(check.213.ses.3i.df)
### 3. -> check.213.ses.3i.df

str(bci.data$check.213.ses.3t) # dito
check.213.ses.3t.df <- as.data.frame(bci.data$check.213.ses.3t)
check.213.ses.3t.df[is.na(bci.data$check.213.ses.3t)] <- 0
# replace NA
str(check.213.ses.3t.df)
### 4. -> check.213.ses.3t.df

str(bci.data$veech213.15.100.ses) # data.frame with 18 columns
veech213.ses.df <- bci.data$veech213.15.100.ses
### 5. -> veech213.ses.df

str(bci.data$veech213.15.100.obs) # dito
veech213.obs.df <- bci.data$veech213.15.100.obs
### 6. -> veech213.obs.df

str(bci.data$veech213.15.100.prob) # dito
veech213.prob.df <- bci.data$veech213.15.100.prob
### 7. -> veech213.prob.df

# combine coocc-data under a list in bci.data:
coocc.213 <- list("check.213.df" = check.213.df, "check.213.ses.3x.df"
= check.213.ses.3x.df, "check.213.ses.3i.df" = check.213.ses.3i.df,
"check.213.ses.3t.df" = check.213.ses.3t.df, "veech213.ses.df" =
veech213.ses.df, "veech213.obs.df" = veech213.obs.df,
"veech213.prob.df" = veech213.prob.df)
str(coocc.213)
bci.data$coocc.213 <- coocc.213

save(bci.data, file = "bci.data.Rdata")


###########
# put niche distances (based on both raw and PCA trait distances, see
above) as vectors in one data.frame

niche.dist.213.df <- cbind(niche.diff.raw3, niche.diff.raw2,
niche.diff.raw1, niche.diff.pca3, niche.diff.pca2, niche.diff.pca1)

head(niche.dist.213.df)
bci.data$niche.dist.213.df <- as.data.frame(niche.dist.213.df)
save(bci.data, file = "bci.data.Rdata")

head(bci.data$niche.dist.213.df)

CorTestPlot(bci.data$niche.dist.213.df)


################################
# plot the surfaces for all 6 variants of niche difference and the
following response variables ##
################################
# !!
# a) C.score (scaled, but wo null model)
# b) check.3t
# c) check.3x
# d) check.3i
# e) veech.obs
# f) veech.prob
# g) veech.ses

#######################################################
#### set up function that loops, for a given response variable (e.g.
check.df), over i) all 18 scales (15-100m) -> (inner foreach-loop) and
ii) the 6 versions of niche differences (outer for-loop):
#######################################################

bci.data$traits.abu.213 <- traits.abu.213

colnames(bci.data$traits.abu.213)
# fit.dist <- dist(bci.data$traits.abu.213[,5] /
bci.data$traits.abu.213[,6])

# for "fitnessSMA"
fit.dist <- dist(bci.data$traits.abu.213[,8])

####### continue here ###!!1
# for "logratio"
fit.dist <- dist(bci.data$traits.abu.213[,9])
str(fit.dist)

## start the function:
# figlist <- list()

# resp <- check.213.df # to be changed accordingly
niche <- bci.data$niche.dist.213.df[,1]
fitness <- (as.vector(fit.dist))

i <- 10 # scale
j <- 5 # cooc-response variable

library(doParallel)
# Find out how many cores are available (if you don't already know)
detectCores()
# Create cluster with desired number of cores
cl <- makeCluster(3)

# Register cluster

registerDoParallel(cl)

# Find out how many cores are being used
getDoParWorkers()

for (j in 1:7){ # loop across cooc-response variable (7 variants)
    coocc <- bci.data$coocc.213[[j]]
    figlist <- foreach (i = 1:18, combine = list, .packages='lattice')
%dopar% { # loop across scales (grain sizes)
    resp <-coocc[,i]
    phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1)
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))   
fig <- lattice::contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
                   labels = F,
                 contour = F,
            xlab = "Light response differences",
            ylab = "Demographic differences",
            main = colnames(coocc)[i]
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
           #,
            #       panel = function(x,y,z,...){
            #  panel.contourplot(x,y,z,...)
            #  panel.abline(0,1,lwd=1,col="blue")
             #      }
            )   
    #fig
    
# pdf(file = paste(paste("Check.213.", i, sep=""), "pdf", sep="."),
width = 5, height = 4.6, pointsize=12)
#jpeg(filename = paste(paste("Coocc.check.wo.rec.a.spat.", i, sep=""),
"jpeg", sep="."), width = 240, height = 226, quality = 100)
#plot(fig)
#dev.off()
#list(fig)
        fig
    }
    
pdf(file = paste(paste("Coocc.213.fitLogRatio", j, sep=""), "pdf",
sep="."),
width = 41, height = 8, pointsize=12)
grid.arrange(
    figlist[[1]],figlist[[2]],figlist[[3]],figlist[[4]],figlist[[5]],figlist[[6]],figlist[[7]],figlist[[8]],figlist[[9]],figlist[[10]],figlist[[11]],figlist[[12]],figlist[[13]],figlist[[14]],figlist[[15]],figlist[[16]],figlist[[17]],figlist[[18]],ncol=9,
nrow=2)
dev.off()
}

#### continue here (Friday afternoon):
# select most aggregated and most segregated species pairs:

names(bci.data$veech213.15.100)

summary(bci.data$veech213.15.100[[1]])
head(bci.data$veech213.15.100[[1]]$results)
summary(bci.data$veech213.15.100[[1]]$results$p_lt)

library(dplyr)
library(foreach)

i <- 18

x <- bci.data$veech213.15.100

veech.low.hi <- foreach (i = 1:18, .combine = rbind,
.packages='dplyr') %dopar% {
    df <- x[[i]]$results[,8:11]
    df.lo <- arrange(df, p_lt)[1:10,]
    df.hi <- arrange(df, p_gt)[1:10,]
    df.bind <- rbind(df.lo, df.hi)
    df.bind$scale <- names(bci.data$veech213.15.100)[i]
    df.bind
}

dim(veech.low.hi)

save(veech.low.hi, file = "veech.low.hi.Rdata")
load("veech.low.hi.Rdata")

# check whether order of species pairs in veech.data corresponds to
species pairs in 
# if yes, put species1 and species2 names as rownames on those vectors
head(bci.data$veech213.15.100$results)
bci.data$veech213.15.100[[1]]$results[1:250,c(1,2,10,11)]

PCA <- prcomp(bci.data$traits.abu.213[ ,c(2,3,4)])
niche.diff.pca3 <- as.vector(dist(scores(PCA, choices=c(1,2,3))))
str(niche.diff.pca3)
niche.diff.pca3 <- as.data.frame(niche.diff.pca3)

niche.diff <- cbind(bci.data$veech213.15.100[[1]]$results[,c(10,11)],
niche.diff.pca3)
niche.diff.pca3.mat <- as.matrix(niche.diff.pca3.dist)

as.dist(niche.diff.pca3.mat[1:3,1:3])
head(niche.diff)
# yes, the names match up
# put names of species pairs on niche and fitness diffs. data set
# first combine niche and fitness differences into one data set


fitness.dist <- as.vector(dist(bci.data$traits.abu.213[,5]) /(bci.data$traits.abu.213[,6]))

fitness.dist.2 <- as.vector(dist(bci.data$traits.abu.213[,5] /bci.data$traits.abu.213[,6]))
plot(fitness.dist, fitness.dist.2)

a <- bci.data$traits.abu.213[,5]) / bci.data$traits.abu.213[,6]

niche.fitness.dist.213.df <- cbind(bci.data$niche.dist.213.df,fitness.dist, bci.data$veech213.15.100[[1]]$results[,c(10,11)])
names(niche.fitness.dist.213.df)

bci.data$niche.dist.213.df

str(bci.data$coocc.213)

# put species pair names from veech on niche distance vector:

    
    
######## load new fitness measures:
fit.new <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abun/new_fitness_measures.txt")
head(fit.new)
names(bci.data$traits.abu.213)
fit.new.213 <- fit.new[match(bci.data$traits.abu.213$sp, fit.new$sp),]
fit.new.213[1:20,c(1,2,7,8,9)]
names(fit.new.213)
names(bci.data$traits.abu.213)
match(fit.new.213$demo.growth.mean2,
bci.data$traits.abu.213$growth.mean2)
bci.data$traits.abu.213 <- cbind(bci.data$traits.abu.213,
fit.new.213[,c(1,8,9)])
head(bci.data$traits.abu.213)
CorTestPlot(bci.data$traits.abu.213[,c(2:6,8,9)])
save(bci.data, file = "bci.data.Rdata")

# calculate (for all 18 scales)
    
# to do:
# 1) check why results for 213 species set differ from the 205 species set
# run normalized C.score (bipartite) without null model on grid.205and link to new niche (raw3) and fitness differences
# 2) try doij and cij indices for 213 species set 
# to do: calculate abundance based indices

############################################################################
#### re-run all of the analysis for the habitat classes and light levels
############################################################################

#  start with habitat types
# ... and for light levels

# read all files:
path <-
"/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/Light_Levels/"
temp <- list.files(path, pattern="*.txt")
for(file in temp) {
    perpos <- which(strsplit(file, "")[[1]]==".")
    assign(
        gsub(" ","",substr(file, 1, perpos-1)), 
        read.table(paste(path,file,sep="")))
}

# match the grids

# example for 40m scale and slope:

i <- 20
j <- "1990_lowplateau"

bci.data$traits.abu.213$sp <- as.character(bci.data$traits.abu.213$sp)

# run separately for the different habitat types "1990_hiplateau",
"1990_lowplateau", "1990_slope"
# ... and for the different light levels "1990_highlight3",
"1990_lowlight3", "1990_medlight3"

gridlist <- list()
for (i in seq(20,100, 20)){
    for (j in c("1990_medlight3")){ # just if there are several years
        # get the species names in
"Abundance_gridcells100_1990_medlight3", select which of them are in
"traits.abu.213"
        colnames(get(paste(paste("Abundance_gridcells", i, sep = ""),
j, sep = "_")))[which(colnames(get(paste(paste("Abundance_gridcells",
i, sep = ""), j, sep = "_"))) %in% bci.data$traits.abu.213$sp ==
TRUE)] 
        
        as.character(bci.data$traits.abu.213$sp)[which(as.character(bci.data$traits.abu.213$sp)
%in% colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j,
sep = "_"))) == FALSE)]
        
        bci.data$traits.abu.213$sp <-
as.character(bci.data$traits.abu.213$sp)
        
        # match abundance grid data to trait data
        grid.pruned <- get(paste(paste("Abundance_gridcells", i, sep =
""), j, sep = "_"))[,
which(colnames(get(paste(paste("Abundance_gridcells", i, sep = ""), j,
sep = "_"))) %in% bci.data$traits.abu.213$sp)] # prunes the abundance
grid to the species that are present in the trait data set
        # match trait data to abundance grid data
        traits.pruned <-
bci.data$traits.abu.213[match(colnames(grid.pruned),
bci.data$traits.abu.213$sp), ]
        
                                        # give full names to gridded
data
colnames(grid.pruned) <- rownames(traits.pruned)
        gridlist <- c(gridlist, list(grid.pruned))
    }
}

# match(traits.pruned$sp, colnames(grid.pruned))

# name the grid list
gridlistnames <- NA
for (i in seq(20,100, 20)){    
    for (j in c("1990_medlight3")){
        gridlistnames <- c(gridlistnames, paste(i,j, sep = "."))
    }    
}

gridlistnames <- gridlistnames[-1]
# create comma-separated name vector
cat(paste(shQuote(gridlistnames, type="cmd"), collapse=", "))

names(gridlist) <- c("20.1990_medlight3", "40.1990_medlight3",
"60.1990_medlight3", "80.1990_medlight3", "100.1990_medlight3")

bci.data$grid.medlight3 <- gridlist

# !! for trait matching
traits.lowlight3 <-
bci.data$traits.abu.213[match(colnames(bci.data$grid.lowlight3[[1]]),
rownames(bci.data$traits.abu.213)), ]

# just to check whether they match
match(rownames(traits.highlight3),
colnames(bci.data$grid.highlight3[[1]]))

names(bci.data)
save(bci.data, file = "bci.data.Rdata")

# !! there is an error in the "bci.data$grid.slope"
dim(bci.data$grid.lowlight3[[5]])
range(colSums(bci.data$grid.lowlight3[[5]]))
which(colSums(bci.data$grid.lowlight3[[5]])==0)
# yes, there is one species (Vochysia_ferruginea (203)) that is not
present for slope[[3]] and slope[[4]]

# remove Vochysia_ferruginea (203) from "slope"
# ... and remove "Vismia_baccifera" (183) from lowlight3
zero.spec <- which(colSums(bci.data$grid.lowlight3[[4]])==0)

bci.data$grid.lowlight3[[5]] <- bci.data$grid.lowlight3[[5]][,
-zero.spec]
dim(bci.data$grid.lowlight3[[5]])

light.grids <- bci.data[60:62]
names(light.grids)

save(light.grids, file = "light.grids.Rdata")

## just for exploration: plot raw c.scores against ses and veech
names(bci.data$coocc.213$check.213.df[,4])
summary(bci.data$coocc.213$check.213.df[,4])

length(bci.data$coocc.check.213)

scatter.smooth(bci.data$coocc.213$check.213.df[,16],
bci.data$coocc.213$check.213.ses.3t.df[,16], lpars = list(col = "red",
lwd = 5))

abline(lowess(bci.data$coocc.213$check.213.df[,13] ~
bci.data$coocc.213$check.213.ses.3x.df[,13]), col = "red")

cor(bci.data$coocc.213$check.213.df[,16],
bci.data$coocc.213$check.213.ses.3x.df[,16])

# some confirmatory plots: do species with low niche differences
really have the highest cooccurrence-probability

scatter.smooth(bci.data$niche.dist.213.df$niche.diff.raw3,
bci.data$coocc.213$veech213.ses.df[,18], lpars = list(col = "red", lwd
= 5))

cor(bci.data$niche.dist.213.df$niche.diff.raw3,
bci.data$coocc.213$veech213.ses.df[,2])

##################################
##################################
###### Markov network models #####
##################################
##################################

library(rosalia)
library(mistnet)
library(vegan)

# steps according to email by Dave Harris, 11th Dec. 1
# Run the first chunk with no modifications.

# 1) convenience function for adding intercepts to each column
`%plus%` = mistnet:::`%plus%`
logistic = binomial()$linkinv # logistic inverse link

# Random bernoulli trial
rbern = function(p){rbinom(length(p), size = 1, prob = p)}

# 2) load your "x" and "y" data matrices and set n_loc, n_spp, and n_env to match your data (n_loc = nrow(y); n_spp = ncol(y); n_env = ncol(x))
# start with 20m scale since i have the env. variables for that scale:
load("bci.data.Rdata")

# i) y-matric (species data):
names(bci.data)
dim(bci.data$grid.213[[4]])
# 1250 sites x  213 species
names(bci.data$grid.213)
y <- as.matrix(bci.data$grid.213[[4]])
# transform into presence-absence matrix:
y <- decostand(y, "pa")

# ii) x-matric (environmental data):
# http://www.davidzeleny.net/anadat-r/doku.php/en:data:bci:script-soil
soil20x20 <- read.delim('http://www.davidzeleny.net/anadat-r/lib/exe/fetch.php?media=data:bci-soil-20x20.txt')
names(soil20x20[,c(8,11,13:15)])
#soil.5 <- soil20x20[,c(8,11,13:15)]
soil.13 <- soil20x20[,c(3:15)]
env = true_env <- x <- soil.13 <- scale(soil20x20[,c(3:15)])
#env = true_env <- x <- soil.5 <- scale(soil20x20[,c(8,11,13:15)])

# later on: check whether the soil maps 

# set some parameters
set.seed(1)
n_spp = ncol(y)   # number of species
n_loc = nrow(y)    # number of locations
n_env = ncol(x)     # number of environmental predictors
n_gibbs = 5000  # number of Gibbs sampling iterations

# 3) Skip the second and third chunks, since they involve the generation of a simulated y matrix and you already have all your data.

# 4) Run the fourth chunk ("Calculate sufficient statistics of the data") without modification
# Calculate sufficient statistics of the data

y_stats = crossprod(y)
# ?? Q. to Dave: can y only contain presence-absence data or can it contain relative abundances as well?

y_env_stats = t(true_env) %*% y

########################################
## ??? do i need to run this bit?:
# Initialize the simulated landscape for stochastic approximation

y_sim = matrix(0.5, nrow = nrow(y), ncol = ncol(y))

# In this example, the true state of the environment is 
# known without error

env = true_env

# Initialize species' responses to environment at 0.
# Also initialize the delta (change in parameter values from the
# previous optimization iteration) to zero, since no optimization
# has occurred yet

alpha_env = delta_alpha_env = matrix(0, nrow = n_env, ncol = n_spp)

# Initialize species' intercepts to match observed occurrence rates
# plus a small amount of regularization

alpha_species = qlogis((colSums(y) + 1) / (nrow(y) + 2))

# Initialize the deltas for the intercepts to zero

delta_alpha_species = rep(0, n_spp)

# Initialize pairwise interactions and deltas to zero

beta = delta_beta = matrix(0, nrow = n_spp, ncol = n_spp)

# overall alpha depends on alpha_species and alpha_env.
# Will be filled in later, so can initialize it with zeros
# no delta alpha to initialize b/c alpha not optimized directly

alpha = matrix(0, nrow = n_spp, ncol = n_spp) 
#########################
#################################################

# 5.) Run the fifth chunk (priors) without modification unless you have prior knowledge about the alpha and beta coefficients

# Very weak priors on alpha terms, somewhat stronger on beta terms

alpha_env_prior = rosalia::make_logistic_prior(scale = 2)$log_grad 
alpha_species_prior = rosalia::make_logistic_prior(scale = 2)$log_grad
beta_prior = rosalia::make_logistic_prior(scale = 0.5)$log_grad

# 6) Remove the lines about r-squared from the next chunk (R-squared can't be calculated unless the "true" coefficients are known) and then run the remaining code.  This might take a while, depending on how many iterations you choose and how big your data set is.

initial_learning_rate = 1 # step size at start of optimization
maxit = 25000             # Number of rounds of optimization # try 50000 and 100000 as well
start_time = as.integer(Sys.time())


# Record the R-squared values in this vector
# r2s = numeric(maxit)

# Record the timing history in this vector

times = integer(maxit)

for(i in 1:maxit){
  ##############################
  # Gibbs sampling for predicted species composition
  ##############################

  # Update alpha
  alpha = env %*% alpha_env %plus% alpha_species

  # Sample entries in y_sim from their conditional 
  # distribution (Gibbs sampling)
    for(j in sample.int(n_spp)){
    y_sim[,j] = rbern(logistic(alpha[ , j] + y_sim %*% beta[ , j]))
  }

  ##############################
  # Stochastic approximation for updating alpha and beta
  ##############################

  # Update learning rate and momentum
 
    learning_rate = initial_learning_rate * 1000 / (998 + 1 + i)
 momentum = .9 * (1 - 1/(.1 * i + 2))

  # Calculate sufficient statistics
  y_sim_stats = crossprod(y_sim)
  y_sim_env_stats = t(env) %*% y_sim

  # Calculate the gradient with respect to alpha and beta.
  # Gradients are differences in sufficient statistics plus prior
  # gradients, all divided by the number of locations
  stats_difference = y_stats - y_sim_stats
  beta_grad = (stats_difference + beta_prior(beta)) / n_loc

  alpha_species_grad = (
    diag(stats_difference) + 
      alpha_species_prior(alpha_species)
  ) / n_loc
  diag(beta_grad) = 0 # beta_ii is 0 by convention
  y_env_difference = y_env_stats - y_sim_env_stats
  alpha_env_grad = (y_env_difference + 
                      alpha_env_prior(alpha_env))  / n_loc


  # Calculate parameter updates: gradient times learning rate 
  # plus momentum times delta
  delta_beta = beta_grad * learning_rate + momentum * delta_beta
  delta_alpha_species = alpha_species_grad * learning_rate + 
    momentum  * delta_alpha_species
  delta_alpha_env = alpha_env_grad * learning_rate +
    momentum  * delta_alpha_env

  # Add the deltas to the previous parameter values
  beta = beta + delta_beta
  alpha_species = alpha_species + delta_alpha_species
  alpha_env = alpha_env + delta_alpha_env

  # Record R-squared and timing
  # r2s[i] = cor(
  #   true_beta[upper.tri(true_beta)], 
  #   beta[upper.tri(beta)]
  # )^2
  times[i] = as.integer(Sys.time()) - start_time
}

# running time for 25000 iterations: 206 min

# save results:

MarkovNet213_20_env13_25000 <- list("alpha_species"=alpha_species, "alpha_env"=alpha_env, "beta"=beta)
str(MarkovNet213_20_env13_25000)
names(MarkovNet213_20_env13_25000)

save(MarkovNet213_20_env13_25000, file = "MarkovNet213_20_env13_25000.Rdata")

# plot distribution of beta values
plot(density(as.dist(MarkovNet213_20_env5_50000$beta)))
(hist(as.dist(MarkovNet213_20_env5_50000$beta)))


# correlation between beta and co-occurrence scores
names(bci.data$coocc.213)

plot(bci.data$coocc.213$veech213.ses.df[[2]])
plot(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)))

plot(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), as.vector(as.dist(MarkovNet213_20_env5_25000$beta)))
cor(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), as.vector(as.dist(MarkovNet213_20_env5_25000$beta)))
# 0.9736406 # interaction strengths for 5 and 13 variables are highly correlated
# env5_50000 & env5_25000 converge on the same answer
plot(bci.data$coocc.213$veech213.ses.df[[2]], bci.data$coocc.213$veech213.ses.df[[18]], ylim=c(-.10,.10), xlim=c(-.10,.10))

plot(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)),bci.data$coocc.213$veech213.ses.df[[2]])
cor(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), bci.data$coocc.213$veech213.ses.df[[2]])
cor(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), bci.data$coocc.213$check.213.ses.3i.df[[2]])

plot(as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), -1*bci.data$coocc.213$veech213.ses.df[[2]])
abline(h=0, v=0, col="red")


plot(bci.data$coocc.213$check.213.df[[2]],
bci.data$coocc.213$check.213.ses.3t.df[[2]])
cor(bci.data$coocc.213$check.213.df[[2]],
bci.data$coocc.213$check.213.ses.3t.df[[2]])

# correlation to niche differences:
cor(bci.data$niche.dist.213.df$niche.diff.raw3, as.vector(as.dist(MarkovNet213_20_env5_50000$beta)))

match(colnames(MarkovNet213_20_env5_50000$beta),
rownames(bci.data$traits.abu.213))

# correlation to fitness differences:
cor(as.vector(dist(bci.data$traits.abu.213$fitnessLogratio)), as.vector(as.dist(MarkovNet213_20_env5_50000$beta)))
# slightly negative correlation

cor(as.vector(dist(bci.data$traits.abu.213$fitnessLogratio)),
bci.data$coocc.213$veech213.ses.df[,2])

cor(as.vector(dist(bci.data$traits.abu.213$fitnessLogratio)),bci.data$coocc.213$check.213.df[,2])

# correlation to single niche differences:
cor(as.vector(dist(bci.data$traits.abu.213$growth.mean2)), as.vector(as.dist(MarkovNet213_20_env5_50000$beta)))


## correlate the different betas with ses of cooccurrence indices:

beta.mat <- cbind(as.vector(as.dist(MarkovNet213_20_env5_25000$beta)), as.vector(as.dist(MarkovNet213_20_env5_50000$beta)), as.vector(as.dist(MarkovNet213_20_env13_25000$beta)), bci.data$coocc.213$veech213.ses.df[[2]], -1*bci.data$coocc.213$check.213.ses.3t.df[[2]], -1*bci.data$coocc.213$check.213.ses.3x.df[[2]], -1*bci.data$coocc.213$check.213.ses.3i.df[[2]])

colnames(beta.mat) <- c("MN.5.25", "MN.5.50", "MN.13.25", "Veech", "Check.3t", "Check.3x", "Check.3i")

pdf(file = "coocc.pdf", width = 10, height = 10, pointsize=12)
CorTestPlot(beta.mat)
dev.off()

# load MarkovNet for random env. variables:
load("MarkovNet213_10_rand5_25000.Rdata")
load("MarkovNet213_20_rand5_25000.Rdata")
load("MarkovNet213_40_rand5_25000.Rdata")
load("MarkovNet213_60_rand5_25000.Rdata")
load("MarkovNet213_80_rand5_25000.Rdata")
load("MarkovNet213_100_rand5_25000.Rdata")

# are betas for env5 correlated with betas for rand5?:
cor(as.vector(as.dist(MarkovNet213_20_env5_25000$beta)), as.vector(as.dist(MarkovNet213_20_rand5_25000$beta)))
 # 0.9438586, yes, but not perfectly
plot(as.vector(as.dist(MarkovNet213_20_env5_25000$beta)), as.vector(as.dist(MarkovNet213_20_rand5_25000$beta)))

resp <- as.vector(as.dist(MarkovNet213_20_rand5_25000$beta))
diff <- as.vector(dist(bci.data$traits.abu.213[,c(3)]))
cor(resp, diff)

summary(as.vector(as.dist(MarkovNet213_10_rand5_25000$beta)))
mean(as.vector(as.dist(MarkovNet213_100_rand5_25000$beta)))
median(bci.data$coocc.213$veech213.ses.df[,18])

niche <- as.vector(dist(bci.data$traits.abu.213[,c(2:4)]))
fit <- as.vector(dist(bci.data$traits.abu.213[,c(9)]))
dat.scale <- as.data.frame(scale(cbind(niche, fit)))

#resp <- as.vector(as.dist(MarkovNet213_100_rand5_25000$beta))
resp <- bci.data$coocc.213$veech213.ses.df[,6]
summary(lm(resp ~ niche * fit, data=dat.scale))


#> names(bci.data$traits.abu.213)
#[1] "sp"                 "rec.light.mean2"    "growth.light.mean2"
#[4] "mort.light.mean2"   "growth.mean2"       "mort.mean2"        
#[7] "sp"                 "fitnessSMA"         "fitnessLogratio"   

# plot response surface beta~niche x fitness
    resp <- as.vector(as.dist(MarkovNet213_80_rand5_25000$beta))
    #resp <- bci.data$coocc.213$veech213.ses.df[,2]
niche <- as.vector(dist(bci.data$traits.abu.213[,c(3)]))
fitness <- as.vector(dist(bci.data$traits.abu.213[,c(4)]))
#fitness <- as.vector(dist(bci.data$traits.abu.213[,c(9)]))
    phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1)
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))   
fig <- lattice::contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
                   labels = F,
                 contour = F,
            xlab = "Light response differences",
            ylab = "Demographic differences",
            main = "MarkovNet213_20_env5_50000$beta"
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,"char"))
          #}
           #,
            #       panel = function(x,y,z,...){
            #  panel.contourplot(x,y,z,...)
            #  panel.abline(0,1,lwd=1,col="blue")
             #      }
            )   
   fig
    
# pdf(file = paste(paste("Check.213.", i, sep=""), "pdf", sep="."), width = 5, height = 4.6, pointsize=12)
#jpeg(filename = paste(paste("Coocc.check.wo.rec.a.spat.", i, sep=""), "jpeg", sep="."), width = 240, height = 226, quality = 100)
#plot(fig)
#dev.off()
#list(fig)
        fig

# inspect environmental variables:
filled.contour (matrix (env[,13], ncol = 25, byrow = T), color.palette = terrain.colors, main = 'pH')
# env. variables from Stefan Kupers:
elev.20 <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Environment/elev.20m.mean.txt")
slope.20 <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Environment/slope.20m.mean.txt")
curv.20 <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Environment/curv.20m.mean.txt")
# has negative values, check with stefan what this means
filled.contour (matrix (slope.20[,1], ncol = 25, byrow = F), color.palette = terrain.colors, main = 'slope.20')
filled.contour (matrix (curv.20[,1], ncol = 25, byrow = F), color.palette = terrain.colors, main = 'curv.20')
filled.contour (matrix (elev.20[,1], ncol = 25, byrow = F), color.palette = terrain.colors, main = 'elev.20')

par(pin = c(6, 3))
contour((matrix (curv.20[,1], ncol = 25, byrow = F))) # for stefans data, set byrow = F

# compare with species distributions:
# [147] "Poulsenia_armata" 

filled.contour(matrix(log(bci.data$grid.213[[4]][,147]), ncol = 25, byrow = T), color.palette = terrain.colors, main = "Poulsenia_armata")

# make sure env. data from stefan kupers is in the same order as the species and nadja's species grids
# the data should be in the following order:
filled.contour(matrix(log(bci.data$grid.213[[4]][,147]), ncol = 50, byrow = F), color.palette = terrain.colors, main = "Poulsenia_armata")

Poulsar.mat <- matrix(bci.data$grid.213[[4]][,147], ncol = 50, byrow = F) # true: good for plotting, false: fits the species data
dim(Poulsar.mat)
filled.contour(log(Poulsar.mat), color.palette = terrain.colors, main = "Poulsenia_armata")

Poulsar.vec <- as.vector(Poulsar.mat)

cor(bci.data$grid.213[[4]][,147], Poulsar.vec)

filled.contour(matrix(log(Poulsar.vec), ncol = 25, byrow = T), color.palette = terrain.colors, main = "Poulsenia_armata")


# 

Slope.mat <- (matrix((slope.40m.mean.txt[,1]), ncol = 50, byrow = F) # ncol = 50 (long edge) & byrow = T should produce a matrix that fits the species data
dim(Slope.mat)
filled.contour((Slope.mat))

Slope.vec <- as.vector(Slope.mat)


# final check: create matrix from original species data and matrix from the transformed env. data and plot them both using the same function:
filled.contour(matrix(log(bci.data$grid.213[[4]][,147]), ncol = 25, byrow = T), color.palette = terrain.colors, main = "Poulsenia_armata")

# plotted hochkant korrekt -> vector draus machen
filled.contour(t(matrix((slope.20m.mean.txt[,1]), ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m")
    
Slope.mat <- t(matrix(slope.40m.mean.txt[,1], ncol = 25, byrow = T))
Slope.vec <- as.vector((Slope.mat))
    
filled.contour(t(matrix(Slope.vec, ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Poulsenia_armata")
    
    
  Slope.mat <- matrix(slope.40m.mean.txt[,1], ncol = 50, byrow = T)
Slope.vec <- as.vector(Slope.mat)
 filled.contour(matrix(Slope.vec, ncol = 25, byrow = F), color.palette = terrain.colors, main = "Poulsenia_armata")
   
# to match the species data, we need a vector that is plottible with the following function:
filled.contour((matrix(Slope.vec, ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m")
  
    # try to generate such a vector:
 Slope.vec <- (as.vector(((matrix(slope.20m.mean.txt[,1], ncol = 50, byrow = T)))))  ##!! correct:  ncol = 50, byrow = T
# take these parameters to write a function that transform env.vec to species vec format
    
env.to.spec <- function(x, ncol){
    as.vector(matrix(x, ncol = ncol, byrow = T))
}
    
}
    
Slope.vec <- env.to.spec(slope.20m.mean.txt[,1], ncol = 50) # adjust ncol according to scale (long side of BCI plot/grain size)

filled.contour((matrix(Slope.vec, ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m")

# all grids are 1000x500, apart from:
# 40m: 1000 x 480
# 60m: 960 x 480
# 40m: 960 x 480

##################################################################################################
#################################################
# here starts the new analysis from August 2016:
#################################################
##################################################################################################
############################
# read in all environmental data
# if there are "." in the name,run the following script in the shell to rename the files accordingly:
# for filename in *_txt; do newname=`echo $filename | sed 's/\_txt$/.txt/g'`; mv $filename $newname; done
# ! if there are several scales, better to run 

path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Environment/Kupers_grids_bci-2016-06-27"
#path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Environment"
files <- list.files(path, pattern="*.txt")
for (i in 1:length(files)) assign(files[i], read.table(file.path(path, files[i])))

#########################################################################
# function to bring environmental data in the same order as species data:
#########################################################################
env.to.spec <- function(x, ncol){
    as.vector(matrix(x, ncol = ncol, byrow = T))
}

################################################################
# script to load all env.files for a particular scale and put them into one dataframe
################################################################
library(foreach)
env.scale <- list()

for (j in c("5m","10m","20m","40m","60m","80m","100m")){
    filenames <- list.files(path, pattern=j, full.names=TRUE)
    ldf <- lapply(filenames, read.table)
    res <- foreach(i = 1:length(filenames), .combine = cbind) %dopar% {
        as.vector(ldf[[i]])
    }
    env.scale <- c(env.scale, list(res))
}

str(env.scale)
names(env.scale) <- c("5m","10m","20m","40m","60m","80m","100m")

#####################################################
# make sure data are in the same order as species data (check for slope, ph and light):
######################################################
names(env.scale[[7]])
# all grids are 1000x500, apart from:
# 40m: 1000 x 480
# 60m: 960 x 480
# 80m: 960 x 480

ncol.vec <- c(200,100,50,25,16,12,10) # set up ncol-values for the env.scale-function

env.scale.2 <- env.scale

for(i in 1:7){
    for (j in 1:dim(env.scale[[i]])[2]){
        env.scale.2[[i]][,j] <- env.to.spec(env.scale[[i]][,j], ncol = ncol.vec[i])
    }
}

str(env.scale.2)

###################################################################
### just some plots to explore single environmental variables
#################################################################
# plot the environmental variables for each spatial scale
filled.contour((matrix(env.scale.2[[7]][,47], ncol = 5, byrow = T)), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour((matrix(env.to.spec(env.scale[[3]][,47], ncol = 50), ncol = 25, byrow = T)), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour(log(matrix(grid.213.7[[3]][,147], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

# check for stefans new data from 27th June, 2016:
filled.contour(matrix(env.scale[[3]][,55], ncol = 25, byrow = T), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour(log(matrix(grid.213.7[[3]][,147], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)


##################################################
# try with ggplot for single enviromental map
###################################################
df <- expand.grid(x = 0:99, y = 0:49) # initialize coordinates 
df$z <- env.scale[[2]][,47] # set up fill values
# default is compatible with geom_tile()
ggplot(df, aes(x, y, fill = z)) + geom_raster()
##############################################

##########################
# ggplot in loop (only  works for one page)
###########################
library(gridExtra)

p = list()
df <- expand.grid(x = 0:49, y = 0:24)

i <- 1

# only works with env.scale.2
for(i in 1:28) {
  df$z = env.to.spec(env.scale[[3]][,i], ncol = 50)
  p[[i]] = ggplot(df, aes(x, y, fill = z)) + 
      geom_raster() + 
      ggtitle(names(env.scale[[3]])[i]) + 
      scale_fill_gradientn(colours = terrain.colors(10)) + 
      theme(axis.title.x=element_blank(), 
        axis.text.x=element_blank(), 
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        axis.line = element_blank(),
        legend.position="right")+ 
      labs(fill="") # remove legend title
}
 
ggsave(file="env.100m.maps1.new.pdf", do.call("grid.arrange", c(p[1:28], ncol=4)), width = 45, height = 35, units = "cm")

################################
env.scale.correct <- env.scale
save(env.scale.correct, file = "env.scale.correct.Rdata")
#save(env.scale.2, file = "env.scale.2.Rdata")

#### 11th March 2016
# 1) 10 min: check again whether env. data and species data are in the right order
# 2) explore env.data (pairwise corr. plots, PCA)
# 3) generate PCA axes for each spatial scale (add the first few PCA as predictors)
# 4) forward selection (packfor, RDA)
# 5) check whether the size grids match the environmental data

# 1) 10 min: check again whether env. data and species data are in the right order

load("grid.213.7.Rdata")
names(grid.213.7)
load("env.scale.Rdata")
load("env.scale.2.Rdata")
names(env.scale.2)
env.scale.2[[3]][1:5,1:5]
env.scale[[3]][1:5,1:5]

plot(env.scale[[3]][,1], env.scale.2[[3]][,1]) # these two data sets are not the same

####

filled.contour(log(matrix(grid.213.7[[3]][,147], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour((matrix(env.scale.2[[3]][,47], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

# great, env.scale.2 and grid.213.7 (species data) are matching

#####
# for PDAR scaling:
# 1) put coordinates on the BCI community matrix:


# 2) 
mat <- matrix(grid.213.7[[1]][,147], ncol = 100, byrow = T)
dim(mat)
vec <- as.vector(mat)

x <- rep(1:200, each =100)
y <- rep(1:100, 200)

coord <- as.data.frame(cbind(x,y))
coord$coords <- paste(coord[,1], coord[,2], sep = ".")

mat.coord <- matrix(coord$coords, ncol = 100, byrow = T)


filled.contour(log(matrix(grid.213.7[[1]][,147], ncol = 100, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour(log(matrix(vec, ncol = 100, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

##################################################
# explore env.data (pairwise corr. plots, PCA)
##################################################

pdf("pca.env.correct.100.pdf", width=7.5, height=8)
dat <- env.scale.correct.mean[[7]]
colnames(dat) <- substr(colnames(dat),1, 5)
rda.60 <- rda(dat, scale = T)
plot(rda.60, type = "none", main="100m", scaling = 3)
ordipointlabel(rda.60, display = "species", scaling = 3, add = TRUE)
dev.off()

pdf("cor100.correct.pdf", width=25, height=25)
CorTestPlot(dat)
dev.off()

## covariance among predictors doesnt change much across scales
# but needs to be checked for new corrected data set including soil type:

# there are different variables in the data sets for the different scales
lapply(env.scale.correct, names)

##################################################
# extract only variables that are contained at the smallest spatial scale
# extract before the (\\.) any character (.) any number of times (*) until the end of the string
ind <- sub("\\..*$", "", names(env.scale.correct[[1]]))
##################################################

##################################################
# kick out variables that do not occur in the 5m scale data set
##################################################
which(sub("\\..*$", "", names(env.scale.correct[[4]])) %in% ind)

env.scale.correct.2 <- env.scale.correct
for (i in 1:7){
    env.scale.correct.2[[i]] <- env.scale.correct[[i]][, which(sub("\\..*$", "", names(env.scale.correct[[i]])) %in% ind)]
}
names(env.scale.correct.2)

# select soil types
ind.soil.type <- c("ava","fairchild","marron","swamp")

##################################################
# delete soil type columns (which occur throughout the data) to data
##################################################
env.scale.correct.3 <- env.scale.correct.2

for (i in 1:7){
    env.scale.correct.3[[i]] <- env.scale.correct.2[[i]][, -which(sub("\\..*$", "", names(env.scale.correct.2[[i]])) %in% ind.soil.type)]
}

lapply(env.scale.correct.3, names)

##################################################
# append soil type:
##################################################
env.scale.correct.4 <- env.scale.correct.3

for (i in 1:7){
    env.scale.correct.4[[i]] <- cbind(env.scale.correct.3[[i]], env.scale.correct.2[[i]][, which(sub("\\..*$", "", names(env.scale.correct.2[[i]])) %in% ind.soil.type)])
}

lapply(env.scale.correct.4, names)

##################################################
## extract the mean columns
##################################################
# run four sets of predictors for each spatial scale:
# select means of variables at each scale:
env.scale.correct.mean <- env.scale.correct.4
for (i in 2:7){
    env.scale.correct.mean[[i]] <- env.scale.correct.mean[[i]][,c(seq(1, 56, 2), 57:60)]
}
names(env.scale.correct.mean)
lapply(env.scale.correct.mean, names)

##################################################
# 1st and 2nd PCA axis on all predictors (27 vars without shade)
##################################################
env.scale.2.mean.PC <- env.scale.correct.mean
names(env.scale.2.mean.PC[[2]])[-26] # exclude shade

pca.test <- prcomp(scale(env.scale.correct.mean[[7]][ ,-26]))
summary(pca.test)
rownames(pca.test$rotation)

for (i in 1:7){
    env.scale.2.mean.PC[[i]] <- cbind(env.scale.correct.mean[[i]], scores(prcomp(scale(env.scale.correct.mean[[i]][ ,-26])), choices=c(1,2)))
}

dim(env.scale.2.mean.PC[[4]])

tail(env.scale.2.mean.PC[[3]][,33:34])

# 3.2 just PC1 (without shade)
tail(env.scale.2.mean.PC[[3]][,33])

# 3.3 just pH
colnames(env.scale.2.mean.PC[[3]][24])

# 3.4 just shade
colnames(env.scale.2.mean.PC[[3]][26])

filled.contour((matrix(env.scale.2.mean.PC[[3]][,33], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)
# 

env.scale.2.mean.PC.correct <- env.scale.2.mean.PC
save(env.scale.2.mean.PC.correct, file = "env.scale.2.mean.PC.correct.Rdata")

##################################################
# generate reduced data set with just 5 columns: 
##################################################
#1) pH (1st axis), 
# 2) elevation (2nd axis), 
# 3) shade, 
# 4) PC1 & 
# 5) PC2
# the latter based on all (but not shade) environmental variables, incl. the 4 soil types
env.scale.small <- env.scale.2.mean.PC.correct

for (i in 1:7){
    env.scale.small[[i]] <- env.scale.2.mean.PC.correct[[i]][,c(24,8,26,33,34)]
}
lapply(env.scale.small, names)

save(env.scale.small, file = "env.scale.small.Rdata")

##################################################
# create dataset for standard dev. of env. variables 
##################################################
# ... include sd as well (scales 10-100) ...
# generate sd dataset:

lapply(env.scale.correct.4, names)

env.scale.correct.sd <- env.scale.correct.4

for (i in 2:7){
    env.scale.correct.sd[[i]] <- env.scale.correct.4[[i]][,seq(2, 56, 2)]
}
names(env.scale.correct.sd)

lapply(env.scale.correct.sd, names)

env.scale.correct.sd <- env.scale.correct.sd[-1]

# 1st and 2nd PCA axis on all predictors (27 vars without shade)
env.scale.2.sd.PC <- env.scale.correct.sd

names(env.scale.2.sd.PC[[2]])[-26] # exclude shade

##################################################
#  explore standard deviation (sd) of env.data (pairwise corr. plots, PCA)
##################################################

pdf("pca.env.correct.sd.10.pdf", width=7.5, height=8)
dat <- env.scale.correct.sd[[1]]
colnames(dat) <- substr(colnames(dat),1, 5)
rda.60 <- rda(dat, scale = T)
plot(rda.60, type = "none", main="10m", scaling = 3)
ordipointlabel(rda.60, display = "species", scaling = 3, add = TRUE)
dev.off()

pdf("cor10.correct.sd.pdf", width=25, height=25)
CorTestPlot(dat)
dev.off()

#################
# PCA on sd data:
#################
pca.test <- prcomp(scale(env.scale.correct.sd[[6]][ ,-26]))
summary(pca.test)
rownames(pca.test$rotation)

for (i in 1:6){
    env.scale.2.sd.PC[[i]] <- cbind(env.scale.correct.sd[[i]], scores(prcomp(scale(env.scale.correct.sd[[i]][ ,-26])), choices=c(1,2)))
}

lapply(env.scale.2.sd.PC, names)


dim(env.scale.2.sd.PC[[4]])

tail(env.scale.2.sd.PC[[2]][,29:30])
summary(env.scale.2.sd.PC[[2]][,29:30])

filled.contour((matrix(env.scale.2.sd.PC[[2]][,30], ncol = 25, byrow = T)), color.palette = terrain.colors, main = "slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

env.scale.2.sd.PC.correct <- env.scale.2.sd.PC
save(env.scale.2.sd.PC.correct, file = "env.scale.2.sd.PC.correct.Rdata")

lapply(env.scale.2.sd.PC.correct, names)

##################################################
# generate reduced data set with just 5 columns: 
##################################################
#1) pH  
# 2) elevation 
# 3) shade 
# 4) PC1 & 
# 5) PC2
# the latter based on all (but not shade) environmental variables, incl. the 4 soil types
env.scale.small.sd <- env.scale.2.sd.PC.correct
lapply(env.scale.small.sd, names)

## continue here:

for (i in 1:6){
    env.scale.small.sd[[i]] <- env.scale.2.sd.PC.correct[[i]][,c(24,8,26,29,30)]
}

lapply(env.scale.small.sd, names)
lapply(env.scale.small.sd, str)

save(env.scale.small.sd, file = "env.scale.small.sd.Rdata")

##
##################################################
# match demographic rates and trait data (from Joe Wright) with species data (all )
##################################################
traits.new <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abun/new_fitness_measures_relpopchange.txt", stringsAsFactors = F)
dim(traits.new)
str(traits.new)

names(traits.new)
CorTestPlot(traits.new[,-c(1,7)])

# match to species data
filled.contour(log(matrix(grid.213.7[[1]][,147], ncol = 100, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

lapply(grid.213.7, dim)
dim(grid.213.7[[7]])

index <- which(traits.new$species %in% colnames(grid.213.7[[7]]))
traits213new <- traits.new[index,]

summary(traits213new)

colnames(grid.213.7[[7]])
traits213new$species
match(traits213new$species, colnames(grid.213.7[[7]]))

traits213new2 <- traits213new[,c(1,7,4,5,6,2,3,8:12)]
rownames(traits213new2) <- traits213new2$species

# load Joe Wright's data:
traits.bci <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/Traits_BCI.txt")
head(traits.bci)
dim(traits.bci)
match(traits213new$species, traits.bci$species)
summary(traits.bci)

library(dplyr)
traits.213.all <- dplyr:::inner_join(traits213new2, traits.bci, by = "species")
bci.data$traits.213.all <- traits.213.all[,-13]
rownames(bci.data$traits.213.all) <- bci.data$traits.213.all$species
colnames(bci.data$traits.213.all)[1] <- "sp"

save(bci.data, file = "bci.data.Rdata")

# complete trait data only is available for 164 out of the 213 species for which complete demographic rate data is available 
# !!! mainly, because data on seed mass is missing for 46 species
# !!! means that in order analyse cooccurrence in relation to trait difference we would need to prune the trait data and re-run the co-occurrence (markov network analysis) based on the smaller set of 164 species
# i guess to match it to the phylogeny we need to reduce that set even further:
# -> need to re-run the markov network analysis for two (or three) more sets of species:
# 1) set of species for which the wright traits are available (164, in case we skip phylogeny)
# 2) for which both, wright traits and phylogeny, is available (<167, in case we include phylogeny)
# 3) for which demographic rates and phylogeny (>164, in case we skip the wright traits)

# two steps to achieve that:
# first, generate reduced trait data sets
# second, match the species data on them

# first, generate the reduced trait data sets:
# 1) wright traits:
traits.wright <- bci.data$traits.213.all[!is.na(rowSums(bci.data$traits.213.all[,c(13:20)])),]
bci.data$traits.164.all <- traits.wright
# 2) both, wright traits and phylogeny:
which(bci.data$traits.164.all$species %in% bci.data$phy.298$tip.label)
# great, all 164 species for which demographic rates and wright traits are available are in the phylogeny
# 3) demographic rates and phylogeny:
which(bci.data$traits.213.all$species %in% bci.data$phy.298$tip.label)
which(bci.data$phy.298$tip.label %in% bci.data$traits.213.all$species)
# great, all 213 species for which demographic rates are available are in the phylogeny

# because both, the 213 species for which demographic rates are available and the 164 species for which demographic and wright traits are available, match the phylogeny, we "only" need re-run the markov analysis for the 164 species data set

# second, match the species data onto the trait information:
# !!!! continue here:
lapply(grid.213.7, dim)
bci.data$phy.213 <- match.phylo.comm(bci.data$phy.298, (grid.213.7[[6]]))$phy
bci.data$phy.164 <- match.phylo.data(bci.data$phy.298, bci.data$traits.164.all)$phy


load("grid.size.1.Rdata")
load("grid.size.5.Rdata")
load("grid.size.10.Rdata")

names(grid.size.10)
lapply(grid.size.5, dim)

i <- 6

grid.213.7.wright <- foreach(i = 1:7) %do% {
    index <- which(colnames(grid.213.7[[i]]) %in% bci.data$traits.164.all$species)
    grid.213.7[[i]] <- grid.213.7[[i]][,index]
}
lapply(grid.213.7.wright, dim)
names(grid.213.7.wright) <- c("5m","10m","20m","40m","60m","80m","100m")

grid.wright.213.7 <- grid.213.7.wright
save(grid.wright.213.7, file = "grid.wright.213.7.Rdata")

## !!! we have to check whether after removing, all of the species are present at least once (and whether all sites contain at least one species... but probably not as important as the first criterium)
# ? yes, but should not matter

# do we need to run markov models on the entire network of all BCI species (~300), since indirect interactions might not be taken into account correctly if we miss a bunch of species?
# to check for that, look at correlation between interaction strenght estimated from larger set of species (213 species) with interaction strengths estimated for smaller set of species (164 species) -> start comparing 
# prior to that, test whether in general, two realizations of the same MN settings (run) converge on a similar answer e.g. for demogr.traits_mean.25000 (size10) ; and wright.size.sd (25000 & 50000; 25000 vs 50000) for each of the size classes

# i) copy some markov results over from eve
# ii) compare whether in general two realizations of the same MN settings (run) converge on a similar answer:

## does taking the mean or sd make a difference?
# for 213.7 and 50000 and c(4,5)
# yes, it does. particularily at larger spatial scales

# for the first two PCA axes
MN.size10.mean1_15 <- get(load("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/bci.markov-analyse-1-1426287-grid.full.size.10_env.scale.small.mean_1_50000.Rdata"))
length(MN.size10.mean1_15)

MN.size10.mean1_15 <- foreach(i=1:7) %do% {
    as.dist(MN.size10.mean1_15[[i]][[3]])
    }

str(MN.size10.mean1_15)
length(MN.size10.mean1_15)
lapply(MN.size10.mean1_15, FUN=median)


plot(MN.size10.mean1_14[[7]], MN.size10.mean1_14[[7]])

x <- MN.size10.mean1_15
scalevec <- c(5,10,20,40,60,80,100)
#betavec <- c(3,6,9,12,15,18,21)
par(mfrow=c(2,4))
for (i in 1:7){
     plot(density(x[[i]]), xlim = c(-.8,.8), main = scalevec[i])
     #abline(v=median(x[[betavec[i]]]))
     abline(v=0)
}

# strange, two run with 25000 iters each, for the same size class and same env. variable seem to converge on the same answer.

# compare betas for pH and elevation (which are orthogonal on each other)
# depending on which environmental variables we put into the model, we get different estimates for interaction strength, particularily at the larger spatial scales
# ! i guess, we should stick with PC1 and PC2, i.e. c(4,5)

# try size5 mean. do interaction show stronger scale dependent shifts
# only a little bit

# !!!! continue here:

# compare sd 100000 PC1&2: 213(all), size1 size5 size10
# yes, there is a scale dependent shift, generally from negative to positive interactions
# shift is clearest when based on all 213 species, 
# when based on the smallest size class (<1cm) it shifts from even stronger negative interactions to just slightly positive (close to zero)
# when based on largest size class (size.10), mean interactions are negative throughout scales, but stongest at intermediate scales

# however, this is all just based on sd

# compare 25000, 50000, 100000 for a particular size class (sd, grid213, PC1 & 2)
# (in case 100000 estimates are different from the 25000 ones, I should wait for final results from the runs with 100000 iterations)
# plot betas from 25,000 against betas from 100,000 runs

i <- 1

par(mfrow=c(2,3))

for (i in 1:6)
{
    plot(MN.size10.mean1_14[[i]], MN.size10.mean1_15[[i+1]])#, xlim=c(-2,2), ylim=c(-2,2)
    #abline(0, 1) 
}

x <- foreach(i = 1:6) %do% {
    cor.test(MN.size10.mean1_14[[i]], MN.size10.mean1_15[[i+1]])$estimate
    #abline(0, 1) 
}
x

# yes, it really makes a massive difference (particularily at larger spatial scales)) whether betas are estimated based on 25000 or 100000 iterations
# anyway, 50000 gets pretty close to 100000

# does it make a difference whether I take sd or mean? (for 25000)
# not really!

#######
# does interaction change depending on whether it is estimated on smaller or larger set of species:
########
# 213 species: MN.size10.mean1_14
# 164 species: MN.size10.mean1_13

# do species pairs shared by these two data sets correlate?
MN.size10.mean1_14.new <- MN.size10.mean1_14

x <- foreach(i = 1:6) %do% {
    MN.size10.mean1_14.new[[i]] <- match.comm.dist(comm=t(bci.data$traits.164.all[,3:4]), dis=MN.size10.mean1_14[[i]])$dis
}

mat <- match.comm.dist(comm=t(bci.data$traits.164.all[,3:4]), dis=MN.size10.mean1_14[[i]])$dis

MN.size10.mean1_14pruned <- x
# do the names match?:
str(MN.size10.mean1_14pruned[[1]])
match(attr(MN.size10.mean1_14pruned[[1]], "Labels"), attr(MN.size10.mean1_13[[1]], "Labels"))

for (i in 1:6)
{
    plot(MN.size10.mean1_14pruned[[i]], MN.size10.mean1_13[[i]])#, xlim=c(-2,2), ylim=c(-2,2)
    #abline(0, 1) 
}

x <- foreach(i = 1:6) %do% {
    cor.test(MN.size10.mean1_14pruned[[i]], MN.size10.mean1_13[[i]])$estimate
    #abline(0, 1) 
}
x

## yes, the species set makes a difference

abu <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/grid.305.7/Abundance_gridcells5_1990.txt")

abu.size <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/5m_Steps/Abundance_gridcells5_1990.txt")


##########################
# Species interactions need to be estimated based on all species in the Markov network:
##########################
# read in 
#path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/grid.305.7"

path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/5m_Steps"

grid.302.7 <- list()

for (j in c("gridcells5_1990","gridcells10_1990","gridcells20_1990","gridcells40_1990","gridcells60_1990","gridcells80_1990","gridcells100_1990")){
    filenames <- list.files(path, pattern=j, full.names=TRUE)
    ldf <- lapply(filenames, read.table)   
    
    grid.302.7 <- c(grid.302.7, (ldf))
}

lapply(grid.302.7, dim)

str(grid.302.7)
names(grid.302.7) <- c("5m","10m","20m","40m","60m","80m","100m")

#### prune the 305 species data sets to 302 species (40-80m scales)

grid.302 <- foreach(i = 1:7) %do% {
    index <- which(toupper(colnames(grid.302.7[[i]])) %in% colnames(grid.302.7[[4]]))
    grid.302.7[[i]] <- grid.302.7[[i]][,index]
}
lapply(grid.302, dim)

names(grid.302) <- c("5m","10m","20m","40m","60m","80m","100m")
colnames(grid.302[[1]]) <- toupper(colnames(grid.302[[1]]))


# check whether species in grid.302.7 are in the same order as the env. data
filled.contour(log(matrix(grid.302[[1]][,212], ncol = 100, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)
# yes, it is correct

grid.302 <- grid.302.7
save(grid.302.7, file = "grid.302.7.Rdata")

##########################
# re-run for size classes:
##########################
path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/SizeClasses"

grid.size.10 <- list()

for (j in c("gridcells5_1990_10cm","gridcells10_1990_10cm","gridcells20_1990_10cm","gridcells40_1990_10cm","gridcells60_1990_10cm","gridcells80_1990_10cm","gridcells100_1990_10cm")){
    filenames <- list.files(path, pattern=j, full.names=TRUE)
    ldf <- lapply(filenames, read.table)   
    grid.size.10 <- c(grid.size.10, (ldf))
}

lapply(grid.size.10, dim)
names(grid.size.10) <- c("5m","10m","20m","40m","60m","80m","100m")

grid.full.size.10 <- grid.size.10
save(grid.full.size.10, file = "grid.full.size.10.Rdata")

#########################################################
mod <- summary(lmp(y ~ N * P, data = CC164, perm="")) 

## test whether piecewiseSEM takes lmp-output

library(lmPerm)
library(piecewiseSEM)
#library(semPlot)

data(iris)

modlist = list(
    lm(Sepal.Width ~ Petal.Width, data = iris),
    lm(Petal.Length ~ Petal.Width + Sepal.Width, data = iris),
    #lm(Petal.Length ~ Sepal.Width, data = iris),
    #lm(Petal.Length ~ Sepal.Width, data = iris),
    lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris)
)

modlist.perm = list(
    lmp(Sepal.Width ~ Petal.Width, data = iris, perm="Prob"),
    lmp(Petal.Length ~ Petal.Width, data = iris, perm="Prob"),
    lmp(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris, perm="Prob")
)

sem.fit(modlist, iris)

for (i in 1:length(modlist.perm)){
    class(modlist.perm[[i]]) <- "lm"
    }

vec <- c("Sepal.Width ~~ Petal.Length", "Petal.Length ~~ Petal.Width")
#sem.fit(modlist, data = iris, corr.errors = vec)
sem.fit(modlist, data = iris)


sem.plot(modlist, iris)

sem.coefs(modlist, iris)
sem.coefs(modlist.perm, iris)

# compare lm with lmp
mod <- lm(Sepal.Width ~ Petal.Width, data = iris)
summary(mod)
mod.perm <- lmp(Sepal.Width ~ Petal.Width, data = iris, perm="Prob")
summary(mod.perm)

mod.glm <- glm(Sepal.Width ~ Petal.Width, data = iris)
summary(mod.glm)

## would lmPerm be the right approach for piecewiseSEM?
# to test that, compare MRM with lmp and lm for wright.size10.PC1.2
## 
# stop 18.30
#

MN.size10.mean1_14 <- get(load("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/bci.markov-analyse-1-1426284-grid.full.302.7_env.scale.small.sd_c(1,2)_50000.Rdata"))
length(MN.size10.mean1_14) # 177 species

coocc.20 <- MN.size10.mean1_14[[2]]$beta
str(coocc.20)
# match coocc.distance matrix with traits

pdf("Cor.demo.wright.pdf", width= 20, height = 20)
CorTestPlot(bci.data$traits.213.all[,c(3:20)])
dev.off()

niche.fit <- bci.data$traits.213.all[,c(3:7,13:20)]
rownames(niche.fit) <- bci.data$traits.213.all[,c(2)]

mat <- match.comm.dist(comm = as.matrix(t(niche.fit)), dis = as.dist(coocc.20))

niche.fit.2 <- niche.fit[colnames(coocc.20),]
match(rownames(niche.fit.2), colnames(coocc.20))

niche.dist <- dist(niche.fit.2[,c(1:3)])
fit.dist <- dist(niche.fit.2[,c(4:5)])
wd.dist <- dist(niche.fit.2[,c(6)])
sm.dist <- dist(niche.fit.2[,c(8)])
height.dist <- dist(niche.fit.2[,c(7)])

coocc.20 <- MN.size10.mean1_14[[7]]$beta
mod.mrm <- MRM(dist(coocc.20) ~ niche.dist + fit.dist + height.dist, nperm=1000)
mod.mrm

coocc.20 <- MN.size10.mean1_14[[7]]$beta
ind <- sample(1:13366, 2000)
mod.lmp <- lmp(as.vector(dist(coocc.20))[ind] ~ as.vector(niche.dist)[ind] + as.vector(fit.dist)[ind], perm="Prob")
summary(mod.lmp)

##### Run example prelim. analysis on "mean 213.7 c(4,5 50000"
# run real analysis when "mean 302.7 c(4,5 50000" is ready 
#### decide on fitness measures:

niche <- as.vector(dist(bci.data$traits.abu.213[,c(2:4)]))
fit <- as.vector(dist(bci.data$traits.abu.213[,c(9)])) # logresponse


# what about the ration between "growth.mean2""/mort.mean2"
fit.gro_mor <- bci.data$traits.213.all$demo.growth.mean2/bci.data$traits.213.all$demo.mort.mean2

bci.data$traits.213.all$fit_gro.mor_ratio <- fit.gro_mor

pdf("Cor.demo.wright.pdf", width= 20, height = 20)
CorTestPlot(bci.data$traits.213.all[,c(3:21)])
dev.off()

# for traits.213.all, calculate PCA for niche (PC1-3) and fitness (PC1-2)
names(bci.data$traits.213.all)

PCA <- prcomp(bci.data$traits.213.all[ ,c(3:5)])
niche.pca3 <- scores(PCA, choices=c(1,2,3))
colnames(niche.pca3) <- paste("Niche",colnames(niche.pca3),sep=".")
apply(niche.pca3, 2, function(x){diff(range(x))})

PCA <- prcomp(bci.data$traits.213.all[ ,c(6:7)])
fit.pca2 <- scores(PCA, choices=c(1,2))
colnames(fit.pca2) <- paste("Fit",colnames(fit.pca2),sep=".")
apply(fit.pca2, 2, function(x){diff(range(x))})

bci.data$traits.213.all <- cbind(bci.data$traits.213.all, niche.pca3, fit.pca2)

# for traits.164.all, calculate gro/mor-ratio, PCA for niche and fitness, for Wright-traits: N, P (PC1:2, ? scale), all 7 traits without LDMC

names(bci.data$traits.164.all)

PCA <- prcomp(bci.data$traits.164.all[ ,c(3:5)])
niche.pca3 <- scores(PCA, choices=c(1,2,3))
colnames(niche.pca3) <- paste("Niche",colnames(niche.pca3),sep=".")
apply(niche.pca3, 2, function(x){diff(range(x))})

PCA <- prcomp(bci.data$traits.164.all[ ,c(6:7)])
fit.pca2 <- scores(PCA, choices=c(1,2))
colnames(fit.pca2) <- paste("Fit",colnames(fit.pca2),sep=".")
apply(fit.pca2, 2, function(x){diff(range(x))})

bci.data$traits.164.all <- cbind(bci.data$traits.164.all, niche.pca3, fit.pca2)

###################
# wright traits:
# transform trait data prior to PCA
names(bci.data$traits.164.all)
hist((bci.data$traits.164.all[,20]))
# leaf.n and leaf.p are approx. normally distributed

# log transform seed mass and leaf area:
hist(log(bci.data$traits.164.all[,15])) # seed mass
hist(log(bci.data$traits.164.all[,17])) # lead area
# log the other traits as well
hist(log(bci.data$traits.164.all[,14])) # height
plot((bci.data$traits.164.all[,14])) #


bci.data$traits.164.all$SeedMass.log <-  log(bci.data$traits.164.all$SeedMass)
hist(bci.data$traits.164.all$SeedMass.log)

bci.data$traits.164.all$LeafArea.log <-  log(bci.data$traits.164.all$LeafArea)
hist(bci.data$traits.164.all$LeafArea.log)


## after all that re-check whether species and environmental data in markov.network script at a particular spatial scale really match up-

PCA <- prcomp(scale(bci.data$traits.164.all[ ,c(19:20)]))
summary(PCA)
biplot(PCA)
np.pca2 <- scores(PCA, choices=c(1,2))
colnames(np.pca2) <- paste("NP",colnames(np.pca2),sep=".")
apply(np.pca2, 2, function(x){diff(range(x))})


# check whether PCA on untransformed traits (sm, leaf area) differed from PCA with included traits
names(bci.data$traits.164.all[,c(13:14,16,18:20,37,38)])
names(bci.data$traits.164.all[,c(13:20)])
PCA <- prcomp(scale(bci.data$traits.164.all[ ,c(13:14,16,18:20,37,38)]))
PCA <- prcomp(scale(bci.data$traits.164.all[ ,c(13:20)]))
summary(PCA)

fig <- ordiplot(PCA, type = "none", xlim = c(-.7,.7), ylim = c(-.7,.7))
text(fig, "species", col="blue", cex=0.9)

wright.8.trans.pca8 <- scores(PCA, choices=c(1:8))
colnames(wright.8.trans.pca8) <- paste("wright.8.trans",colnames(wright.8.trans.pca8),sep=".")
apply(wright.8.trans.pca8, 2, function(x){diff(range(x))})

bci.data$traits.164.all <- cbind(bci.data$traits.164.all, wright.8.trans.pca8)

fit.gro_mor <- bci.data$traits.164.all$demo.growth.mean2/bci.data$traits.164.all$demo.mort.mean2
bci.data$traits.164.all$fit_gro.mor_ratio <- fit.gro_mor

traits.164.all <- bci.data$traits.164.all[,c(1:20,36,21:35)]
bci.data$traits.164.all <- traits.164.all

save(bci.data, file = "bci.data.Rdata")

# ## would lmPerm be the right approach for piecewiseSEM?
# to test that, compare MRM with lm for mean 213.7 c(4,5 50000
##

MN.size10.mean1_14 <- get(load("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/bci.markov-markov-correct-2-1419821-grid.213.7_env.scale.small.mean_c(4,5)_50000.Rdata"))
length(MN.size10.mean1_14)

coocc.20 <- MN.size10.mean1_14[[2]]$beta
str(coocc.20)

# match the distance matrix to the wright traits:
mat <- match.comm.dist(comm = (t(bci.data$traits.164.all[,c(3:35)])), dis = as.dist(coocc.20))

### continue here:

# to compare the model types, begin with single effects:

####
# !!! continue here on Tuesday: read in files with certain patterns in an index:
##

################################
##### grand analysis function: #
################################

# indices in for loops:

# i - size class (302, size1 ....)
# v - variable
# s - scale
# t - traits
# 

## outside loop

mn.path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/"
traits <- bci.data$traits.164.all
phylo <- bci.data$phy.164
# only in some cases (traits.213.all): give short names as rownames:
rownames(traits) <- bci.data$traits.164.all$sp

i <- "size.1_"
v <- "(4,5)_"
s <- 1
t <-  "1:3"

mn.list <- list.files(mn.path, pattern=glob2rx(paste0("*grid.full","*",i,"*mean*",v,"*100000*"))) 
                                        # to be changed if sd or 100000 iterations are used
mn.list

# start loop
library(doParallel)
out <- foreach(i = c("302.7", "size.1_", "size.5_", "size.10_")) %:%
    foreach(v = c("_1_", "_2_", "_3_", "(1,2)_", "_4_", "(4,5)_"), .combine = rbind) %do% {
        
        mn.path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/"
        traits <- bci.data$traits.164.all
        phylo <- bci.data$phy.164
# only in some cases (traits.164.all): give short names as rownames:
        rownames(traits) <- bci.data$traits.164.all$sp

        mn.list <- list.files(mn.path, pattern=glob2rx(paste0("*grid.full","*",i,"*mean*",v,"*100000*"))) 
                                        # to be changed if sd or 100000 iterations are used
        mn.list
        mn.list <- get(load(paste0(mn.path, mn.list)))
                                        # match cooccurence matrices to traits
        coocc <- foreach(s = 1:length(mn.list)) %do% {
            beta <- mn.list[[s]]$beta
            rownames(beta) <- toupper(rownames(beta))
            colnames(beta) <- toupper(colnames(beta))
            index.beta <- which(colnames(beta) %in% rownames(traits))
            beta.small <- beta[index.beta, index.beta]
            index.traits <- which(rownames(traits) %in% rownames(beta.small))
            traits.small <- traits[index.traits,]
            mat.dis <- match.comm.dist(comm = t(traits.small[,c(3:dim(traits.small)[2])]), dis = as.dist(beta.small))$dis
            }        
        names(coocc) <- c("5m", "10m", "20m", "40m", "60m", "80m", "100m")
        
        ## to be deleted later on: some extra stuff for the veech analysis
        #traits <- bci.data$traits.213.all[,c(3:dim(bci.data$traits.213.all)[2])]
        #coocc <- veech.ses
        ######################
        
                                        # match traits to cooccurrence
        beta <- mn.list[[1]]$beta
        rownames(beta) <- toupper(rownames(beta))
        colnames(beta) <- toupper(colnames(beta))
        index.beta <- which(colnames(beta) %in% rownames(traits))
        beta.small <- beta[index.beta, index.beta]
        index.traits <- which(rownames(traits) %in% rownames(beta.small))
        traits.small <- traits[index.traits,]
        traits <- t(match.comm.dist(comm = t(traits.small[,c(3:dim(traits.small)[2])]), dis = coocc[[1]])$comm)
        dim(traits)

#################################
# for the demo and wright traits:
#################################
#1 "1:3": "demo.rec.light.mean2"    "demo.growth.light.mean2" "demo.mort.light.mean2"
#2 "4:5": "demo.growth.mean2"  "demo.mort.mean2"
#3 "7": "fitnessLogratio"
#4 "10": "relpopchange"
#5 "19": "fit_gro.mor_ratio"
#6 "20": "Niche.PC1"
#7 "23": "Fit.PC1"
#8 11: "WoodDensity"
#9 12: "MAXHEIGHT"              
#10 13 "SeedMass"
#11 14: "LMA"                    
#12 15: "LeafArea"
#13 25: "NP.PC1"
#14 27: "Wright.8.PC1"
        
        trait.dist <- foreach(i = c("1:3", "4:5", "7", "20", "23",   
                                    "11", "12", "13", "14", "15", "25", "27",
                                    "27:34",
                                    "35", "36",
                                    "37",
                                    "37:44")) %do% {
            dist(traits[,eval(parse(text=i))])    
        }
        #lapply(trait.dist, range)
        names(trait.dist) <- c("Niche", "Fitness", "Fit.Log.Ratio", "Niche.PC1", "Fit.PC1",   
                               "WoodDensity", "MAXHEIGHT", "SeedMass", "LMA", "LeafArea", "NP.PC1", "Wright.8.PC1",
                               "Wright.8.PC1.8",
                               "SeedMass.log", "LeafArea.log",
                               "wright.8.trans.PC1",
                               "wright.8.trans.PC1.8")

#################################
# just for demo traits:
#################################
#1 "1:3": "demo.rec.light.mean2"    "demo.growth.light.mean2" "demo.mort.light.mean2"
#2 "4:5": "demo.growth.mean2"  "demo.mort.mean2"
#3 "7": "fitnessLogratio"
#4 "10": "relpopchange"
#5 "19": "fit_gro.mor_ratio"
#6 "20": "Niche.PC1"
#7 "23": "Fit.PC1"

#        trait.dist <- foreach(t = c("1:3", "4:5", "7", "10", "19", "20", "23")) %do% {
#            dist(traits[,eval(parse(text=t))])    
#        }
        #lapply(trait.dist, range)
#        names(trait.dist) <- c("Niche", "Fitness", "Fit.Log.Ratio", "Rel.pop.change", "Fit.gro.mor.ratio", "Niche.PC1", "Fit.PC1")

# scale the data for multivariate analysis:
#trait.dist.scale <- lapply(trait.dist, scale)
#lapply(trait.dist.scale, mean)
#lapply(trait.dist.scale, sd)

# dis.1 <- dist(traits[,1:3])
#dis.2 <- dist(traits[,4:5])

# do names in coocc and trait distance matrices match up?:
#match(attr(coocc[[1]], "Labels"), attr(trait.dist[[1]], "Labels"))

#######################################
# add phylogenetic distance matrix
#######################################

# to match traits with phylogeny, give full species names as rownames to trait data:
#str(traits)
#class(traits)
        traits.2 <- traits
        traits.2 <- as.data.frame(traits.2)
        traits.2$sp <- rownames(traits.2)

#names(bci.data$traits.164.all)

# 17-17.30: match phylo with traits
        library(dplyr)
        traits.2.match <- inner_join(traits.2, bci.data$traits.164.all[,c(1:2)])
        rownames(traits.2.match) <- traits.2.match$species

        traits <- traits.2.match[, -c(25:26)]


        mat <- match.phylo.data(phy = bci.data$phy.164, data = traits)
        #mat$phy
#
        phy.mat <- as.dist(cophenetic(mat$phy))

        phy.sort <- match.comm.dist(comm = t(traits[,c(3:dim(traits)[2])]), dis = phy.mat)$dis

#match(attr(coocc[[1]], "Labels"), attr(phy.sort, "Labels"))
#match(attr(trait.dist[[1]], "Labels"), attr(phy.sort, "Labels"))

        trait.dist.phy <- trait.dist
        trait.dist.phy$phylo <- phy.sort

#trait.dist.phy.scale <- trait.dist.scale
#trait.dist.phy.scale$phylo <- scale(phy.sort)

#lapply(trait.dist.phy.scale, mean)
#lapply(trait.dist.phy.scale, sd)


## univariate regression analysis

        coocc <- coocc
        traits <- trait.dist.phy # for veech, just use "trait.dist" here
        
        ####################################################
        ## the following chunk might be deleted later on
        # put transformation here:
        # log-transform seed mass and leaf area, sqrt-transform the rest:
        #names(traits)[c(8,10)]
        
        for(i in c(1:7,9,11:18)){
            traits[[i]] <- sqrt(traits[[i]])
        }
        
        for(i in c(8,10)){
            traits[[i]] <- log(traits[[i]]+0.0000001) # there are zero distances for seed mass
        }
        
        #########################################

    # include the data matching cleaning and matching bits in here
            modelcoef <- foreach (s = 1:length(coocc)) %:% 
                foreach(t = 1:length(traits), .combine = rbind) %do% {
                    round(summary(lm(coocc[[s]] ~ traits[[t]]))$coefficients[2,], 4)
                    #rownames(res) <- names(traits)
          
            }
            #rownames(res) <- names(traits)
                
       names(modelcoef) <- names(coocc)
       ldply(modelcoef)
    }

out

names(out) <- c("302.7", "size.1", "size.5", "size.10")
out.2 <- ldply(out)

nam <- expand.grid(
    trait.dist = c("Niche", "Fitness", "Fit.Log.Ratio", "Niche.PC1", "Fit.PC1",   
                               "WoodDensity", "MAXHEIGHT", "SeedMass", "LMA", "LeafArea", "NP.PC1", "Wright.8.PC1",
                               "Wright.8.PC1.8",
                               "SeedMass.log", "LeafArea.log",
                               "wright.8.trans.PC1",
                               "wright.8.trans.PC1.8","Phylo"),
    scale = c("5", "10", "20", "40", "60", "80", "100"),
    env = c("1", "2", "3", "1,2", "4", "4,5"),
    size = c("All", "Size.1", "Size.5", "Size.10")
)

out.3 <- cbind(nam, out.2)
head(out.3)
out.4 <- out.3[,-c(5:7)]

str(out.4)
names(out.4)[5] <- "t.val"

######
# plot correlation between interaction strenght and trait distances
######

#library(RColorBrewer)
#gs.pal <- colorRampPalette(brewer.pal(8 , "RdBu" ))

sub.5 <- subset(out.4, trait.dist %in% c("Niche", "Fit.Log.Ratio", "WoodDensity", "MAXHEIGHT", "SeedMass"))

sub.6 <- subset(out.4, trait.dist %in% c("LMA", "LeafArea", "NP.PC1", "Wright.8.PC1", "Wright.8.PC1.8"))

sub.7 <- subset(out.4, trait.dist %in% c("SeedMass.log", "LeafArea.log", "wright.8.trans.PC1", "wright.8.trans.PC1.8", "Phylo"))

pdf("Cor.Coocc.Dist.wright.7.trans.100000.pdf", width = 10, height = 11)
ggplot(sub.7, aes(scale, t.val, color = trait.dist, group = trait.dist)) + 
    #geom_point() + 
    geom_line() +
    facet_grid(env ~ size, margins=F) +
    labs(y="Cor.Coocc.Dist", x= "Scale") + 
    #scale_colour_manual(values=gs.pal(8)) +
    geom_hline(yintercept=c(0), color = c("black"), linetype="dashed") +
    geom_hline(yintercept=c(-1.96, 1.96), color = c("grey"), linetype="dashed")
dev.off()

#### 
# 1) test whether, at small spatial scales, the strong relationship 
# 13.45-14.00
names(coocc)
names(trait.dist)

colnames(traits)
plot(traits[,16])

plot((coocc[[1]]), (trait.dist[[1]]))

plot(trait.dist[[1]], trait.dist[[3]])
# yes, there are crazy outliers in seed mass and leaf area, that influence the relationship between cooccurrence and trait differences, if we do not log-transform seed mass and leaf area
# means, we should work with the log-transformed data

#####################
# try piecewiseSEM ##
#####################

# does lm on matrix or vector give similar results?
summary(lm(coocc[[1]] ~ trait.dist[[1]]))
summary(lm(as.vector(coocc[[1]]) ~as.vector( trait.dist[[1]])))
# yes, give the same results

names(coocc)
names(trait.dist)

# combine cooccurrence and trait distance vectors into on 

x1 <- foreach(i = 1:length(coocc), .combine = cbind) %do% {
    as.vector(coocc[[i]])
    }
dim(x1)
colnames(x1) <- paste0("coocc.", names(coocc))

x2 <- foreach(i = c(1,3,6:11,14:16), .combine = cbind) %do% {
    as.vector(trait.dist[[i]])
    }
dim(x2)

colnames(x2) <- names(trait.dist)[c(1,3,6:11,14:16)]

coocc.trait.dist <- cbind(x1,x2)
head(coocc.trait.dist)

# scale data for multivariate regression
coocc.trait.dist.scale <- as.data.frame(scale(coocc.trait.dist))

library(piecewiseSEM)

colnames(coocc.trait.dist.scale)
#colnames(coocc.trait.dist.scale)[c(1,9,17)] <- c("coocc5m","FitLogRatio", "LeafArealog")

modlist = list(
    lm(Fit.Log.Ratio ~ SeedMass.log, data = coocc.trait.dist.scale),
    lm(Niche ~ SeedMass.log, data = coocc.trait.dist.scale),
    lm(coocc.5m ~ SeedMass.log + Niche + Fit.Log.Ratio, data = coocc.trait.dist.scale)
    #lm(FitLogRatio ~ LeafArealog, data = coocc.trait.dist.scale)
    #lm(Fit.Log.Ratio ~ Niche + LeafArea.log, data = coocc.trait.dist.scale), # extra path
    #lm(coocc.10m ~ Niche + Fit.Log.Ratio + LeafArea.log, data = coocc.trait.dist.scale)
)

# ,corr.errors=c("Niche~~FitLogRatio"),conditional=T
sem.fit(modlist, coocc.trait.dist.scale, conditional=T, adjust.p=T)
sem.plot(modlist, coocc.trait.dist.scale)
sem.coefs(modlist, coocc.trait.dist.scale)

library(ecodist)

MRM(coocc[[1]] ~ trait.dist[[1]] + trait.dist[[3]], nperm=1000)
MRM(coocc[[1]] ~ trait.dist[[1]] + trait.dist[[3]] + I(trait.dist[[1]] * trait.dist[[3]]), nperm=1000)

#####
# scale dependent changes in interaction strength
############

i <- "302.7"
v <- "(4,5)_"

inter <- foreach(i = c("302.7", "size.1_", "size.5_", "size.10_")) %:%
    foreach(v = c("_1_", "_2_", "_3_", "(1,2)_", "_4_", "(4,5)_"), .combine = rbind) %do% {
        
        mn.path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/"
        mn.list <- list.files(mn.path, pattern=glob2rx(paste0("*grid.full","*",i,"*mean*",v,"*50000*"))) 
                                        # to be changed if sd or 100000 iterations are used
        mn.list
        mn.list <- get(load(paste0(mn.path, mn.list))) 
        
        coocc <- foreach(s = 1:length(mn.list)) %do% {
            as.dist(mn.list[[s]]$beta)
            }        
        names(coocc) <- c("5m", "10m", "20m", "40m", "60m", "80m", "100m")
        ldply(lapply(coocc, sd))
        }

names(inter) <- c("All", "Size.1", "Size.5", "Size.10")
inter.2 <- ldply(inter)

nam.inter <- expand.grid(
    scale = c("5", "10", "20", "40", "60", "80", "100"),
    env = c("1", "2", "3", "1,2", "4", "4,5"),
    size = c("All", "Size.1", "Size.5", "Size.10")
)

inter.3 <- cbind(nam.inter, inter.2)
head(inter.3)

inter.4 <- inter.3[,-c(4)]
names(inter.4)[4] <- "Beta"

##################

pdf("Inter.scales.env.sd.pdf", width = 6, height = 5)
ggplot(inter.4, aes(scale, Beta, color = env, group = env)) + 
    #geom_point() + 
    geom_line() +
    facet_wrap(~size) +
    labs(y="Interaction strength (Beta)", x= "Scale") + 
    #scale_colour_manual(values=gs.pal(8)) +
    geom_hline(yintercept=c(0), color = c("black"), linetype="dashed")
    #geom_hline(yintercept=c(-1.96, 1.96), color = c("grey"), linetype="dashed")
dev.off()

##################
### correlate markov-network to veech results
##################

# install older version of "cooccur" package to calculate effect sizes:
install.packages("/home/oliver/Downloads/cooccur", repos = NULL)

eff.mat <- effect.sizes(bci.data$veech213.15.100[[6]], standardized = T, matrix = T)

ses <- foreach(i = c(2,6,10,14,18), .combine = c) %do% {
  list(cooccur::effect.sizes(bci.data$veech213.15.100[[i]], standardized = T, matrix = T))
}

names(ses) <- names(bci.data$veech213.15.100)[c(2,6,10,14,18)]

veech.ses <- ses

str(coocc)
coocc2 <- coocc[c(3:7)]
str(coocc2)

nam.coocc <- attr(coocc2[[1]], "Labels")

attr(veech.ses[[1]], "Labels")

# check match between species names in trait data and coocc
match(bci.data$traits.213.all[,c(1)], attr(coocc2[[1]], "Labels"))
identical(bci.data$traits.213.all[,c(1)], attr(coocc2[[1]], "Labels"))
# yes, they match

# check match between species names in trait data and veech
match(bci.data$traits.213.all[,c(2)], attr(veech.ses[[1]], "Labels"))
identical(bci.data$traits.213.all[,c(2)], attr(veech.ses[[1]], "Labels"))
# yes, they match

# plot veech.ses vs. 
pdf("cor.veech.mn.pdf", height = 8, width = 12)
par(mfrow = c(2,3))
for (i in 1:5)
{
    plot(veech.ses[[i]], coocc2[[i]], main = names(coocc2)[i])#, xlim=c(-2,2), ylim=c(-2,2)
    #abline(0, 1) 
}
dev.off()

x <- foreach(i = 1:5) %do% {
    cor.test(veech.ses[[i]], coocc2[[i]])$estimate
    #abline(0, 1) 
}
x
# correlations are pretty weak (20m: 0.39 - 100m: 0.68)

############
### something to consider: when looking at univariate regression coeffs. between coocc and demo.diffs, veech shows stronger negative correlation than markov.network beta, across scales  
############

## plot correlation between demographic rate diffs, traits diffs. and phylogen. distance:
######

dist.vec <- foreach(i = c(1,3,8:15), .combine = "cbind") %do% {
    as.vector(trait.dist.phy[[i]])
    }

colnames(dist.vec) <- names(trait.dist.phy)[c(1,3,8:15)]

pdf("Cor.Dist.demo.traits.phylo.pdf", width= 20, height = 20)
CorTestPlot(dist.vec)
dev.off()

#### Idea:
# when presenting relationship between trait and demographic rates, I could show the regression line from SMA if the mantel test was significant (see Fortunel 2014 JEcol)
# or http://link.springer.com/article/10.1007/s10709-008-9271-9 where they use RMA with 10.000 permutations on distance matrices
# or Coyer 2003, mol.Ecol

########################
### short version of the grand analysis function:
########################

out <- foreach(i = c("302.7", "size.1_", "size.5_", "size.10_")) %:%
    foreach(v = c("_1_", "_2_", "_3_", "(1,2)_", "_4_", "(4,5)_"), .combine = rbind) %do% {
        mn.path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Results/MarkovNetworks/"
        traits <- bci.data$traits.164.all
        phylo <- bci.data$phy.164
        rownames(traits) <- bci.data$traits.164.all$sp
        mn.list <- list.files(mn.path, pattern=glob2rx(paste0("*grid.full","*",i,"*mean*",v,"*50000*"))) 
        mn.list
        mn.list <- get(load(paste0(mn.path, mn.list)))
        
        coocc <- foreach(s = 1:length(mn.list)) %do% {
            beta <- mn.list[[s]]$beta
            rownames(beta) <- toupper(rownames(beta))
            colnames(beta) <- toupper(colnames(beta))
            index.beta <- which(colnames(beta) %in% rownames(traits))
            beta.small <- beta[index.beta, index.beta]
            index.traits <- which(rownames(traits) %in% rownames(beta.small))
            traits.small <- traits[index.traits,]
            mat.dis <- match.comm.dist(comm = t(traits.small[,c(3:dim(traits.small)[2])]), dis = as.dist(beta.small))$dis
        }        
        names(coocc) <- c("5m", "10m", "20m", "40m", "60m", "80m", "100m")
        
        beta <- mn.list[[1]]$beta
        rownames(beta) <- toupper(rownames(beta))
        colnames(beta) <- toupper(colnames(beta))
        index.beta <- which(colnames(beta) %in% rownames(traits))
        beta.small <- beta[index.beta, index.beta]
        index.traits <- which(rownames(traits) %in% rownames(beta.small))
        traits.small <- traits[index.traits,]
        traits <- t(match.comm.dist(comm = t(traits.small[,c(3:dim(traits.small)[2])]), dis = coocc[[1]])$comm)
        dim(traits)
        
        trait.dist <- foreach(i = c("1:3", "4:5", "7", "10", "19", "20", "23",   "11", "12", "13", "14", "15", "25", "27")) %do% {
            dist(traits[,eval(parse(text=i))])    
        }
        names(trait.dist) <- c("Niche", "Fitness", "Fit.Log.Ratio", "Rel.pop.change", "Fit.gro.mor.ratio", "Niche.PC1", "Fit.PC1",   "WoodDensity", "MAXHEIGHT", "SeedMass", "LMA", "LeafArea", "NP.PC1", "Wright.8.PC1")

        traits.2 <- traits
        traits.2 <- as.data.frame(traits.2)
        traits.2$sp <- rownames(traits.2)
        library(dplyr)
        traits.2.match <- inner_join(traits.2, bci.data$traits.164.all[,c(1:2)])
        rownames(traits.2.match) <- traits.2.match$species
        traits <- traits.2.match[, -c(25:26)]
        mat <- match.phylo.data(phy = bci.data$phy.164, data = traits)
        phy.mat <- as.dist(cophenetic(mat$phy))
        phy.sort <- match.comm.dist(comm = t(traits[,c(3:dim(traits)[2])]), dis = phy.mat)$dis
        trait.dist.phy <- trait.dist
        trait.dist.phy$phylo <- phy.sort

        coocc <- coocc
        traits <- trait.dist.phy
        modelcoef <- foreach(s = 1:length(coocc)) %:% 
        foreach(t = 1:length(traits), .combine = rbind) %do% {
            round(summary(lm(coocc[[s]] ~ traits[[t]]))$coefficients[2,], 4)          
        }            
        names(modelcoef) <- names(coocc)
        ldply(modelcoef)
    }

#######################################
# plot histograms of trait distances: #
#######################################

traits.untrans <- bci.data$traits.164.all[,3:length(bci.data$traits.164.all)]
traits.untrans.2 <- traits.untrans[ ,c(1:3, 4:5, 7, 11, 12, 13, 14, 15, 25, 27)]

pdf("hist.traits.pdf", height = 9, width = 15)
par(mfrow=c(3,5))
for(i in 1:length(traits.untrans.2)){
    hist((traits.untrans.2[[i]]), main = names(traits.untrans.2)[i])
    }
dev.off()

pdf("dist.untrans.2.pdf", height = 9, width = 15)

par(mfrow=c(3,6))
for(i in 1:length(traits)){
    hist((traits[[i]]), main = names(traits)[i])
    }

dev.off()

pdf("dist.sqrt.trans.pdf", height = 9, width = 15)
par(mfrow=c(3,5))
for(i in 1:length(traits)){
    hist(sqrt(traits[[i]]), main = names(traits)[i])
    }
dev.off()

pdf("dist.log.trans.pdf", height = 9, width = 15)
par(mfrow=c(3,5))
for(i in 1:length(traits)){
    hist(log(traits[[i]]), main = names(traits)[i])
    }
dev.off()


par(mfrow=c(2,5))
for(i in 1:length(coocc)){
    hist((coocc[[i]]), main = names(coocc)[i])
    }

### end of function
#####################

# look at additive effects
round(summary(lm(coocc[[1]] ~ traits[[1]] + traits[[3]] +traits[[14]] + traits[[15]]))$coefficients[-1,], 4)

round(summary(lm(coocc[[1]] ~ traits[[1]] * traits[[3]]))$coefficients[-1,], 3)

round(summary(lm(coocc[[7]] ~ as.dist(scale(traits[[1]])) * as.dist(scale(traits[[15]]))))$coefficients[-1,], 3)

# look at interactions


## MRM
library(ecodist)

i <- 1
j <- 2
mod.mrm <- MRM(coocc[[i]] ~ traits[[j]], nperm=1000)
mod.mrm

modelcoef.mrm <- foreach (i = 1:length(coocc)) %:% 
    
    foreach(j = 1:length(traits), .combine = rbind) %do% {
        
        round(MRM(coocc[[i]] ~ traits[[j]], nperm=2000)$coef[2,], 4)
        
    }
modelcoef.mrm

# !!!! continue here: check the results with some manual univariate analysis
# put in MRM


# consider: running markov network for intermediate to larger scales (20-100m) with 200000 and 500000 iteration, if analyses for 50000 and 100000 iterations do not converge on the same answer to those scales (no problem at small scales, i.e. 5-10m with Pearson r>0.95) 

################################
################################

# 3.6 


# 4) forward selection (packfor, RDA), with and without "shade"
# (prob. not needed, as community composition )


# 5) check whether the size grids match the environmental data


########################
########################

# just check with nadja's species data and env. data have same number of grid cells:

names(bci.data$grid.164)
lapply(bci.data$grid.213, FUN=dim)

# create function that converts env.data into format that fits species data
# takes matrix that has "unordered" environmental variables (at a particular spatial scale) as columns

env.sort <- apply()

# grids are inconsistent:
# nadja:
5m: 19976
10m: 5000
20m: 1250
40m: 300
60m: 128
80m: 72
100m: 50

stefan:
5m: 20000
10m: 5000
20m: 1250
40m: 325
60m: 153
80m: 91
100m: 50


#!! check again some single files Nadja send me earlier!!!
grid40 <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/Abundance_gridcells40_1990.txt")
dim(grid40)

# 40m
dim(bci.data$grid.213[[8]])
bci.data$grid.213[[8]][,1:5]

which(1:20000 %in% rownames(grid5)==F)

# at the 5m scales, number of grid cells also differ between the censuses


##########

filled.contour (matrix (rnorm(1250), ncol = 25, byrow = T), color.palette = terrain.colors, main = 'pH')
filled.contour (matrix (soil20x20$Al, ncol = 25, byrow = T),
color.palette = terrain.colors, main = 'pH')
filled.contour (matrix (scores(PCAenv, choices=c(2)), ncol = 25, byrow = T), color.palette = terrain.colors, main = 'pH')

PCAenv <- prcomp(soil20x20[ ,3:15])
summary(PCAenv)
scores(PCAenv, choices=c(1,2))
biplot(PCAenv)

################# 
# cross-scale analyses of community and environmental data (markov networks):

lapply(bci.data$grid.213, FUN=dim)

# just select the 7 scales (5, 10, 20, 40, 60, 80, 100m)
# 1) list for abundance grids at the 7 scales:
grid.213.7 <- bci.data$grid.213[c(1,2,4,8,12,16,20)]
length(grid.213.7)
names(grid.213.7)
lapply(grid.213.7, FUN=dim)

save(grid.213.7, file = "grid.213.7.Rdata")

# 2) list for enviormental data at the 7 scales:
env.to.spec <- function(x, ncol){
    as.vector(matrix(x, ncol = ncol, byrow = T))
}
 
# 5m:
ncol <- 200 # corresponds to 1000m / grain size (long side of bci)
env.5 <- as.data.frame(cbind(
   env.to.spec(slope.5m.txt[,1], ncol = ncol),
   env.to.spec(elev.5m.txt[,1], ncol = ncol),
   env.to.spec(curv.5m.txt[,1], ncol = ncol)) 
    )
colnames(env.5) <- c("slope.5m", "elev.5m", "curv.5m")

# 100m:
ncol <- 10 # corresponds to 1000m / grain size (long side of bci)
env.100 <- as.data.frame(cbind(
   env.to.spec(slope.100m.mean.txt[,1], ncol = ncol),
   env.to.spec(elev.100m.mean.txt[,1], ncol = ncol),
   env.to.spec(curv.100m.mean.txt[,1], ncol = ncol),
   env.to.spec(slope.100m.sd.txt[,1], ncol = ncol),
   env.to.spec(elev.100m.sd.txt[,1], ncol = ncol),
   env.to.spec(curv.100m.sd.txt[,1], ncol = ncol)) 
    )
colnames(env.100) <- c("slope.100m.mean", "elev.100m.mean", "curv.100m.mean", "slope.100m.sd", "elev.100m.sd", "curv.100m.sd")


filled.contour((matrix(env.100[,1], ncol = 5, byrow = T)), color.palette = terrain.colors, main = "Slope.100m") # ncol here corresponds to 500m / grain size (short side of bci)

filled.contour(log(matrix(grid.213.7[[7]][,147], ncol = 5, byrow = T)), color.palette = terrain.colors, main = "Slope.20m") # ncol here corresponds to 500m / grain size (short side of bci)

# all grids are 1000x500, apart from:
# 40m: 1000 x 480
# 60m: 960 x 480
# 80m: 960 x 480

## combine env. data frames in a list

env.topo.7 <- list("env.5" = env.5, "env.10" = env.10, "env.20" = env.20, "env.40" = env.40, "env.60" = env.60, "env.80" = env.80, "env.100" = env.100)

save(env.topo.7, file = "env.topo.7.Rdata")

###
# add pca-axes:
PC1.topo.100.mean <- scores(prcomp(scale(env.topo.7$env.100[ ,1:3])), choices=c(1))
PC1.topo.100.mean.sd <- scores(prcomp(scale(env.topo.7$env.100[ ,1:6])), choices=c(1))
PC1.topo.100.sd <- scores(prcomp(scale(env.topo.7$env.100[ ,4:6])), choices=c(1))
env.topo.7$env.100$PC1.topo.100.mean <- PC1.topo.100.mean
env.topo.7$env.100$PC1.topo.100.mean.sd <- PC1.topo.100.mean.sd
env.topo.7$env.100$PC1.topo.100.sd <- PC1.topo.100.sd
####

colnames(env.topo.7$env.10)[7] <- "slope.10m.sd"


summary(PC1.topo.100.mean)
#scores(PCAenv20, choices=c(1,2))
biplot(PCAenv20)



filled.contour (matrix (scores(PC1.topo.5.mean, choices=c(1)), ncol = 100, byrow = T), color.palette = terrain.colors, main = 'PC1')

filled.contour (matrix (env.topo.7$env.80[,8], ncol = 6, byrow = T), color.palette = terrain.colors, main = 'PC1')

#################
# prepare loop for markov script
##########################

# !!! check everything with "!!!"

library(vegan)
library(rosalia)
library(mistnet)
library(doParallel)
# Find out how many cores are available (if you don't already know)
detectCores()
# Create cluster with desired number of cores
cl <- makeCluster(2) # !!! set to 2, since the first process (20,000 sites) takes ages on one core, while the other can finish on the second core 
# Register cluster
registerDoParallel(cl)
# Find out how many cores are being used
getDoParWorkers()

########
# # outside the loop
`%plus%` = mistnet:::`%plus%`
logistic = binomial()$linkinv # logistic inverse link
rbern = function(p){rbinom(length(p), size = 1, prob = p)}

# load("env.scale.2.sd.PC.Rdata") ### !!! change to "mean"
load("env.scale.2.mean.PC.Rdata")
# load("grid.213.7.Rdata") # !!! change to "size"
load("grid.size.5.Rdata")


######################
MN.7.shade.size.5.mean <- foreach (s = 1:7, .packages=c("rosalia", "mistnet","vegan")) %dopar% { 
# !!! change to "1:7" if means are used
y <- as.matrix(grid.size.5[[s]]) # !!! for "mean" change to [[s+1]]...
# y <- as.matrix(grid.213.7[[s]])                                     # !!! change to just "s", if means instead of sd are used
# transform into presence-absence matrix:
y <- decostand(y, "pa")

###################################################################
####### to be changed depending on which env. data should be used
env = true_env <- x <- soil.13 <- scale(env.scale.2.mean.PC[[s]][,c(26)]) #!!!! change to the right variable set
    # -c(26,29,30) all.env
    # c(26) shade
    # c(29) PC.1
    # c(29,30) PC.1.2 
    # c(24) pH
###################################################################

set.seed(1)
n_spp = ncol(y)   # number of species
n_loc = nrow(y)    # number of locations
n_env = ncol(x)     # number of environmental predictors

n_gibbs = 5000  # number of Gibbs sampling iterations
######################

y_stats = crossprod(y)
y_env_stats = t(true_env) %*% y
y_sim = matrix(0.5, nrow = nrow(y), ncol = ncol(y))
env = true_env
alpha_env = delta_alpha_env = matrix(0, nrow = n_env, ncol = n_spp)
alpha_species = qlogis((colSums(y) + 1) / (nrow(y) + 2))
delta_alpha_species = rep(0, n_spp)
beta = delta_beta = matrix(0, nrow = n_spp, ncol = n_spp)
alpha = matrix(0, nrow = n_spp, ncol = n_spp) 

alpha_env_prior = rosalia::make_logistic_prior(scale = 2)$log_grad 
alpha_species_prior = rosalia::make_logistic_prior(scale = 2)$log_grad
beta_prior = rosalia::make_logistic_prior(scale = 0.5)$log_grad

initial_learning_rate = 1 # step size at start of optimization

##############################################
### needs to be changed
maxit = 25000        
                                        # !!! 25000, Number of rounds of optimization # try 50000 and 100000 as well
########################################
start_time = as.integer(Sys.time())
times = integer(maxit)
        for(i in 1:maxit){
  ##############################
  # Gibbs sampling for predicted species composition
  ##############################

  # Update alpha
  alpha = env %*% alpha_env %plus% alpha_species

  # Sample entries in y_sim from their conditional 
  # distribution (Gibbs sampling)
    for(j in sample.int(n_spp)){
    y_sim[,j] = rbern(logistic(alpha[ , j] + y_sim %*% beta[ , j]))
  }

  ##############################
  # Stochastic approximation for updating alpha and beta
  ##############################

  # Update learning rate and momentum
 
    learning_rate = initial_learning_rate * 1000 / (998 + 1 + i)
 momentum = .9 * (1 - 1/(.1 * i + 2))

  # Calculate sufficient statistics
  y_sim_stats = crossprod(y_sim)
  y_sim_env_stats = t(env) %*% y_sim


  stats_difference = y_stats - y_sim_stats
  beta_grad = (stats_difference + beta_prior(beta)) / n_loc

  alpha_species_grad = (
    diag(stats_difference) + 
      alpha_species_prior(alpha_species)
  ) / n_loc
  diag(beta_grad) = 0 # beta_ii is 0 by convention
  y_env_difference = y_env_stats - y_sim_env_stats
  alpha_env_grad = (y_env_difference + 
                      alpha_env_prior(alpha_env))  / n_loc


  delta_beta = beta_grad * learning_rate + momentum * delta_beta
  delta_alpha_species = alpha_species_grad * learning_rate + 
    momentum  * delta_alpha_species
  delta_alpha_env = alpha_env_grad * learning_rate +
    momentum  * delta_alpha_env

  beta = beta + delta_beta
  alpha_species = alpha_species + delta_alpha_species
  alpha_env = alpha_env + delta_alpha_env
  times[i] = as.integer(Sys.time()) - start_time
}
        list("alpha_species"=alpha_species, "alpha_env"=alpha_env, "beta"=beta)

}
save(MN.7.shade.size.5.mean, file = "MN.7.shade.size.5.mean.Rdata")

################
### end here #
################

## check MN output from R-server
load("MN.6.topo.mean.sd.Rdata")
load("MN.6.topo.sd.Rdata")
load("MN.6.topo.sd.PC1.Rdata")
load("MN.6.topo.mean.PC1.Rdata")
load("MN.6.topo.mean.sd.PC1.Rdata")

names(MN.6.topo.sd.PC1)
rownames(MN.6.topo.mean.sd$alpha_env)

lapply(MN.6.topo.mean.PC1[c(3,6,9,12,15,18)], FUN=mean)
lapply(MN.6.topo.mean.PC1[c(3,6,9,12,15,18)], FUN=quantile)

scalevec <- c(10,20,40,60,80,100)
betavec <- c(3,6,9,12,15,18)
par(mfrow=c(2,3))
for (i in 1:6){
    plot(density(MN.6.topo.mean.PC1[[betavec[i]]]), xlim = c(-1,1), main = scalevec[i])
    #abline(v=mean(MN.6.topo.mean.PC1[[betavec[i]]]))
    abline(v=0)
}


# correlate betas from the different env. datasets:
cor(as.dist(MN.6.topo.mean.sd[[c(18)]]), as.dist(MN.6.topo.sd[[c(18)]]))
# strong correlation between beta (mean+sd vs sd.only) at the 10 and 20m scales (0.95) but much weaker corralation at the scales of 40m and above (0.67)

# raw vs. pc1
cor(as.dist(MN.6.topo.mean.sd[[c(9)]]), as.dist(MN.6.topo.mean.sd.PC1[[c(9)]]))
# even for the same trait set, correlation change from high to low if we compare a raw data PC1

# mean.PC1 vs. sd.PC1
cor(as.dist(MN.6.topo.sd.PC1[[c(18)]]), as.dist(MN.6.topo.mean.PC1[[c(18)]]))
# correlation change from high to low if we compare mean.PC1 with sd.PC1

# mean raw vs. mean PC1
cor(as.dist(MN.6.topo.sd[[c(9)]]), as.dist(MN.6.topo.sd.PC1[[c(9)]]))

# which env.data to take for the across-life stage analysis?
## clearly, we should use both mean and sd, but should we the raw or the 
## import and clean the life stage grids:

# match to the species in the abundance grid
# read all files:
path <- "/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abundance_gridcells/SizeClasses/"
temp <- list.files(path, pattern="*.txt")
for(file in temp)
{
    perpos <- which(strsplit(file, "")[[1]]==".")
    assign(
        gsub(" ","",substr(file, 1, perpos-1)), 
        read.table(paste(path,file,sep="")))
}

# match the grids

i <- 20
j <- 1990
k <- "10cm"

gridlist <- list()
for (i in c(5,10,20,40,60,80,100)){
    for (j in c(1990)){ 
        for (k in c("1_5cm","5_10cm","10cm")){                            # just if there are several years        
        # i <-20
        colnames(get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_")))[which(colnames(get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_"))) %in% traits.abu.213$sp == FALSE)]
        
            as.character(traits.abu.213$sp)[which(as.character(traits.abu.213$sp) %in% colnames(get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_"))) == FALSE)]
        

            traits.abu.213$sp <- as.character(traits.abu.213$sp)
        new.205 <- get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_"))[, which(colnames(get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_"))) %in% traits.abu.213$sp)]
                                        # reorder short names according to trait data
        # new.205 <- get(paste(paste(paste("Abundance_gridcells", i, sep = ""), j, sep = "_"), k, sep = "_"))[, traits.abu.213$sp]
                                        # give full names to gridded data
#colnames(new.205) <- rownames(traits.abu.213)
        gridlist <- c(gridlist, list(new.205))    
        }
    }
}


# name the grid list
gridlistnames <- NA

for (i in c(5,10,20,40,60,80,100)){
    for (j in c(1990)){ 
        for (k in c("1_5cm","5_10cm","10cm")){ 
        gridlistnames <- c(gridlistnames, paste(i,j,k, sep = "."))
        }
    }    
}

gridlistnames <- gridlistnames[-1]
# create comma-separated name vector
cat(paste(shQuote(gridlistnames, type="cmd"), collapse=", "))

names(gridlist) <- c(
"5.1990.1_5cm", "5.1990.5_10cm", "5.1990.10cm", "10.1990.1_5cm", "10.1990.5_10cm", "10.1990.10cm", "20.1990.1_5cm", "20.1990.5_10cm", "20.1990.10cm", "40.1990.1_5cm", "40.1990.5_10cm", "40.1990.10cm", "60.1990.1_5cm", "60.1990.5_10cm", "60.1990.10cm", "80.1990.1_5cm", "80.1990.5_10cm", "80.1990.10cm", "100.1990.1_5cm", "100.1990.5_10cm", "100.1990.10cm"
)

dim(gridlist[[19]])

grid.size.1 <- gridlist[seq(1,21,3)]
grid.size.5 <- gridlist[seq(2,21,3)]
grid.size.10 <- gridlist[seq(3,21,3)]

save(grid.size.1, file = "grid.size.1.Rdata")
save(grid.size.5, file = "grid.size.5.Rdata")
save(grid.size.10, file = "grid.size.10.Rdata")

lapply(grid.size.10, dim)

#################
# import MN.outputs for different size classes:
#################
# 10-100m scale
load("MN.6.topo.sd.PC1.size.10.Rdata")
load("MN.6.topo.sd.PC1.size.5.Rdata")
load("MN.6.topo.sd.PC1.size.1.Rdata")
load("MN.6.topo.mean.PC1.size.10.Rdata")
load("MN.6.topo.mean.PC1.size.5.Rdata")
load("MN.6.topo.mean.PC1.size.1.Rdata")

# 5-100m scales
load("MN.7.topo.mean.Rdata")
load("MN.7.topo.mean.size.1.Rdata")
load("MN.7.topo.mean.size.5.Rdata")
load("MN.7.topo.mean.size.10.Rdata")

names(MN.7.topo.mean)

lapply(MN.7.topo.mean[c(3,6,9,12,15,18,21)], FUN=function(x){median(as.dist(x))})


lapply(MN.6.topo.mean.PC1.size.1[c(3,6,9,12,15,18)], FUN=function(x){median(as.dist(x))})
lapply(MN.6.topo.sd.PC1.size.10[c(3,6,9,12,15,18)], FUN=function(x){quantile(as.dist(x))})


x <- MN.7.topo.mean
scalevec <- c(5,10,20,40,60,80,100)
betavec <- c(3,6,9,12,15,18,21)
par(mfrow=c(2,4))
for (i in 1:7){
     plot(density(x[[betavec[i]]]), xlim = c(-1,1), main = scalevec[i])
     #abline(v=median(x[[betavec[i]]]))
     abline(v=0)
}

# for comparison, look at some traditional coocc-indces:
apply(bci.data$check.213.ses.1s, 2, FUN=function(x){mean(x, na.rm=T)})
apply(bci.data$check.213.ses.3t, 2, FUN=function(x){median(x, na.rm=T)})


####### correlate interaction strenght 
# look standardized effect sizes of the relationship between interaction strength and niche and fitness differences:

# continue here:
# modify the following code :

# get the demographic rates (+ add nadja's new fitness measures)

traits.new <- read.table("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Data/Traits/Nadja_Traits/abun/new_fitness_measures_relpopchange.txt", stringsAsFactors = F)
dim(traits.new)
str(traits.new)

names(traits.new)
CorTestPlot(traits.new[,-c(1,7)])

niche.fit.scaled <- as.data.frame((cbind(niche, fitness)))

modelcoef <- NA

for (i in 1:7){
resp.vec <- bci.data$check.205.ses.1s[,i]
mod <- lm(resp.vec ~ niche*fitness, data = niche.fit.scaled)                   
modelcoef <- rbind(modelcoef, melt(summary(mod)$coefficients))
}
modelcoef <- modelcoef[-1,]
modelcoef$scale <- rep(seq(10,100,5), each=16)
colnames(modelcoef)[c(1:2)] <- c("variable", "coefficient")
str(modelcoef)

modelcoef$variable <- as.character(modelcoef$variable)
modelcoef$coefficient <- as.character(modelcoef$coefficient)

 ##

modelcoef.estim <- modelcoef[modelcoef$coefficient=="t value",]
modelcoef.estim.2 <-
modelcoef.estim[modelcoef.estim$variable!="(Intercept)",]
modelcoef.estim.2 <-
modelcoef.estim.2[modelcoef.estim.2$variable!="niche.vec:fit.vec",]

modelcoef.estim.3 <- modelcoef.estim.2[,-2]
# scale >15
modelcoef.estim.4 <- modelcoef.estim.3[modelcoef.estim.3$scale > 15, ]
modelcoef.estim.4$variable <- as.factor(modelcoef.estim.4$variable)
modelcoef.estim.4$value <- -(modelcoef.estim.4$value)
modelcoef.estim.5 <- modelcoef.estim.4

# rerun for t-value

# do the lattice plot
# include interaction
div <- xyplot(value ~ scale, groups=variable, data =
modelcoef.estim.4, type = "l", lty = c(1), par.settings =
list(axis.line = list(col = 0)),scales=list(col=1,tck=c(-1,0)),  #
remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 4.5)
                panel.abline(h=0,lwd=1, lty=2, col="black")
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 2.5, col = c("red","green","black"), xlab = "Scale (m)", ylab =
"Correlation", key=list(space="inside",  between = 1, padding.text =
2, just = c(.6, .5), columns = 1, lines = list(lty = c(1), lwd = 2.5,
col = c("red","green","black")),text = list(c("Fitness diff.",
"Niche.diff", "Niche x Fitness"))))
plot(div)

pdf(file = "Scales.t_value.inter.PCA1-3.coef.scale.pdf",width = 4.2, height = 4, pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()



####################

# functions to calculate coordinates for grid cells:
# !!! check with nadja since both scale 95 and scale 100 have 50 grid cells

index.to.rowcol <- function(index,gridsize=20,plotdim=c(1000,500))
{
index=index-1

badindex=(index<0 | index>=plotdim[1]*plotdim[2]/(gridsize^2))

maxrow=floor(plotdim[2]/gridsize)
rowno=index%%maxrow
colno=floor((index-rowno)/maxrow)
row=rowno+1
col=colno+1

if(length(badindex[badindex>0])) row[badindex]=col[badindex]=-1

return(data.frame(row=row,col=col))
} 

index.to.gxgy <- function(index,gridsize=20,plotdim=c(1000,500))
{
badindex <- (index<=0 | index>plotdim[1]*plotdim[2]/(gridsize^2))

rc <- index.to.rowcol(index,gridsize,plotdim)
gx <- gridsize*(rc$col-1)
gy <- gridsize*(rc$row-1)

if(length(badindex[badindex>0])) gx[badindex]=gy[badindex]=-1

return(data.frame(gx=gx,gy=gy))
}

index.to.gxgy(1:10,gridsize=100,plotdim=c(1000,500))




#############################################################
# table of how many species associations are non-random (% of lower
and higher than )
# ! based on checkerboard (segregation) score
#############################################################
non.rand <- matrix(nrow=6, ncol=2)
colnames(non.rand) <- c("low.coocc", "high.coocc")
rownames(non.rand) <- c("5", "10","20","33","50", "100")
for (i in 1:6){
non.rand[i,1] <- 100*(sum(bci.data$check.205.ses.1a[,i]>1.96)/20910) #
low co-occurrence (segregation)
non.rand[i,2] <- 100*(sum(bci.data$check.205.ses.1a[,i]< -1.96)/20910)
# high co-occurrence
}

write.csv(non.rand, "Non.Rand.Check.SES.1a.csv")

##########

# 3) correlation plot between phylogenetic distance and niche and
fitness differences
mat <- match.phylo.comm(phy=bci.data$phy206,
comm=bci.data$grid.205[[1]])
phy205 <- mat$phy
match(colnames(bci.data$grid.205[[1]]), phy205$tip.label)

match(rownames(bci.data$traits.abu.all.205[ ,c(25,39)]), attr(resp, "Labels"))

bci.data$phy205 <- phy205

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])
resp <- as.dist(cophenetic(phy205))
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
                   labels = F,
                 contour = F,
            ylab = "Fitness differences",
            main = "PhyDist"
            ,
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
fig

####

pdf("PhyDist.Niche.Fit.PCall.pdf", width=8.5, height = 8)
plot(fig)
dev.off()

# test the relationships beween phylogenetic distance and niche and
fitness differences (permutation based)
niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])
niche.vec <- as.vector(niche.dist)
fit.vec <- as.vector(fit.dist)

#resp <- as.dist(cophenetic(bci.data$phy205))
#resp.vec <- as.vector(resp)

colnames(bci.data$check.205.ses.1s)

# 

modelcoef <- NA

for (i in 1:19){
resp.vec <- bci.data$check.205.ses.1s[,i]
mod <- lm(resp.vec ~ niche.vec*fit.vec)                   
modelcoef <- rbind(modelcoef, melt(summary(mod)$coefficients))
}
modelcoef <- modelcoef[-1,]
modelcoef$scale <- rep(seq(10,100,5), each=16)
colnames(modelcoef)[c(1:2)] <- c("variable", "coefficient")
str(modelcoef)

modelcoef$variable <- as.character(modelcoef$variable)
modelcoef$coefficient <- as.character(modelcoef$coefficient)

##

modelcoef.estim <- modelcoef[modelcoef$coefficient=="t value",]
modelcoef.estim.2 <-
modelcoef.estim[modelcoef.estim$variable!="(Intercept)",]
modelcoef.estim.2 <-
modelcoef.estim.2[modelcoef.estim.2$variable!="niche.vec:fit.vec",]

modelcoef.estim.3 <- modelcoef.estim.2[,-2]
# scale >15
modelcoef.estim.4 <- modelcoef.estim.3[modelcoef.estim.3$scale > 15, ]
modelcoef.estim.4$variable <- as.factor(modelcoef.estim.4$variable)
modelcoef.estim.4$value <- -(modelcoef.estim.4$value)
modelcoef.estim.5 <- modelcoef.estim.4

# rerun for t-value

# do the lattice plot
div <- xyplot(value ~ scale, groups=variable, data =
modelcoef.estim.4, type = "smooth", lty = c(1), par.settings =
list(axis.line = list(col = 0)),scales=list(col=1,tck=c(-1,0)),  #
remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 4.5)
                panel.abline(h=0,lwd=1, lty=2, col="black")
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 2.5, col = c("red","green","black"), xlab = "Scale (m)", ylab =
"Correlation", key=list(space="inside",  between = 1, padding.text =
2, just = c(.6, .5), columns = 1, lines = list(lty = c(1), lwd = 2.5,
col = c("red","green","black")),text = list(c("Fitness diff.",
"Niche.diff", "Niche x Fitness"))))
plot(div)

pdf(file = "Scales.t_value.inter.pdf",width = 4.2, height = 4,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

##
summary(mod)$r.squared


##
mod <- lmp(resp.vec ~ niche.vec + fit.vec)                   
gc()


########

#############


# 4) plot for "check.1990.wo.rec.a" (7 scales) ~ phylogenetic distance

c(3,10,17,24,31,38,45)

res <- list()
pdf("Phylo.Check.spat.10-100.pdf", width=34.5, height = 6)
par(mfrow=c(2,10))
for (i in c(2:20)){
coocc.phylo.qr <- comm.phylo.qr(bci.data$grid.205[[i]], phy205,
metric="check",null.model="sample.taxa.labels", show.plot = TRUE, runs
= 999)
res <- c(res, list(coocc.phylo.qr))
}
dev.off()
Phylo.Check.spat.10.100 <- res

bci.data$Phylo.Check.spat.10.100 <- Phylo.Check.spat.10.100

Phylo.Coocc.results <- NA
for (i in 1:19){
    Phylo.Coocc.results <-
rbind(Phylo.Coocc.results,unlist(bci.data$Phylo.Check.spat.10.100[[i]][1:5]))
}

Phylo.Coocc.results <- Phylo.Coocc.results[-1,]
#Phylo.Coocc.results <- as.data.frame(Phylo.Coocc.results)

rownames(Phylo.Coocc.results) <- seq(10,100,5)

Phylo.Coocc.results$p.one.side <- 1-(Phylo.Coocc.results[,3])
Phylo.Coocc.results$p.two.side <- (1-(Phylo.Coocc.results[,3]))*2

write.csv(Phylo.Coocc.results, file =
"Phylo.Coocc.results.10.100.csv")


# calculate regression coefficients and t-values for the coocc ~
phy.dist

phy.vec <- as.vector(as.dist(cophenetic(phy205)))
    
modelcoef <- NA
for (i in 1:19){
resp.vec <- bci.data$check.205.ses.1s[,i]
mod <- lm(resp.vec ~ phy.vec)                   
modelcoef <- rbind(modelcoef, melt(summary(mod)$coefficients))
}

modelcoef <- modelcoef[-1,]
modelcoef$scale <- rep(seq(10,100,5), each=8)
colnames(modelcoef)[c(1:2)] <- c("variable", "coefficient")
str(modelcoef)

modelcoef$variable <- as.character(modelcoef$variable)
modelcoef$coefficient <- as.character(modelcoef$coefficient)

modelcoef.estim <- modelcoef[modelcoef$coefficient=="t value",]
modelcoef.estim.2 <-
modelcoef.estim[modelcoef.estim$variable!="(Intercept)",]

modelcoef.estim.3 <- modelcoef.estim.2[,-2]

# scale >15
modelcoef.estim.4 <- modelcoef.estim.3[modelcoef.estim.3$scale > 15, ]
modelcoef.estim.4$variable <- as.factor(modelcoef.estim.4$variable)
modelcoef.estim.4$value <- -(modelcoef.estim.4$value)

modelcoef.estim.6 <- rbind(modelcoef.estim.5, modelcoef.estim.4)

div <- xyplot(value ~ scale, groups=variable, data =
modelcoef.estim.6, type = "smooth", lty = c(1), par.settings =
list(axis.line = list(col = 0)),scales=list(col=1,tck=c(-1,0)),  #
remove top and right axes
              panel=function(...){
                lims <- current.panel.limits()
                panel.xyplot(...)
                panel.abline(h=lims$ylim[1],v=lims$xlim[1], lwd = 4.5)
                panel.abline(h=0,lwd=1, lty=2, col="black")
              },
              layout.heights=list(axis.xlab.padding = 1),
lwd = 2.5, col = c("red","green","black"), xlab = "Scale (m)", ylab =
"Correlation", key=list(space="inside",  between = 1, padding.text =
2, just = c(.6, .5), columns = 1, lines = list(lty = c(1), lwd = 2.5,
col = c("red","green","black")),text = list(c("Fitness diff.",
"Niche.diff", "Phylo.diff"))))
plot(div)

pdf(file = "Scales.t_value.phylo.pdf",width = 4.2, height = 4,
pointsize=12)
# postscript(file = "BCI.DivergenceSize.eps",width = 6, height = 6.5,
paper = "special", onefile = FALSE, horizontal = FALSE, pointsize=12)
plot(div)
dev.off()

# redo surface plot coocc ~ niche vs. fitness (without dots and larger
labelling)

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])

resp <- as.vector(as.dist(cophenetic(phy205)))
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))

pdf(file = "Phy.dist.PCnich.PCfit.pdf", width = 5, height = 4.6,
pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE, 
            labels = F,
                 contour = F,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phylogenetic distance"
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )        
dev.off()   



# 5) use Susanne Fritz's funcion to plot fitness and niche traits on
phylogeny


###################

colnames(Coocc.2x.20.1990.check)

niche.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(14,28,42)],
scale = T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2])
resp <- Coocc.1a.20.1990.check[,1]
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
fig <- contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Obs_Null.1s.cij.SES.10.1990"
            ,
            panel=function(...){
            panel.contourplot(...)
            grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          }
            )
fig

####

pdf("Obs_Null.1s.check.SES.20.1990.pdf", width=10, height = 10)
plot(fig)
dev.off()

# order species according to their niche and fitness scores:
# 
library(dplyr)

fit.df <- rda(bci.data$traits.abu.all.205[ ,c(25,39)], scale =
T)$CA$u[,1:2]
fit.df <- as.data.frame(fit.df)
fit.df <- as.data.frame(cbind(rownames(fit.df),fit.df))

fit.df.arr <- arrange(fit.df, PC1)

write.csv(fit.df.arr, "fit.df.arr.csv")

#############

# ! save all the coocc.data.sets

# ? why is there switch between 20 and 50 m?

# for phylo.dist:

niche.dist <- dist(rda(bci.data$traits.abu.all[ ,c(14,28,42)], scale =
T)$CA$u[,1:3])
fit.dist <- dist(rda(bci.data$traits.abu.all[ ,c(11,25,39)], scale =
T)$CA$u[,1:3])
resp <- as.vector(phy.dist.206)
#resp <- bci.data$distvec.traits.phy.cooc$coocc.check
#niche <- bci.data$distvec.traits.phy.cooc$PC1.Nich
niche <- as.vector(niche.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$PC1.Fit
fitness <- as.vector(fit.dist)
#fitness <- bci.data$distvec.traits.phy.cooc$abund.rel
phylodistance <- loess(resp ~ niche*fitness, span = 1, degree = 1) #
try additive effect
n.marginal <- seq(min(niche), max(niche), length.out = 50)
f.marginal <- seq(min(fitness), max(fitness), length.out = 50)
nf.marginal <- list(niche = n.marginal, fitness = f.marginal)
grid <- expand.grid(nf.marginal)
grid[, "fit"] <- c(predict(phylodistance, grid))
pdf(file = "Phy.dist.PCnich.PCfit.(spa1dec1).pdf", width = 8, height =
7.8, pointsize=12)
contourplot(fit ~ niche * fitness, data = grid,
            cuts = 10, region = TRUE,
            xlab = "Niche differences",
            ylab = "Fitness differences",
            main = "Phy.dist ~ niche*fitness"
            #,
            #panel=function(...){
            #panel.contourplot(...)
            #grid.points(niche, fitness, pch=1, size=unit(.001,
"char"))
          #}
            )        
dev.off()   


## !!! #################
# to do for Rick Condit by mid August latest i) different scales (for
check 19; ii)
# Nadja mentioned that ()
# test correlation between 1985 and 1990 traits

# also try: i) combining the two censuses, ii) on all three fitness
PCs (with and without rec.a), ii) 1985 and 1990 censuses
# test for correlations between traits in the 1st and 2nd census

pdf(file = "CorFit.Cens1985.90.pdf", width = 18, height = 18,
pointsize=12)
CorTestPlot(bci.data$traits.abu.all[,c(3,4,10,11,17,18,24,25,31,32,38,39)])
dev.off()

pdf(file = "CorNich.Cens1985.90.pdf", width = 18, height = 18,
pointsize=12)
CorTestPlot(bci.data$traits.abu.all[,c(3,7,10,14,17,21,24,28,31,35,38,42)])
dev.off()

# 3) plot trait values on the phylogeny (using script of Susanne
Fritz)
# have a look at will pearse' function, see
http://willeerd.wordpress.com/page/2/

  require(stats)
     attach(environmental)
     ozo.m <- loess((ozone^(1/3)) ~ wind * temperature * radiation,
            parametric = c("radiation", "wind"), span = 1, degree = 2)
     w.marginal <- seq(min(wind), max(wind), length.out = 50)
     t.marginal <- seq(min(temperature), max(temperature), length.out
= 50)
     #r.marginal <- seq(min(radiation), max(radiation), length.out =
4)
     wtr.marginal <- list(wind = w.marginal, temperature = t.marginal,
             radiation = r.marginal)
     grid <- expand.grid(wtr.marginal)
     grid[, "fit"] <- c(predict(ozo.m, grid))
     contourplot(fit ~ wind * temperature | radiation, data = grid,
                 cuts = 10, region = TRUE,
                 xlab = "Wind Speed (mph)",
                 ylab = "Temperature (F)",
                 main = "Cube Root Ozone (cube root ppb)")
     detach()
   
# alternative ways to plot to do contour plots:
# a) with ggplot:
http://www.google.de/imgres?imgurl=http%3A%2F%2Flearnr.files.wordpress.com%2F2009%2F07%2Fchapter06-06_14_r.png&imgrefurl=http%3A%2F%2Flearnr.wordpress.com%2F2009%2F07%2F20%2Fggplot2-version-of-figures-in-lattice-multivariate-data-visualization-with-r-part-6%2F&h=320&w=580&tbnid=RDMURNiefuH3CM%3A&zoom=1&docid=nw1Wvt3-uhmvVM&ei=aIkiVKb9JOG7ygPH4oDwCw&tbm=isch&client=ubuntu&iact=rc&uact=3&dur=206&page=1&start=0&ndsp=45&ved=0CKMBEK0DMCk
# b) within the range of the data:
http://stackoverflow.com/questions/7851602/methods-for-doing-heatmaps-level-contour-plots-and-hexagonal-binning


#### just for fun:
# do phylogenetic PCA

pca.phy <- phyl.pca(bci.data$phy206,
bci.data$traits.pca[,c(2,4,6,8,10,12)], method="BM", mode="corr")



# multi-rate BM models: 
# rjmcmc(tree, trait, type = "rbm")
# bayou ...
# might use BAMMtools, Surface (mahler)
# Khabbazian, MEE, 2016: Fast and accurate detection of evolutionary shifts in Ornstein–Uhlenbeck models

##############

# run additional tests that:
# i) that include the ~ 200 species that species for which all traits are available
# plot trait values on the phylogeny 
# plot nodewise phylogenetic signal, mean values, variance and contribution index



# plot added species with differnt color on the phylogeny


# other steps:
# "Appunia_seibertii"] <- "Morinda_seibertii" #!! to be changed in throughout Nadja's trait data # add small number to zero branch lenght
 # ?!? what about "Swartzia_simplex_var.grandiflora" (corresponds to "SWARS1" accoriding to Nadja's trait table)

#####
# preparing BCI-data for macroevolutionary model analysis with Luke Harmon:
###########

load("bci.data.Rdata")
str(bci.data$phy205)
rownames(bci.data$traits.abu.all.205)
mat <- match.phylo.data(bci.data$phy205, bci.data$traits.abu.all.205)

phylo.205 <- mat$phy
traits.205 <- mat$data

## 1) tree for which complete  for all demographic traits is available: 205 species
chronotree <- chronoMPL(multi2di(phylo.205))
is.ultrametric(chronotree)

bci.phylo.205 <- chronotree
write.tree(bci.phylo.205, file = "bci.phylo.205.tre")
bci.phylo.205 <- read.tree("bci.phylo.205.tre")
# plot lineages through time

## 2) tree for species for which at least one demographic trait is available: 308 species
bci.phylo.308 <- bci.data$phy.308
is.ultrametric(bci.phylo.308)
chronotree <- chronoMPL(multi2di(bci.phylo.308))
is.ultrametric(chronotree)
bci.phylo.308 <- chronotree
write.tree(bci.phylo.308, file = "bci.phylo.308.tre")
bci.phylo.308 <- read.tree("bci.phylo.308.tre")

## 3) full BCI tree: 465 species
bci.phylo.465 <- bci.data$phyfull
is.ultrametric(bci.phylo.465)
chronotree <- chronoMPL(multi2di(bci.phylo.465))
is.ultrametric(chronotree)
bci.phylo.465 <- chronotree
write.tree(bci.phylo.465, file = "bci.phylo.465.tre")
bci.phylo.465 <- read.tree("bci.phylo.465.tre")

### 4) what about tree for all BCI species? ask Nadja

######

###
str(bci.data$phy205)
rownames(bci.data$traits.abu.all.205)
mat <- match.phylo.data(bci.data$phy205, bci.data$traits.abu.all.205)

phylo.205 <- mat$phy
traits.205 <- mat$data

is.ultrametric(phylo.205)

abu <- traits.205$abun.rec2
gro.a <- traits.205$growth.mean2
rownames(gro.a) <- rownames(traits.205)

gro.b <- traits.205$growth.light.mean2
mor.a <- traits.205$mort.mean2
mor.b <- traits.205$mort.light.mean2
rec.b <- traits.205$rec.light.mean2

rec.b.2 <- data.frame(as.numeric(as.character(rec.b)))
rownames(rec.b.2) <- rownames(traits.205)

brownianModel <- fitContinuous(chronotree, rec.b.2)
OUModel <- fitContinuous(chronotree, rec.b.2, model = "OU")
EBModel <- fitContinuous(chronotree, rec.b.2, model = "EB")



#OUModel <- fitContinuous(anoleTree, anoleSize, model = "OU")
#EBModel <- fitContinuous(anoleTree, anoleSize, model = "EB")

#brownianModel <- fitContinuous(phylo.205, anoleSize, SE = seSize)
#OUModel <- fitContinuous(anoleTree, anoleSize, model = "OU", SE = seSize)
#EBModel <- fitContinuous(anoleTree, anoleSize, model = "EB", SE = seSize)



## reconstruct states on the phylogeny:

# divide 95CI distance by 4


# calculate AIC weights
bmAICC <- brownianModel$opt$aicc
ouAICC <- OUModel$opt$aicc
ebAICC <- EBModel$opt$aicc

aicc <- c(bmAICC, ouAICC, ebAICC)
aiccD <- aicc - min(aicc)
aw <- exp(-0.5 * aiccD)
aiccW <- aw/sum(aw)
aiccW

####
# some checking whether PDAR script works on non-squared landscapes:

### 1) load grid.scale.5 data
load("/home/oliver/Dokumente/PhD/PostPhD/Projects/BCI_Coexistence/Code/grid.213.7.Rdata")


### redoing the stuff at the 20m scale:
## 1.1) bring BCI community matrix in the same order as scape matrix
# generate Ypa & Yabu
Yabu <- grid.213.7[[3]]
Ypa <- decostand(grid.213.7[[3]], "pa")

length(grid.213.7[[3]][,1])

## give rownames according to coordinates:
x <- rep(1:50, each =25)
y <- rep(1:25, 50)
coord <- as.data.frame(cbind(x,y))
coord$coords <- paste(coord[,1], coord[,2], sep = ".")
#mat.coord <- matrix(coord$coords, ncol = 100, byrow = T)

rownames(Yabu) <- coord$coords
rownames(Ypa) <- coord$coords

split <- strsplit(rownames(Ypa), ".", fixed = TRUE)
    row <- as.numeric(sapply(split, "[", 1)) # assumes that the first two columns hold the y- (rows) and and x-(columns) coordinates of the landscape
    column <- as.numeric(sapply(split, "[", 2))
    coords <- cbind(row, column)                                        # define in the header
    rows <- sqrt(dim(Ypa)[1]) # to be changed, if landscape is not a square matrix
    cols <- sqrt(dim(Ypa)[1])

pdac.nest.rand.all.rep.bci <- function(samp, tree, size=10) # size: maximum side of the moving window
{
    Yabu <- samp
    Ypa <- decostand(Yabu, "pa")
    
    split <- strsplit(rownames(Ypa), ".", fixed = TRUE)
    row <- as.numeric(sapply(split, "[", 1)) # assumes that the first two columns hold the y- (rows) and and x-(columns) coordinates of the landscape
    column <- as.numeric(sapply(split, "[", 2))
    coords <- cbind(row, column)                                        # define in the header
    rows <- 50 # to be changed, if landscape is not a square matrix
    cols <- 25 # to be changed, if landscape is not a square matrix
    #env <- eco.scape(tree=tree, scape.size=rows-1, g.center=100, signal.center=TRUE, K=100, extinction=TRUE)$environ$env.gradient
    SAcurve<-NULL
    SAcurve.mean<-NULL
    for(ss in 1:2) # 1- spatial, 2- non-spatial curve
    {
        for (sizex in 1:size)
        {
        ratio1 <- NULL
        ratio2 <- NULL
        ratio3 <- NULL
        ratio4 <- NULL
        ratio5 <- NULL
       env.sub <- NULL
        env.sub.sd <- NULL
        ##
        #ss <- 1
        #sizex <- 5
        #ROW <- 196
        #COL <- 96
        ##
            for(ROW in 1:(rows-sizex+1))
            {
                for(COL in 1:(cols-sizex+1))
                {
                    rowind <- ROW:(ROW+sizex-1)
                    colind <- COL:(COL+sizex-1)
                    if(ss==1) # spatially explicit curve
                    {
                        ind.subset <- which(coords[,1] %in% rowind & coords[,2] %in% colind)
                    }
                    else {  # non-spatial curve
                        ind.subset <- sample(rows*cols, length(rowind)*length(colind))
                    }
                    if(sizex==1) {ypa<-Ypa[ind.subset,]} else {ypa <- colSums(Ypa[ind.subset,])>0}
                    if(sizex==1) {yabu<-Yabu[ind.subset,]} else {yabu <- colSums(Yabu[ind.subset,])}
                    ratio1 <- rbind(ratio1, psr(ypa,tree,compute.var=FALSE)) # change index here
                    ratio2 <- rbind(ratio2, pse(yabu,tree)) # change index here
                    ratio3 <- rbind(ratio3, mntd(t(yabu),cophenetic(tree), abundance.weighted=TRUE)) # change index here
                    ratio4 <- rbind(ratio4, mntd(t(yabu),cophenetic(tree), abundance.weighted=FALSE)) # change index here
                    ratio5 <- rbind(ratio5, psv(ypa,tree,compute.var=FALSE)) # change index here
                    
                    #env.sub <- rbind(env.sub, mean(env[ind.subset]))
                    #env.sub.sd <- rbind(env.sub.sd, sd(env[ind.subset]))# extract the environenmental data here
                }
            }
        SAcurve <- rbind(SAcurve, cbind(ss, sizex, ratio1[,1], ratio1[,2], ratio2[,1], ratio3[,1], ratio4[,1], ratio5[,1])) #
        SAcurve.mean <- rbind(SAcurve.mean, c(ss,sizex,mean(ratio1[,1],na.rm=TRUE),sd(ratio1[,1],na.rm=TRUE),mean(ratio1[,2]),sd(ratio1[,2]), mean(ratio2[,1],na.rm=TRUE),sd(ratio2[,1],na.rm=TRUE),mean(ratio2[,2]),sd(ratio2[,2]), mean(ratio3[,1],na.rm=TRUE),sd(ratio3[,1],na.rm=TRUE), mean(ratio4[,1],na.rm=TRUE),sd(ratio4[,1],na.rm=TRUE), mean(ratio5[,1],na.rm=TRUE),sd(ratio5[,1],na.rm=TRUE),mean(ratio5[,2]),sd(ratio5[,2])))
        }
    }
    SAcurve<-data.frame(SAcurve)
    SAcurve[SAcurve[,1]==1,1]<-"spatial"
    SAcurve[SAcurve[,1]=="2",1]<-"nonspatial"
    colnames(SAcurve)<-c("curve","aggregate","psr","sr","pse","mntd.abu", "mntd.pa", "psv")
    SAcurve.mean<-data.frame(SAcurve.mean)
    SAcurve.mean[SAcurve.mean[,1]==1,1]<-"spatial"
    SAcurve.mean[SAcurve.mean[,1]=="2",1]<-"nonspatial"
    colnames(SAcurve.mean)<-c("curve","aggregate","mean.psr","sd.psr","mean.sr","sd.sr","mean.pse","sd.pse","mean.sr","sd.sr", "mean.mntd.abu", "sd.mntd.abu", "mean.mntd.pa", "sd.mntd.pa","mean.psv","sd.psv","mean.sr","sd.sr")

    SAcurve.all <- list("SAcurve" = SAcurve, "SAcurve.mean" = SAcurve.mean)
    return(SAcurve.all)
}

mat <- match.phylo.comm(bci.phylo.205, Yabu)

pdac.nest.rand.pool.shape.bci.20n <- pdac.nest.rand.all.rep.bci(samp=mat$comm, tree=mat$phy, size = 25)

######
# prepare script for ggplot
# get mean PD values at each scale:
dat <- pdac.nest.rand.pool.shape.bci.20n[[2]]

dim(dat)
    
library(ggplot2)

# for loop
i <-  c(5,3,15,11)[4]
p <- unique(dat.2$pool)[3]
w <- unique(dat.2$width)[1]


for (i in c(5,3,15,11)){ # index for PD metric
    
                dat$curve <- as.factor(dat$curve)
         
            
            ggplot(dat, aes(x = aggregate, y = eval(parse(text=names(dat)[i])), color= factor(curve)))+
                                        #geom_jitter(alpha=.1, position=position_jitter(width=0, height = 0), size = 1)+
                geom_point() +
                                        #geom_smooth(se=FALSE)+
                geom_line() +
                                        #geom_smooth(method=lm, se=FALSE)+
               
                                        #scale_colour_gradient( low="red") +
                labs(y=names(dat)[i], x= "Scale", color="Curve") +
                ggtitle(names(dat)[i]) +
                                        #facet_grid(shape ~ pool, scales="free") +
                
                theme_bw()
            ggsave(file = paste(names(dat)[i], "bci.real", "pdf", sep = "."), width=13, height=9, units="cm")
        }


# including measurement error

@

%\bibliographystyle{apa}
\bibliography{/home/oliver/Dokumente/PhD/Literatur/Bibfile/dislit}


\end{document}
